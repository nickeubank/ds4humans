# Causal Questions

In our previous readings, we learned how answering different types of questions can help us better understand the world around us. By answering Exploratory Questions, we can better understand the contours of our problem — where our problem is most acute, whether there are groups who have figured out how to get around the problem on their own, etc. — and by doing so help us prioritize our subsequent efforts. And by answering Passive Predictive Questions, we can help identify individual entities — patients, customers, products, etc. — to whom we may wish to pay extra attention or recommend certain products or services, or we can automate tasks by predicting how a person or more complicated process *would* have classified an entity.

In both cases, however, answering these questions only helps us better understand the world *around* us. But to the extent to which, as data scientists, we want to *solve* problems, we are rarely interested in just knowing about the world around us — we want to *act* on the world, and wouldn't be great if data science could provide us with a set of tools designed to help us predict the *consequences* of our actions?

Enter *Causal Questions*. Causal Questions ask what *effect* we can expect from *intervening* — that is, actively *manipulating* — the world around us in some way. For example, if we pay to show an ad to a specific customer, what will the *effect* of that choice be the likelihood they buy something on our website? Or if we chose to give a new drug to a patient, what will the *effect* of that choice be on their disease?

Because of their potential to help us understand the future consequences of our actions, it should come as no surprise that the ability to answer Causal Questions is of *profound* interest to everyone from companies to doctors and policymakers. At the same time, however, it should *also* come as no surprise that answering Causal Questions is an inherently challenging undertaking.

### What We Mean By "Cause"

To understand why answering Causal Questions is hard, we must actually take a step back and answer the question: "what do we mean when we say some action X *causes* an outcome Y?"

Seriously, what do we mean when we say "X causes Y?" Try and come up with a definition!

While this question may *seem* simple, it turns out that this question has been the subject of serious academic debate for hundreds of years by people as prominent as David Hume. Indeed, even today there is still debate over how best to answer this question.

In this course, we will make use of the *Counterfactual Model of Causality* (sometimes called the Neyman-Rubin causal model). In plain English, it posits that for "doing X to cause Y", it must be the case that if we do X, then Y will occur, and if we did not do X, then Y would not occur. This is by far the most used definition of causality today, and yet remarkably, it only emerged in the 20th Century and was only really fleshed out in the 1970s. Yeah... that recently.

At first blush, this definition may seem simple. But its simplicity belies a profoundly difficult practical problem. See, this definition relies on *comparing* the value of our outcome Y in two states of the world: the world where we do X, and the world where we don't do X. But as we only get to live in one universe, we can never perfectly know what the value of our outcome Y would be in *both* a world where we do X and one where we don't do X for a given entity at a given moment in time. As such, we can **never** directly measure the causal effect of X on Y for a given entity (say, a given patient or customer) at a given moment in time — a problem known as the **Fundamental Problem of Causal Inference** (causal inference being what people call the practice of answering Causal Questions).

To illustrate, suppose we were interested in the effect of taking a new drug (our X) on cancer survival (our Y)  for a given patient (a woman named Shikha who arrived at the hospital on June 18th 2022). We can give her the drug and evaluate whether she is still alive a year later, but that alone can't tell us whether the new drug *caused* her survival according to our counterfactual model of causality — after all, if she survives maybe she would have survived even without the drug! To actually know the effect of the drug on Shikha *by direct measurement,* we would have to be able to measure her survival both in the world where we gave her the drug *and* the world where we did not and compare outcomes.

Since we can never see both states of the world — the world where we undertake the action whose effect we want to understand and the world where we don't — almost everything we do when trying to answer Causal Questions amounts to trying to find something we *can* measure that we think is a *good approximation* of the state of the world we can't actually see.

A quick note on vocabulary: by convention, we refer to the action whose effect we want to understand as a "treatment," and the state of the world where an entity receives the treatment as the "treated condition." Similarly, we refer to the state of the world where an entity does *not* receive the treatment as the "control condition." We use this language even when we aren't talking about medical experiments or even experiments at all. We also refer to the state of the world we cannot observe as the "counterfactual" of the world we can observe — so the world where Shikha does not get the cancer drug is the *counterfactual condition* to the world where Shikha does get the drug.

It's at this point most people start throwing out "but what about..."'s, and that's good! You should be — that's exactly the kind of thinking you have to do when trying to answer Causal Questions. For example, "what about if we measured the size of Shikha's tumor before she took the drug and compared it to the size of her tumor after? If the tumor got smaller as soon as she started the drug, then surely the drug caused the tumor to shrink!"

Maybe! Implicitly, what you have done is asserted that you think that the size of Shikha's tumor before we administered the drug is a good approximation for what the size of Shikha's tumor *would have been* had we not given her the drug.

But this type of comparison will always fall short of the platonic ideal given by our definition of causality. Yes, Shikha's tumor *may* have stayed the same size if we had not given her the drug (in which case the size of the tumor before she took the drug would be a good approximation), but it is also possible that regardless of whether we'd given her the drug, her cancer would have shrunk on its own.[^natural_history]

[^natural_history]: The fact that diseases naturally change over time on their own is known as a disease's "natural history."

According to the Counterfactual Model of Causality, we could only ever *know* if taking the drug caused a decrease in tumor size if we could both administer the drug and observe the tumor *and also observe a parallel world in which the same person at the same moment in time was not given the drug for comparison*. And since we can never see this parallel world — the *counterfactual* to the world we observe — the best we can do is come up with different, imperfect tricks for *approximating* what might have happened in this parallel world, like comparing the tumor size before and after we administer the drug, imperfect though that may be.

So does that mean we're doomed? Yes and no. Yes, it *does* mean that we're doomed to never be able to take the exact measurements that make it possible to directly answer a Causal Question. But no, that doesn't mean we can't do anything — in the coming weeks, we will learn about different strategies for approximating counterfactual conditions, and in each case we will learn about what *assumptions* must be true for our strategy to provide a valid answer to our Causal Question. By making the assumptions that underlie each empirical strategy explicit, we will then be able to evaluate the plausibility of these assumptions.

In the example of Shikha, for example, we know that our comparison of tumor size before taking the drug to tumor size after taking the drug is only valid if her tumor *would not have gotten smaller without the drug*. This is something we can't measure directly, but we can look to other patients with similar tumors, or the history of her tumor size to evaluate how often we see tumors get smaller at the rate observed after she took the drug. If it's very rare for these types of tumors to ever get smaller, than we can have more confidence that a decrease in tumor size was the result of the drug.

For many data scientists, this will feel *profoundly* dissatisfying. May people come to data science because of the promise that it will provide direct answers to questions using statistics. But because of the Fundamental Problem of Causal Inference, this will never be possible when answering Causal Questions. Rather, your task will be like that of a detective trying to solve a crime — your task is to try and determine what *probably* happened at a crime scene by gathering clues, and to decide based on the amount of evidence you've been able to find how confident you are you know what happened. But try as you might, you will never actually get to be present at the time of the crime, so you will never be able to actually be sure if you are right or not.
