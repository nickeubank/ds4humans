{"version":"1","records":[{"hierarchy":{"lvl1":"Class Schedule"},"type":"lvl1","url":"/class-schedule","position":0},{"hierarchy":{"lvl1":"Class Schedule"},"content":"Class: Tuesday / Thursday, 1:25-2:40pm\n\nOffice Hours:\n\nNick: Thursday, 9:30-10:30am, \n\nhttps://​duke​.zoom​.us​/my​/nickeubank or Gross Hall 231","type":"content","url":"/class-schedule","position":1},{"hierarchy":{"lvl1":"Class Schedule","lvl2":"Texts Used"},"type":"lvl2","url":"/class-schedule#texts-used","position":2},{"hierarchy":{"lvl1":"Class Schedule","lvl2":"Texts Used"},"content":"This course will make use of readings from a handful of different sources. The main four, in order of the amount they will be used, are:\n\nDS4H: \n\nData Science for Humans (This website, free.)\n\nCunningham: \n\nCausal Inference Mixtape (30 new, 20 used. \n\nOnline Access through Duke Library)\n\nKTX: \n\nTrustworthy Online Controlled Experiments: A Practical Guide to A/B Testing (40 new, 30 used.)\n\nGHV: \n\nRegression and Other Stories ($40. Too new to have used versions.)\n\nClass Schedule\n\nDate\n\nTopic\n\nDo Before Class\n\nIn Class\n\nTh Jan 9\n\nCourse Overview\n\n\n\nacme\n\nTu Jan 14\n\nSolving Problems by Answering Questions\n\n\n\ngenerating\n\nTh Jan 16\n\nStakeholder Management\n\n\n\nstake\n\nTu Jan 21\n\nProscriptive v. Descriptive Questions\n\n\n\n\n\nTh Jan 23\n\nExploratory Questions: Purpose, Internal and External Validity\n\n\n\nexp\n\nTu Jan 28\n\nCapstone With Training Wheels Assignment\n\n\n\n\n\nTh Jan 30\n\nTeams 1\n\n\n\n\n\nTu Feb 4\n\nTeams 2\n\n\n\n\n\nTh Feb 6\n\nPassive Prediction Questions: Purpose and Alignment\n\n\n\n\n\nTu Feb 11\n\nPassive Prediction Questions: Internal and External Validity\n\n\n\n\n\nTh Feb 13\n\nGiving Feedback\n\nFeedback Exercise?\n\nFeedback Exercise?\n\nTu Feb 18\n\nPassive Prediction Questions: Loss Functions\n\n\n\n\n\nTh Feb 20\n\nPassive Prediction Questions: Interpretability\n\n\n\n\n\nTu Feb 25\n\nCausal Questions: Purpose\n\n\n\n\n\nTh Feb 27\n\nCausal Questions: Potential Outcomes\n\n\n\npo\n\nTu Mar 4\n\nCausal Questions: Potential Outcomes\n\n\n\nresume\n\nTh Mar 6\n\nCausal Questions: Experiments in Practice, Internal Validity\n\n\n\n\n\nTu Mar 11\n\nCausal Questions: Experiments in Practice, External Validity\n\n\n\nabtest\n\nTh Mar 13\n\nCausal Questions: Experiments in Practice, Design\n\n\n\npower\np-value preview\n\nTu Mar 18\n\nNO CLASS\n\n\n\n\n\nTh Mar 20\n\nNO CLASS\n\n\n\n\n\nTu Mar 25\n\nCausal Questions: Experiments, Bayesian Analysis\n\nAB Testing Review\n\n\n\nTh Mar 27\n\nCausal Questions: Experiments, Bayesian Analysis & Decision Theory\n\n\n\n\n\nTu Apr 16\n\nMIDTERM\n\nMIDTERM\n\n\n\nTh Apr 3\n\nCausal Questions: Regression\n\n\n\nincomeineq\n\nTu Apr 8\n\nCausal Questions: Matching\n\n\n\nmatching\n\nTh Apr 9\n\nCausal Questions: Differences and Differences / Panels\n\n\n\n\n\nTu Apr 15\n\nInterpretation of Results\n\n\n\nev\n\nWed, April 23\n\n\n\n\n\n\n\nWed, Apr 30\n\n\n\n\n\n","type":"content","url":"/class-schedule#texts-used","position":3},{"hierarchy":{"lvl1":"Solving Problems with Data"},"type":"lvl1","url":"/solving-problems-with-data","position":0},{"hierarchy":{"lvl1":"Solving Problems with Data"},"content":"Few fields have shown as much promise to address the world’s problems as data science. Today, data science is improving our understanding of and adaptation to climate change. It is being used in medicine to speed drug discovery, improve the quality of X-rays and MRIs, and ensure that patients receive appropriate medical care. It is used in courtrooms to fight for fair elections and electoral maps and by data journalists to document and communicate the injustices prevalent in our criminal justice system and issues in policing.\n\nData science also enables new technologies that may improve our lives. Autonomous drones are delivering blood and medical supplies to rural health clinics from Rwanda to \n\nNorth Carolina, and driver-aid features continue to make progress in reducing the over 30,000 traffic deaths and millions of injuries that occur in the US alone every year. And nearly every facet of business — from the way businesses source materials and manage inventory to the way product offerings respond to customer behavior — has been reshaped by data science.\n\nAt the same time, it is also increasingly clear that today’s challenges will not be met by “throwing data science at the problem” or “just adding AI.” According to a 2020 MIT/BCG survey, \n\nonly 11% of businesses that had piloted or employed Artificial Intelligence (AI) had reaped a sizeable return on their AI investments. Businesses and regulators are also coming to appreciate the potential of data science tools to reinforce racial and gender inequities. Algorithms at Amazon have been found to \n\ndiscriminate against female job applicants. Medical algorithms have been found to prioritize White patients over Black patients \n\nfor kidney transplants and \n\npreventative care. In the criminal justice system, algorithms have been found to \n\nincorrectly identify Black defendants than White defendants as being a “danger to society” when providing risk assessments to judges deciding on pre-trial release, bail and sentencing. And even Meta’s own research has shown its algorithms drive political polarization and division among users, and push users into extremist groups.\n\nHow, then, should a burgeoning data scientist approach this discipline, full of such promise and peril? And why have so many data science endeavors failed to deliver on their promise?","type":"content","url":"/solving-problems-with-data","position":1},{"hierarchy":{"lvl1":"Solving Problems with Data","lvl2":"The Three Big Ideas"},"type":"lvl2","url":"/solving-problems-with-data#the-three-big-ideas","position":2},{"hierarchy":{"lvl1":"Solving Problems with Data","lvl2":"The Three Big Ideas"},"content":"This book is my answer to these questions, and it is organized around three big ideas:\n\nData science is about solving problems. All too often, data scientists get lost in the technical details of models and lose sight of the bigger picture. Data science is not about maximizing accuracy or AUC scores — it’s about using data and quantitative methods to solve problems, and at the end of the day the only “metric” that matters is whether your work has solved the problem you set out to address.\n\nData scientists solve problems by answering questions, and the question you are asking determines what tool is appropriate. At their core, all data science tools are tools for answering questions, whether you realize it or not. Learning to recognize how data scientists use questions to solve problems — and exactly what questions are being answered by the tools you use every day — is key to navigating the ambiguity of real-world problem solving.\n\nReasoning rigorously about uncertainty and errors is what differentiates good data scientists from great data scientists. Data science isn’t just about minimizing classification errors and uncertainty — it’s also about deciding how unavoidable errors should be distributed, how to weigh the risks and trade-offs inherent in probabilistic decision-making rigorously and in a manner that takes into account the problem you are trying to solve, and to take uncertainty into account when acting on data.\n\nFrom the summary of these three ideas, it should be immediately obvious that this book is different from many other data science books you may have read. Where most data science books are designed to teach specific data science techniques or methods, the aim of this book is to provide readers with a framework for thinking about their goals and how to achieve them using data science methods. It is, in a sense, about everything you need to know beyond the technicalities of model fitting. It is about what comes before and after you fit your model: it will help you decide what questions to answer, what data to collect, and what models to consider using before you actually fit your model, and it will help you learn to evaluate whether a result is likely to generalize, whether a model is safe to deploy, and how to communicate those facts to a stakeholder after model fitting.\n\nThe importance of these skills is often underestimated by data science students, and for understandable reasons. Data science curricula usually begin with coding, statistics, and model evaluation techniques. As a result, the hardest part of data science classes is often mastering the technical details of model implementation. Moreover, the limited time available to instructors and the need to support full classes of students means data science exercises almost always have to come with clear directions and problem scaffolding to ensure students meet their learning goals.\n\nBut real-world problems don’t come with directions. Indeed, a problem that is clearly defined and for which a solution is obvious isn’t a problem anyone will pay you very much to solve. No, classroom exercises are carefully structured to foster learning and to make it possible for instructors to grade and provide feedback at scale. But real problems — the kind you will encounter in industry, government, or research — are hard to even articulate clearly, never mind solve. And that is why, as we will see, what really sets exceptional professional data scientists apart is not their ability to get a high AUC — it’s their ability to navigate and thrive in the face of ambiguous problems and goals.","type":"content","url":"/solving-problems-with-data#the-three-big-ideas","position":3},{"hierarchy":{"lvl1":"Solving Problems with Data","lvl2":"This Is A Book About The Forest, Not The Trees"},"type":"lvl2","url":"/solving-problems-with-data#this-is-a-book-about-the-forest-not-the-trees","position":4},{"hierarchy":{"lvl1":"Solving Problems with Data","lvl2":"This Is A Book About The Forest, Not The Trees"},"content":"The goal of this book, to frame things a little differently, is to help young data scientists maintain perspective. Students spend so much time learning individual techniques that they are unable to see the forest for trees. But this is not a book about individual techniques — it’s about learning to think strategically about how to use those techniques to solve real problems.\n\nTo maintain its focus on the “forest,” this book takes as given that you have already been introduced to statistical inference and machine learning and know how to faithfully fit a model in a robust manner. That means that topics like hypothesis testing, cross-validation, how to use train-test splits, and how to evaluate a model’s AUC will be treated as assumed knowledge. This is in no way meant to suggest these topics aren’t important — we will reference them constantly — just that I will not attempt to teach them here, both to maintain focus on the goals of this book, and also because there already exist many other resources that introduce these topics better than I could.","type":"content","url":"/solving-problems-with-data#this-is-a-book-about-the-forest-not-the-trees","position":5},{"hierarchy":{"lvl1":"Solving Problems with Data","lvl2":"Introduction Structure"},"type":"lvl2","url":"/solving-problems-with-data#introduction-structure","position":6},{"hierarchy":{"lvl1":"Solving Problems with Data","lvl2":"Introduction Structure"},"content":"The remainder of this introductory chapter contains an overview of the Big 3 ideas of the book. All concepts discussed here will also be covered in greater detail in future readings, but before we dive into them in detail, it’s helpful to get a sense of the overall approach we will be taking!\n\nRecent reporting by the Wall Street Journal has shown that Facebook’s own research has confirmed what many outside experts have long argued: the way its recommendation engines prioritize content that results in “user engagement” (clicks, shares, comments) ends up promoting partisan, polarizing, sensationalist, or extreme content. In addition, their own research has also shown that group recommendations are contributing to extremism. According to one internal presentation, “64% of all extremist group joins are due to our recommendation tools” like Groups You Should Join and other discovery tools.\n\nIf you are a Duke student reading this, it’s ok if you are not yet familiar with all of these topics so long as you are taking a good machine learning course — like IDS 705 — concurrently.","type":"content","url":"/solving-problems-with-data#introduction-structure","position":7},{"hierarchy":{"lvl1":"Idea 1: Solving Problems"},"type":"lvl1","url":"/solving-problems","position":0},{"hierarchy":{"lvl1":"Idea 1: Solving Problems"},"content":"Given the focus of data science coursework on the math, statistics, and programming that is required to use data science tools, one would be forgiven for thinking that understanding these tools is the ultimate goal of data science.\n\nAt the end of the day, however, your success as a data scientist will not be evaluated by whether you write good code or whether your classification model’s AUC score is high. No, your success as a data scientist will always be evaluated based on a much simpler criterion: did you make your stakeholder’s life better by solving a problem they faced?\n\nYour success as a data scientist will always be evaluated by one simple criterion: did you make your stakeholder’s life better by solving a problem they faced?\n\nOn the last page, I said that that one of the key goals of this book is to help young data scientist’s understand the broader context of their work. There is perhaps no better way to do that then to always keep this one fact front of mind. The things you practice in class exercises — writing good code and finding a classification model with a high AUC — are things that may help you achieve the goal of solving your stakeholder’s problem, but they are never sufficient in and of themselves. Indeed, it is hard to overstate how common it is to see talented young data scientists write brilliant, performant code and fit extremely accurate models that predict the wrong property, solve a problem that isn’t actually core to the stakeholder’s needs, require data not available in deployment, or work in training but won’t generalize to the stakeholder’s deployment context. The data scientists on these projects often deployed the skills they learned in technical classes magnificently, but this execution was not well-directed in service of the stakeholder — the classic “not seeing the forest for the trees” mistake.\n\nNote\n\nThroughout this book, I will frequently use the term “stakeholder” to refer to the person whose problem that you, the data scientist, is seeking to address. I use this term because, as a young data scientist, you will often be in the position of having to use your data science skills to help someone else. Thus your stakeholder may be your manager, your CEO, or someone at another company you are advising.\n\nHowever, if you’re lucky enough to not be directly answerable to someone else, either because you work for yourself or because you’re in a field that gives you substantial autonomy like academia, you can simply think of your “stakeholder” as yourself.\n\nIf you’re interested in developing a consumer-facing product (e.g., you’re an independing developer whose thinking of creating a new data-science-based web app), you may also find it useful to think of your customer of the stakeholder, since very few products are successful if they don’t solve a problem customers face.","type":"content","url":"/solving-problems","position":1},{"hierarchy":{"lvl1":"Idea 1: Solving Problems","lvl2":"Specifying The Problem"},"type":"lvl2","url":"/solving-problems#specifying-the-problem","position":2},{"hierarchy":{"lvl1":"Idea 1: Solving Problems","lvl2":"Specifying The Problem"},"content":"How, then, can we be sure our hard work as data scientists serves the interests of our stakeholder?\n\nThe first step in solving any problem is always to carefully specify the problem. While this may seem obvious, properly articulating the core problem one seeks to address can be remarkably difficult. Moreover, because everything you will do after articulating your problem is premised on having correctly specified your objective, it is the greatest determinant of the success of your project. The most sophisticated, efficiently executed, high precision, high recall model in the world isn’t worth a lick of good if the results it generates don’t solve the problem you or your stakeholder need solved.\n\nSpecifying your problem not only ensures that your subsequent efforts are properly directed, but it can also radically simplify your task. Many times problems only appear difficult because of how they are presented. As Charles Kettering, Head of Research at General Motors from 1920 to 1947 once said, “A problem well stated is a problem half solved.”\n\nHow do you know if you’ve “clearly articulated the problem,” and how should you go about refining your problem statement with your stakeholder? Those are topics we will discuss in detail in the coming chapters, as well as strategies for using data to help inform this process through iterative refinement of your understanding of the contours of the problem space.","type":"content","url":"/solving-problems#specifying-the-problem","position":3},{"hierarchy":{"lvl1":"Idea 1: Solving Problems","lvl2":"Stakeholder Management and Domain Expertise"},"type":"lvl2","url":"/solving-problems#stakeholder-management-and-domain-expertise","position":4},{"hierarchy":{"lvl1":"Idea 1: Solving Problems","lvl2":"Stakeholder Management and Domain Expertise"},"content":"Application is, in many ways, what sets data science apart from the disciplines of mathematics, computer science, and statistics. And to apply the tools of data science tools effectively, by definition, requires an understanding of the domain to which your tools are being deployed. This fact makes many data scientists uncomfortable — after all, many young data scientists do not even know the industry in which they will be employed when the graduate, never mind feel they can lay claim to being a “domain expert” in any specific substantive field.\n\nA consequence of this discomfort is that “domain expertise” is that the term “domain expertise” is often invoked as a way of abdicating responsibility for part of an analysis as “somebody else’s problem” (a dangerously powerful construction, as explained by the \n\nincomparable Douglas Adams).\n\nBut it would be a mistake to view domain expertise as beyond the responsibility of the data scientist for two reasons. First, engaging with the details of a substantive domain to tailor the application of data science methods to solve a specific problem isn’t ancillary to the job of a data scientists — it’s a data scientist’s comparative advantage. Data scientists (generally) are not the most technically skilled mathematicians, statisticians, or programmers — we are professionals who specialize in taking the best insights from all three of these skills sets and adapting them to fit the specific needs of a specific problem. So embrace the role of “domain knowledge!”\n\nThe second reason is that while you are unlikely to be a “domain expert” yourself, learning to solicit important information about a domain from true domain experts is a skill unto itself. As we will detail in our readings on “stakeholder management,” stakeholders may be experts in their particular substantive domain, but because they (usually) won’t understand data science, they are unlikely to ever provide you with the domain knowledge you need to do your job successfully (and you can’t get away with just saying “yes, this project failed, but it was because you didn’t tell me X!” See the discussion above of the single criterion used to evaluate data scientists). So learning to partner with your stakeholder and domain experts to understand a problem is a key part of understanding it properly, and thus eventually solving it.","type":"content","url":"/solving-problems#stakeholder-management-and-domain-expertise","position":5},{"hierarchy":{"lvl1":"Idea 2: Solving Problems by Answering Questions"},"type":"lvl1","url":"/question-types","position":0},{"hierarchy":{"lvl1":"Idea 2: Solving Problems by Answering Questions"},"content":"Once you’ve clearly articulated the problem you wish to solve, the next step is... to solve it! But how best to do so?\n\nAs data scientists, we are somewhat restricted in the types of solutions to which we have access. Nobody expects a data scientist to discover a new semiconductor manufacturing technique or solicit donors for cancer research funds.\n\nBut what data scientists can do is answer questions about the world. And while that may not seem inspiring at first, it’s a remarkably powerful ability. That’s because whether it’s trying to answer the question “does this patient have disease X?”, “what would happen to profits if we changed our pricing strategy?”, or “do universal income programs reduce long-term poverty?”, it turns out that a great many problems faced by both businesses and society as a whole become much easier to solve if we can better understand the consequences of our actions or reduce our uncertainty about the world.\n\nIn light of that fact, we can reframe the challenge of a data scientist from the more amorphous task of “figuring out how to solve the problem” to the more concrete “what question, if answered, would make it easier to solve this problem?” Once we’ve articulated a question to answer we can turn to choosing the best tool for generating an answer. But it is worth emphasizing this point — it is only at this stage of our project—not at the beginning!—that we start thinking about what statistical method, algorithm, or model is appropriate for the task.\n\nAnswering Questions\n\nThe challenge of a data scientist is to figure out “what question, if answered, would make it easier to solve this problem?”\n\nBut what if my stakeholder wants me to do something other than answer a question about the world? What if they want me to write a model to automatically read x-rays, or detect fraudulent transactions?\n\nWhile it may not be immediately obvious how these fit in the “data scientists solve problems by answering questions about the world” framework, I can assure you they do. Indeed, anything you can think of that a data scientist might do ends up fitting this model because — as we’ll discuss in detail below and later in the book — all data science models and algorithms can be understood as instruments designed to answer very specific, very concrete questions about data. And once you come to appreciate that fact, not only will this frame make more sense, but you will probably also find you understand many of the models you work with regularly more intuitively than you did before. To illustrate, [need some examples here. Examples hurt my head. Sticking to framework for now while I have momentum.] ","type":"content","url":"/question-types","position":1},{"hierarchy":{"lvl1":"Idea 2: Solving Problems by Answering Questions","lvl2":"Types of Questions"},"type":"lvl2","url":"/question-types#types-of-questions","position":2},{"hierarchy":{"lvl1":"Idea 2: Solving Problems by Answering Questions","lvl2":"Types of Questions"},"content":"There are three types of questions we will explore in this book, each of which helps to solve problems in a different way:\n\nExploratory Questions: Questions about patterns and structure in the world.\n\nHelp us to understand the problem space better and prioritizing subsequent efforts.\n\nPassive Prediction Questions: Questions about likely outcomes for individual observations or entities.\n\nUseful for targeting individuals for additional attention or automating certain tasks.\n\nCausal Questions: Questions about the consequences of actions or interventions being considered.\n\nUseful for deciding on appropriate courses of action.\n\nEach of these can play a different but important role in solving problems, and any effort to answer a question of each type will raise similar issues that need to be considered. As summarized next, by recognizing the class of questions we are seeking to answer, we can significantly narrow both the set of data science tools that are appropriate to consider and provide a short list of common considerations to think through.","type":"content","url":"/question-types#types-of-questions","position":3},{"hierarchy":{"lvl1":"Idea 2: Solving Problems by Answering Questions","lvl2":"Exploratory Questions"},"type":"lvl2","url":"/question-types#exploratory-questions","position":4},{"hierarchy":{"lvl1":"Idea 2: Solving Problems by Answering Questions","lvl2":"Exploratory Questions"},"content":"Once you have settled on a problem you wish to address, the next step is often to use data science to better understand the contours of the problem in order to better prioritize and strategize your efforts. As data scientists, our best strategy for this type of investigation is to ask questions about general patterns related to your problem — what I call Exploratory Questions.\n\nWhy is this necessary? Well, as we’ll discuss in a future reading on “stakeholder management,” you would be shocked at how often stakeholders have only a vague sense of the patterns surrounding their problem. This makes refinement of your problem statement (and thus prioritization of your subsequent efforts) impossible. So before you get too far into any data science project, it’s important to ask Exploratory Questions to improve your understanding of how best to get at your problem.\n\nTo illustrate, suppose a company hired you because they were having trouble recruiting enough high-quality employees. You could ask for their HR data and immediately try to train a neural network to... well, I’m not even sure what you’d want to train it to do right off that bat! And that’s a big part of the problem. Getting more high-quality employees is a very general problem, and you could imagine addressing it in any number of ways — you could try and get more people to apply for the job in the first place, you could try and get a different type of candidate to apply then is currently applying, you could try and get more high-quality people who are given job offers to accept those offers, or you could help try to increase the number of people who are hired who turn out to be successful hires! But which should you do first?\n\nTo help answer this question, we can start by asking a series of Exploratory Questions that, when answered, will aid in your efforts to solve your stakeholder’s problem:\n\nHow many job applications are you receiving when you post a job?\n\nWhat share of your current job applicants are of high quality?\n\nIf your current applicants come from different sources (online ads, services like Indeed, outreach to colleagues for recommendations, etc.), what share of job applicants from each of these sources are of high quality?\n\nWhat share of employees you try to hire accept your offer?\n\nWhat share of employees you do hire turn out to be successful employees?\n\nSuppose, for example, only 10% of applicants who receive job offers accept. Then clearly that would seem a place where intervention would be likely to substantially increase the number of high-quality employees being hired. If, by contrast, 95% of applicants accept offers, then that is clearly not a place where you would want to focus.\n\nSimilarly, if most applicants are high quality and there just aren’t enough of them, then you would probably want to focus your efforts on increasing the number of people who apply in the first place. But if only 2% of applicants seem appropriate to the company, then maybe focus should be put on changing who is applying for positions with an eye towards increasing the average quality of applicants.\n\nAnswering these questions will likely not, on its own, make it clear exactly where to focus your efforts. Your stakeholder may look at the fact that only 2% of applicants are appropriate and say “That’s fine — we have so many applications that the absolute number of quality applicants is actually high enough, and it’s easy to filter out the bad applicants.” But these are numbers you can bring back to your stakeholder to discuss and use to zero in on the specific facet of their problem that is most amenable to an impactful solution.\n\nGenerating answers to these types of Exploratory Questions doesn’t have the same “coolness factor” as using expensive GPUs to train deep learning models. But it is precisely this type of analysis that will help ensure that when if you do later run up a giant bill renting GPUs, at least that money will have been spent addressing a part of your stakeholder’s problem that matters.\n\nSo how does one go about answering Exploratory Questions? As we’ll discuss in later chapters, at times Exploratory Questions can be answered with simple tools, like scatter plots, histograms, and the calculation of summary statistics like means and medians. Other times, however, it may require more sophisticated methods, like clustering or other unsupervised machine learning algorithms that can, say, identify “customer-types” in a large dataset of customer behavior.\n\nRegardless of the tool used, however, the goal is always to identify patterns in the world that are salient to understanding your stakeholder’s problem.\n\nNote\n\nAnswering Exploratory Questions is not synonymous with “Exploratory Data Analysis” (EDA). As it is commonly understood and practiced by students, EDA refers to the process of poking around in a new data set before fitting a more complicated statistical model. It entails learning what variables are present, how they are coded, and sometimes looking at general patterns in the data prior to model fitting. Crucially, it is generally defined by what it is not — it is what you do before you fit a complicated model — and by the tools used — EDA consists of plotting distributions or cross-tabulations, not fitting models or doing more sophisticated analyses.\n\nAnswering Exploratory Questions, by contrast, is about achieving a substantive goal — learning about patterns in the world — not the tools used to do it, or what it comes before. Answering an important Exploratory Question may require you to actively seek out new data, merge data from different sources together, and potentially do novel data collection. It may also entail model fitting or use of unsupervised machine learning algorithms to uncover latent patterns.\n\nWe will discuss the conceptual issues surrounding EDA in more detail in a later reading.","type":"content","url":"/question-types#exploratory-questions","position":5},{"hierarchy":{"lvl1":"Idea 2: Solving Problems by Answering Questions","lvl2":"Passive Prediction Questions"},"type":"lvl2","url":"/question-types#passive-prediction-questions","position":6},{"hierarchy":{"lvl1":"Idea 2: Solving Problems by Answering Questions","lvl2":"Passive Prediction Questions"},"content":"Answering Exploratory Questions helps you to prioritize your efforts and improve your understanding of your stakeholder’s problem. Often you will bring the answers you generate to Exploratory Questions back to your stakeholder and use them to refine your problem statement in an iterative loop. “Yes, your broader problem is your profit margins are too thin, but after looking at your cost structure, it seems that the biggest driver of costs is the labor that goes into product packaging. So let’s focus on minimizing that.” But what then? Simple! We return to asking “What question, if answered, would help solve my problem?”\n\nThe second class of questions which, if answered, often help solve stakeholder problems are Passive Prediction Questions. Passive Prediction Questions are questions about the future outcomes or behaviors of individual entities (people, stocks, stores, etc.). This type of question may take the form “Given this new customer’s behavior on my website, are they likely to spend a lot over the next year?” or “Given the symptoms of this patient and their test results, how likely are they to develop complications after surgery?”  (Don’t worry about the “passive” part of the name — we’ll circle back to why that’s there below. For the moment, you may find it helpful to just think of these as “Prediction Questions.”).\n\nBecause Passive Prediction Questions are questions about individual entities, they don’t necessarily have one “big” answer. Rather, Passive Prediction Questions are answered by fitting or training a model that can take the characteristics of an individual entity as inputs (e.g., this patient is age 67, has blood pressure of 160/90, and no history of heart disease) and spitting out an answer for that individual (given that, her probability of surgical complications is 82%). This differentiates Passive Prediction Questions from Exploratory Questions, which are about global patterns, not individual level predictions.\n\nWith Passive Prediction Questions, the first question to ask is often one of feasibility: “Given data on new customer behavior on my website, can I predict how much they are likely to spend a lot over the next year?” But you then answer that question by training a model that can answer the question you really care about for any given customer: “Given this new customer’s behavior on my website, are they likely to spend a lot over the next year?”\n\nThis ability to make predictions about future outcomes is obviously of tremendous use to stakeholders as it allows them to tailor their approach at the individual level. A hospital that can predict which patients are most likely to experience complications after surgery can allocate their follow-up care resources accordingly. A business that knows which customers are more likely to be big spenders can be sure that those customers are given priority by customer care specialists.\n\nBut the meaning of the term “Prediction” in Passive Prediction Questions extends beyond “predicting the future”. Passive Prediction Questions also encompass efforts to predict how a third party would behave or interpret something about an individual if given the chance.\n\nFor example, suppose our hospital stakeholder wanted to automate the reading of mammograms so that rural hospitals without full-time radiologists could give patients diagnoses more quickly (or, more cynically, pay fewer radiologists). How does a model that reads mammograms “answer a question”? Well, in a very meaningful way, if you train your model by feeding it a dataset of mammograms that have been labelled as “normal” or “abnormal” by radiologists, then what that model is learning to do is answer the question: “if a radiologist looked at this particular scan, would they conclude it is abnormal?”\n\nThe value of this type of prediction to stakeholders is likely also self-evident, as it opens the door for automation and scaling of tasks that would otherwise be too costly or difficult for humans. Indeed, answering this question is the type of task for which machine learning has become most famous. Spam filtering amounts to answering the question “If the user saw this email, would they tag it as spam?” Automated content moderation amounts to answering “Would a Meta contractor conclude the content of this photo violates Facebook’s Community Guidelines?” Indeed, even Large Language Models (LLMs) like chatGPT, Bard, and LLaMA can be understood in this way, as we will discuss later.\n\nNote\n\nThinking of training an algorithm to read a mammogram as a model that answers the question “if a radiologist looked at this particular scan, would they conclude it is abnormal?” may seem a little strange at first. But this framing is both more accurate and more conceptually useful than the more common frame of “this is a a model that detects abnormal mammograms.” That’s because when a data science problem is solved by training a model on data on past human behavior, it isn’t actually learning to “detect cancer” — it’s learning to emulate the behavior of the humans in the training data.\n\nThis distinction is subtle, but it is important because it helps us to understand why any model we train in this way will inherit all of the biases and limitations of the radiologists who created the data used to train the algorithm. If, for example, our radiologists were less likely to see cancer in denser breast tissue, that bias would also be inherited by the algorithm.\n\n(We call the inevitable existance of some difference between between what we want the algorithm to do — in this case, detect cancer — and what it is actually being trained to do — predict how a radiologist would interpret the scan — an “alignment problem.”)\n\nIt is worth emphasizing that the distinction between Exploratory Questions and Passive Prediction Questions is a distinction in purpose, not necessarily a distinction in the statistical tools that are most appropriate to the task. A linear regression, for example, may be used for answering either type of question, but in different ways. To answer an Exploratory Question, we might look at the coefficients in a linear regression to understand the partial correlations between variables in the data. To answer a Passive Prediction Question, we might only look at the predicted values from the regression model.\n\nBut even if the same type of model can be used for both purposes, how one evaluates the model depends entirely on the purpose to which it is being put. When answering an Exploratory Question through the interpretation of regression coefficients, the size of the standard errors on the coefficients is critical. When making predictions, by contrast, one may not care about the coefficients of a model at all! So long as the R-squared is high enough (and other diagnostics seem good), one can simply use the predicted values the regression generates without ever looking “inside the box.”\n\nAs such, there’s no simple mapping between statistical or machine learning methods and the type of questions you aim to answer. With that said, the study of how to answer Passive Prediction Questions is often referred to as “supervised machine learning.”","type":"content","url":"/question-types#passive-prediction-questions","position":7},{"hierarchy":{"lvl1":"Idea 2: Solving Problems by Answering Questions","lvl2":"Causal Questions"},"type":"lvl2","url":"/question-types#causal-questions","position":8},{"hierarchy":{"lvl1":"Idea 2: Solving Problems by Answering Questions","lvl2":"Causal Questions"},"content":"The last category of question that data scientists are commonly called upon to answer are Causal Questions: questions about what the effect might be if a certain action is taken. For example, “What would be effect be of patients with disease X taking medication Y?” or “what would the effect of changing the interface of my app be on user retention?”\n\nCausal Questions most often arise when a stakeholder wants to do something — buy a Superbowl ad, change how a recommendation engine works, authorize a new medical device — but they fear the action they are considering might be costly and not actually work. In these situations, stakeholders will often turn to a data scientist in the hope that the scientist can “de-risk” the stakeholder’s decision by providing guidance on the likely effect of the action before the action is undertaken at full scale.\n\nCausal Questions, therefore, take the form of “What is the effect of an action X on an outcome Y?”—or more usefully, “If I do X, how will Y change?”. Nearly anything can take the place of X and Y in this formulation: X could be something small, like changing the design of a website, or something big, like giving a patient a new drug or changing a government regulation. Y, similarly, could be anything from “how long users stay on my website” or “how likely are users to buy something at my store” to “what is the probability that the patient survives”.\n\nIn my view, Causal Questions are perhaps the hardest to answer for two reasons. The first is that when we ask a Causal Question, we are fundamentally interested in comparing what our outcome Y would be in two states of the world: the world where we do X, and the world where we don’t do X. But as we only get to live in one universe, we can never perfectly know what the value of our outcome Y would be in both a world where we do X and one where we don’t do X—a problem known as the Fundamental Problem of Causal Inference (causal inference is just what people call the study of how to answer Causal Questions).\n\nBut the second reason is Causal Questions land on the desk of data scientists when a stakeholder wants to know the likely consequences of an action before they actually undertake the action at full scale. This may seem obvious, but it bears repeating — not only is answering Causal Questions hard because we never get to measure outcomes in both a universe where our treatment occurs and also a universe where it does not (the Fundamental Problem of Causal Inference), but answering Causal Questions is also hard because stakeholders want to know about the likely consequences of an action they aren’t ready to actually undertake!\n\nAs a result, the job of a data scientist who wants to answer a Causal Question is to design a study that not only measures the effect of a treatment but also does so in a setting that is enough like the context in which the stakeholder wants to act that any measured effect will generalize to the stakeholder’s context.\n\nNote\n\nNow that we’ve discussed Causal Questions, we can discussion the term “passive” in “Passive Prediction Questions.” The term “Passive” in “Passive Prediction Questions” is meant to differentiate situations where a stakeholder wants to predict things about individuals they do not yet know in a world where the status quo prevails and our behavior doesn’t change.\n\nFor example, when answering the Passive Prediction Question “Given their case history, how likely is this patient to experience post-surgical complications?” we don’t actually want to know how likely they are to experience complications — we want to know how likely they would be to experience complications absent any intervention. Our hope, after all, is that by learning that a certain patient is likely to experience complications we can act to prevent that outcome!\n\nObviously, we might then want to build on the insights provided by that model and ask a followup Causal Question: “What would the effect be of assigning an extra nurse to patients predicted to be more likely to have post-surgical complications?”\n\nBut because these questions are different in their goals, we would also go about answering them in very different ways. For example, we might answer our Passive Prediction Question using historical patient data and a logistic regression or decision tree. And to answer our Causal Question, we might run a randomized experiment in which half the patients we predict as likely to experience complications are assigned an extra nurse and half are not, and we later compare patient outcomes.","type":"content","url":"/question-types#causal-questions","position":9},{"hierarchy":{"lvl1":"Idea 2: Solving Problems by Answering Questions","lvl2":"An Example"},"type":"lvl2","url":"/question-types#an-example","position":10},{"hierarchy":{"lvl1":"Idea 2: Solving Problems by Answering Questions","lvl2":"An Example"},"content":"In this introductory chapter alone, we’ve already covered a substantial amount of material. We’ve discussed the importance of problem articulation, the idea that the way data scientists solve problems is by answering questions, and the three types of questions data scientists are likely to encounter.\n\nIt’s easy to see how this framework might result in a sequential development of a project. First, a hospital comes to you concerned about the cost of surgical complications. So you:\n\nWork with them to more clearly define the problem (“Surgical complications are extremely costly to the hospital and harm patients. We want to reduce these complications in the most cost-effective manner possible.”)\n\nYou answer some Exploratory Questions (“Are all surgical complications equally costly, or are there some we should be most concerned about?”).\n\nYou develop a model to answer a Passive Prediction Question (“Given data in patient charts, can we predict which patients are most likely to experience complications?”) so the hospital can marshal its limited nursing resources more effectively.\n\nThe hospital then comes back to you to ask the Causal Question “Would a new program of post-discharge nurse home visits for patients identified as being at high risk of complications reduce complications?”\n\nIn reality, however, while it is important that some steps come before others (if you don’t start by defining your problem, where do you even start?), real projects are never so linear. The reality is that you will constantly find yourself moving back and forth between different types of questions, using new insights gained from answering one question to refine your problem statement and articulate new questions.\n\nNevertheless, by using this framework as a starting point, and using this taxonomy to help you recognize (a) the type of question you are asking, and (b) the reason you are seeking to answer a given question even when iterating through a project, you will see tremendous gains in your ability to please your stakeholders by staying focused on the problems they need addressed.\n\nCareful readers may notice that these categories do not include should questions, which are sometimes referred to as “prescriptive” or “normative” questions. As we will discuss in detail in an upcoming reading, that is because while data science is an amazing tool for characterizing the world around us, it cannot, on its own, answer questions about how the world should be. Answering “should questions” requires evaluating the desirability of different possible states of the world, and that can only be done with reference to a system of values, making them inherently subjective. Data science can help us predict the consequences of different courses of action, but it cannot tell us whether those consequences make a given course of action preferable.\n\nMammograms are x-rays of breast tissue used for the detection of breast cancer.","type":"content","url":"/question-types#an-example","position":11},{"hierarchy":{"lvl1":"Idea 3: Being Thoughtful About Being Wrong"},"type":"lvl1","url":"/mistakes","position":0},{"hierarchy":{"lvl1":"Idea 3: Being Thoughtful About Being Wrong"},"content":"The third big idea of this book is that one of the biggest differentiators of good data scientists and great scientists is not their ability to maximize the accuracy of their models, but to think rigorously about their models limitations and the errors they will inevitably commit.\n\nTo illustrate the type of fallacy that young data scientists fall prey to in their quest to maximize model performance, let us consider that most intuitive of metrics, accuracy — the share of classifications a model makes that are correct. In my role as the Admissions Chair for the Duke Masters of Interdisciplinary Data Science (MIDS) program, I read hundreds of essays a year from aspiring data scientists, and I long ago lost count of the number of times I have seen some version of the following passage with little to no additional context:\n\nWhile working in [person]'s lab, I fit a [logit/XGBoost/Random Forest/Deep Learning] model to the data and achieved an accuracy of 96%.\n\nOr, in the applicant’s resume, they report attaining an accuracy score in the 90s with some model.\n\nI assume that these authors believe that this type of declaration reflects well on them — after all, 96% accuracy means only 4% of observations were mis-classified! But the truth is that reporting a high accuracy absent addition information about model performance actually tells me more about the author’s failure to understand this third Big Idea of the book than it tells me about their modelling prowess.\n\nTo illustrate why, suppose I told you I had developed a model that could predict breast cancer in mammograms with an accuracy of over 90%. That’d be amazing, right? Mammograms cost roughly $10 billion dollars a year in the US alone, so any reduction in need for skilled radiologists to review mammograms would be a huge win for women’s health and healthcare costs, right?\n\nNow suppose I told you that the model I wrote was this:def my_cancer_detection_model(mammogram):\n    is_scan_abnormal_maybe_cancerous = False\n    return is_scan_abnormal_maybe_cancerous\n\nHow does that have an accuracy of 90%? Simple — according to the Susan G. Komen Society, roughly 90% of routine mammograms are normal and require no followup. Thus a “model” that reports all routine mammograms are normal will immediately achieve an accuracy score of 90%. In fact, the true accuracy of the model is actually higher than 90%, since most mammograms flagged as “abnormal” are determined to not be indicative of cancer after followup (e.g., after biopsies).\n\nSo, are you still impressed by my model’s 90% accuracy?\n\nOf course not. And to be clear, the problem with this model is not that its accuracy is only 90% and not, say 95%. The problem with this model is that it has a False Negative Rate (the share of cases that are positive — in this case, mammograms from women with cancer — that are classified as cancer free) of 100%. And since the thing we care about most in cancer screenings is not telling a patient with cancer they’re fine (a False Negative), that’s a huge problem!\n\nOK, if what we care about is the False Negative Rate, shouldn’t we just minimize the False Negative Rate? Not so fast! Consider this model:def my_no_false_negative_model(mammogram):\n    is_scan_abnormal_maybe_cancerous = True\n    return is_scan_abnormal_maybe_cancerous\n\nOh dear. Yes, that model has a 0% False Negative Rate, but it also has a 100% False Positive Rate, meaning anyone subject to this screening would be told they might have cancer and needs followup diagnostic procedures! That’s no good either.\n\nNo, a good model for reading mammograms needs to maximize accuracy while also balancing the desire to not subject healthy women to unnecessary procedures (minimize False Positives) and the desire to not fail to flag potentially cancerous scans. And that’s what I mean when I say that a great data scientist is one who is thoughtful about how their models make mistakes. Determining what model is “best” requires more than optimizing a simple objective function — it requires thinking critically about the problem one is trying to solve (Big Idea 1), the substantive impact of different types of model errors in the context of that problem, and using that to inform model selection and evaluation. And less you think this is a contrived example, it's not. This particular problem — models that just says everything is from the more prevalent group getting high accuracy scores — happens any time you have *imbalanced data* (the data is mostly of one type). And 90/10 isn't even that imbalanced — fraudulent credit card purchases [make up less than one-tenth of 1% of all credit card transactions](https://www.federalreserve.gov/newsevents/pressreleases/other20181016a.htm). That means a \"model\" that reports all credit card transactions are valid will immediately have an accuracy score of $>99.9%$.\n\nThis is just one example of the kind of problem you will encounter if you aren't thoughtful about the types of errors you make, however. \n\n Suppose you train a model to review job applications. You pick a balance of False Positives, False Negatives, and Accuracy that makes sense for you problem, but forget to look at *who* ends up being classified as False Negatives and False Positives. If all of the False Positives (applicants advanced in the hiring process who shouldn't be) turn out to be White men, and all of the False Negatives are women and People of Color, is that something you should worry about? Is it ethical? Is it *legal*?\n\nAnd  \n\n“Aggregate Cost of Mammography Screening in the United States: Comparison of Current Practice and Advocated Guidelines”, Annals of Internal Medicine, February 2014.","type":"content","url":"/mistakes","position":1},{"hierarchy":{"lvl1":"What is Data Science: An Historical Perspective"},"type":"lvl1","url":"/data-science-in-historical-context","position":0},{"hierarchy":{"lvl1":"What is Data Science: An Historical Perspective"},"content":"Given how often the term “data science” gets thrown around, you would be excused for thinking that the meaning of the term was clearly understood. The reality, however, is that if you were to ask ten people working in the field you will almost certainly get ten different descriptions of what it is and what they do.\n\nPart of that is deliberate obfuscation—data science is so trendy that everyone wants to claim that what they’re doing is data science in order to woo venture capitalists or to win research grants. Indeed, it has been said (half-joking, half-seriously): \"Data science is Artificial Intelligence when you’re raising money, Machine Learning when you’re hiring, and it’s Logistic Regression when you actually have to get the job done.\n\nBut the ambiguity that surrounds the term “data science” is also the result of the fact that data science is not a mature discipline in the way that computer science, economics, or mechanical engineering are mature disciplines. And, as a young data scientist, that immaturity is important for you to understand, as it is both the source of some of the most exciting opportunities and also some of the biggest challenges you will face.","type":"content","url":"/data-science-in-historical-context","position":1},{"hierarchy":{"lvl1":"What is Data Science: An Historical Perspective","lvl2":"The Organization of Academia, Data Science, and You"},"type":"lvl2","url":"/data-science-in-historical-context#the-organization-of-academia-data-science-and-you","position":2},{"hierarchy":{"lvl1":"What is Data Science: An Historical Perspective","lvl2":"The Organization of Academia, Data Science, and You"},"content":"To explain what the term data science means in practice, we have to start by discussing a bit of the inside-baseball of how academia operates. This may feel esoteric, but it’s important to understand because the way academia is organized has shaped the professional training — and thus the language and thought patterns — of most people you will encounter in the data science space. Understanding academia better, as a result, will not only help you understand the material you are exposed to in data science classes better, but also help you relate to your future peers and colleagues.\n\nThe idea that academia is deeply fragmented often surprises students, and understandably so. Universities love to pay lip service to the importance of interdisciplinarity and are quick to highlight successful interdisciplinary collaborations. But successful interdisciplinary collaborations are so notable precisely because they are the exception, not the rule. The reality is that academic research is starkly divided into disciplinary silos (e.g., computer science, statistics, political science, economics, and engineering). This isn’t because researchers aren’t interested in interdisciplinary collaborations, but rather that their professional imperatives push them to focus their attention on the priorities and language of their own departments and disciplines.\n\nThus, while the past several decades have seen an unprecedented emergence of new methods across all of academia, the lack of intellectual cross-pollination across academic silos has resulted in disciplines failing to take full advantage of discoveries from other disciplines. Over time, each discipline has developed a perspective on computational methods that emphasizes its own intellectual priorities.\n\nTo illustrate, suppose we were interested in using patient data to reduce heart attacks. A computer scientist looking at this problem might use their discipline’s methods to predict which patients are most likely to experience a heart attack in the future using current patient data; a social scientist might focus on trying to understand the effect of giving patients a new drug on heart attack risk; and a statistician might focus on understanding how confident we should be in the conclusions reached by the computer scientist and social scientist.\n\nThis fragmentation has also resulted in a fragmentation of language around data science methodologies. Disciplines often come up with different terminology for the same phenomena, adding another layer of difficulty to efforts to work across departmental silos.\n\nThe result is a situation analogous to the Buddhist parable of the blind men and the elephant, wherein a group of blind people come upon an elephant, and upon laying hands on different parts of the elephant, they come to different conclusions about what lies before them. The person touching the tail declares “we have found a rope!”, while the person touching the leg declares “we have found a tree!”\n\n(Note: Not sure of original source of this image. \n\nFound it here, but need to figure out rights prior to anything about this becoming commercial! Lots of pics in public domain if needed, but not blindfolded scientists.)\n\nAnd yet, as the poet John Godfrey Saxe wrote in his poem \n\nThe Blind Men and the Elephant about this parable many centuries later:\n\nAnd so these men of Indostan,\nDisputed loud and long,\nEach in his own opinion\nExceeding stiff and strong,\nThough each was partly in the right,\nAnd all were in the wrong!\n\nIn recent years, however, there has been a growing appreciation of what can be gained from pulling together the insights that have been developed in different fields, despite the challenges of language and professional imperatives to such collaborations. And, at least amongst those who are serious about the development of data science as a discipline and not just a buzzword to use when raising money, is the promise of data science: to unify the different perspectives and methods for analyzing data. Or, to put it more succinctly: to finally see the whole elephant.\n\nWhile the field is making progress towards “seeing the elephant as a whole,” however, as a result of this fragmented origin story, most people you will encounter in the world doing data science were trained in one of these academic silos. That means that depending on who you are working with and how they were trained, you may find your future colleagues using terms you’ve never heard before. And when that happens, it’s important to remember that while that may be because they’re talking about a concept you’ve yet to encounter, it may also simply be because they’re using different language for something you know. Similarly, you may also find senior colleagues unfamiliar with concepts that seem basic to you simply because you were exposed to perspectives that were alien to your colleague’s academic silo at the time they were trained. Indeed, given that data science education is finally becoming more unified, you should probably expect to learn a lot of ideas that even your more senior colleagues (or rather, especially your more senior colleagues!) were never exposed to.\n\nAnd therein also lies some of the greatest opportunities. Precisely because of this intellectual fragmentation, there are lots of opportunities for taking insights from one intellectual silo and using them to solve problems in another — a kind of “intellectual arbitrage,” if you will.","type":"content","url":"/data-science-in-historical-context#the-organization-of-academia-data-science-and-you","position":3},{"hierarchy":{"lvl1":"What is Data Science: An Historical Perspective","lvl2":"The Data Analyst / Software Engineering Distinction"},"type":"lvl2","url":"/data-science-in-historical-context#the-data-analyst-software-engineering-distinction","position":4},{"hierarchy":{"lvl1":"What is Data Science: An Historical Perspective","lvl2":"The Data Analyst / Software Engineering Distinction"},"content":"In addition to this broader intellectual fragmentation, the world of data science also often feels oddly fragmented around the way people use the tools of data science.\n\nOne model of data science is what we will call the “data analyst” approach. Data scientists doing this type of work often collect data to answer specific questions—what is the effect of expanded government health insurance subsidies on mortality? what type of customer should we target with our new advertising campaign?. As a result, when they write code, they write it to be run against a specific set of data to answer a specific question.\n\nThe other model is what we will call the “software engineering” approach. Data scientists doing this type of work write software they plan to deploy to thousands or millions of users. This is the type of work that gets embedded in the apps on your phone, or that generates your movie recommendations at Netflix. As a result, when these data scientists write code, they are writing more sophisticated and generalizable programs.\n\nTo be clear, most data scientists do at least a bit of both types of work—data analysts may often write small programs or packages to aid in types of analysis they do a lot, and software engineers have to prototype and test new programs before they write a version that can be deployed broadly. But most people will eventually choose to specialize in one direction or another, and when you see data science resources in the world—especially ones about programming for data science—bear in mind that depending on your proclivities towards on approach or another, not all resources will be well suited to your interests.\n\nI also want to draw attention to this distinction because it’s remarkable how dismissive most data scientists will be of the “other” type of data science, and I want to encourage you to both (a)not be so tribal yourself (both flavors of data science have their place, and help solve real world problems!), and (b) not be too surprised when you encounter people with irrationally strong opinions about which approach is the “right” approach to doing data science.\n\n“\n\nInside baseball” refers to the discussion of the idiosyncracies and details of how an institution or system operates internally, something that is often not of interest to people who aren’t part of the system.\n\nNearly all university faculty are hired by established departments like statistics or economics, faculty submit their research to journals specific to their discipline, those journals in turn ask fellow members of the discipline to evaluate their work for publication, and promotions and tenure reviews are managed by the faculty in a faculty member’s own department.","type":"content","url":"/data-science-in-historical-context#the-data-analyst-software-engineering-distinction","position":5},{"hierarchy":{"lvl1":"Solving the Right Problem"},"type":"lvl1","url":"/solving-the-right-problem","position":0},{"hierarchy":{"lvl1":"Solving the Right Problem"},"content":"If data science is the study of how to solve problems using quantitative methods, then the first — and arguably most important — stage in any data science project is to define the problem to be solved.\n\nWhile this may seem simple, it is often far from it. Indeed, as noted in the introduction, problems often only appear complicated because they are poorly understood. Reframing or rearticulating a difficult problem is often the key to figuring out how to solve it, which is why the adage “A problem well stated is a problem half solved” has remained popular for so long.\n\nA problem well stated is a problem half-solved.\n\nCharles Kettering, Head of Research at General Motors\n\nIn this chapter, we will discuss what happens when data scientists fail to appreciate the importance of this stage of a project. With that established, we will then turn to advice on how to approach problem articulation.\n\nThis chapter will be written as if you are the sole actor on a data science project, responsible for everything from problem articulation to execution. But of course, this will rarely be the case in your professional life as a data scientist, especially early in your career. With that in mind, in the next chapter we will turn to the topic of “Stakeholder Management” — the practice of refining your understanding of the problem to be solved with a stakeholder.","type":"content","url":"/solving-the-right-problem","position":1},{"hierarchy":{"lvl1":"Solving the Right Problem","lvl2":"If You Don’t Articulate The Problem"},"type":"lvl2","url":"/solving-the-right-problem#if-you-dont-articulate-the-problem","position":2},{"hierarchy":{"lvl1":"Solving the Right Problem","lvl2":"If You Don’t Articulate The Problem"},"content":"There are many examples in the world of data science projects going awry because the team behind them failed to properly articulate the problem they wished to solve. Rather than start with one of those true stories, however, I’d like to begin with one of my favorite fictional (and humorous) examples of the phenomenon.\n\nIn Douglas Adams’ comedic sci-fi classic Hitchhiker’s Guide to the Galaxy, a race of hyperintelligent pandimensional beings set out to build a massive supercomputer the size of a city to solve the mysteries of the cosmos once and for all. When they turned on the computer, named Deep Thought, they announced that:\n\n“The task we have designed you to perform is this. We want you to tell us... the Answer!”\n\n“The Answer?” said Deep Thought.\n\n“The Answer to what?”\n\n“Life!” urged one designer.\n\n“The Universe!” said another.\n\n“Everything!” they said in chorus.\n\nDeep Thought paused, then answered, “Life, the Universe, and Everything. There is an answer. But,” Deep Thought added, “I’ll have to think about it.”\n\nSeven and a half million years later, when Deep Thought had finally finished its calculations, the descendants of those designers assembled to learn the result of their ancestors’ work.\n\n“Er ...good morning, O Deep Thought,” said Loonquawl [one descendant] nervously, “do you have ... er, that is ...”\n\n“An answer for you?” interrupted Deep Thought majestically. “Yes. I have.”\n\nThe two [descendants] shivered with expectancy. Their waiting had not been in vain.\n\n“There really is one?” breathed Phouchg [the other descendant].\n\n“There really is one,” confirmed Deep Thought.\n\n“To Everything? To the great Question of Life, the Universe and Everything?”\n\n“Yes. [...] Though I don’t think,” added Deep Thought, “that you’re going to like it.”\n\n[...]\n\n“All right,” said the computer, and settled into silence again.\n\nThe two fidgeted.\n\nThe tension was unbearable.\n\n“Forty-two,” said Deep Thought, with infinite majesty and calm.\n\n“Forty-two!” yelled Loonquawl. “Is that all you’ve got to show for seven and a half million years’ work?”\n\n“I checked it very thoroughly,” said the computer, “and that quite definitely is the answer. I think the problem, to be quite honest with you, is that you’ve never actually known what the question is.”\n\n“But it was the Great Question! The Ultimate Question of Life, the Universe and Everything,” howled Loonquawl.\n\n“Yes,” said Deep Thought with the air of one who suffers fools gladly, “but what actually is it?”\n\nA slow stupefied silence crept over the men as they stared at the computer and then at each other.\n\n“Well, you know, it’s just Everything ... everything ...” offered Phouchg weakly.\n\n“Exactly!” said Deep Thought. “So once you do know what the question actually is, you’ll know what the answer means.”\n\nIn addition to establishing the premise for one of the greatest comedic science fiction novels in human history, I feel this passage perfectly exemplifies the three reasons most data science projects fail.\n\nThe first is our absolute faith that technology will save us. All we have to do to solve any problem is feed it into the newest, shiniest AI/LLM/ML model available. Sure, there may be technical challenges associated with configuring the environment, formatting the data, etc., but fundamentally, all that lies between us and success is putting the problem into technology’s hands.\n\nThe second is that when a data science project fails, it’s rarely because the technology itself failed. Rather, projects usually fail because people failed to ensure that the task they asked their model to accomplish would actually solve their problem. Technology doesn’t care if the task it’s been given is useful to the user. It will do what it has been asked to do — no more and no less. Garbage in, garbage out.\n\nFinally, this passage also gives a nod to the third — and perhaps most important reason — that data science projects fail: data scientists are far too deferential to their stakeholders. In this passage, we can see that Deep Thought recognizes the idiocy of the request it has been given by its stakeholders — Loonqual and Phouchg — but does nothing about it. And to the degree to which we can think of the Deep Thought personality as a stand-in for the data scientist, this is a troubling realistic illustration of how many data science interactions go. The stakeholder says they want something and the (usually younger) data scientist assumes their only responsibility is to ensure the stakeholder’s request is implemented.\n\nBut as discussed in the introduction of this book, your success as a data scientist will always be evaluated in terms of whether you’ve made your stakeholder’s life better. And if doing precisely what they ask does not improve their lives, that’s the only thing that will matter. No one is blaming Deep Thought in this story, but they sure aren’t excited about what it did, either.","type":"content","url":"/solving-the-right-problem#if-you-dont-articulate-the-problem","position":3},{"hierarchy":{"lvl1":"Solving the Right Problem","lvl2":"Articulating and Reframing Your Problem"},"type":"lvl2","url":"/solving-the-right-problem#articulating-and-reframing-your-problem","position":4},{"hierarchy":{"lvl1":"Solving the Right Problem","lvl2":"Articulating and Reframing Your Problem"},"content":"The preceding story gives (an admittedly extreme) example of how things can go wrong when a data science project is not well motivated — in short, large amounts of energy and sweat can go into creating technically impressive results that, in the end, in no way solve a problem or improve the lives of anyone involved.\n\nHow, then, can you avoid that fate? Every problem is different, but here are some strategies to employ when faced with a problem to aid in refinement, reframing, and articulation. As we work through these, we will also work a few examples based on real cases designed to help you get a feel for what this process entails and why it’s so important.","type":"content","url":"/solving-the-right-problem#articulating-and-reframing-your-problem","position":5},{"hierarchy":{"lvl1":"Solving the Right Problem","lvl3":"1. How do you know if you’ve been successful?","lvl2":"Articulating and Reframing Your Problem"},"type":"lvl3","url":"/solving-the-right-problem#id-1-how-do-you-know-if-youve-been-successful","position":6},{"hierarchy":{"lvl1":"Solving the Right Problem","lvl3":"1. How do you know if you’ve been successful?","lvl2":"Articulating and Reframing Your Problem"},"content":"One of the most helpful questions to ask when trying to understand a problem is “how would we know if we’ve successfully solved this problem?” This question is powerful because it abstracts away the question of how you might solve a problem, and instead focuses attention on the goal one is trying to achieve. In other words, the objective of this question is to figure out how you might measure success.\n\nCrucially, the answer to this question shouldn’t be something like “we have a good model for doing X” — that answer has largely just shifted the question to what constitutes “good.” Rather, try to come up with an answer in terms of the metric or behavior that, if observed, would tell you that you’ve been successful.\n\nTo illustrate the potential power of this question, let’s consider an example I’ve encountered in the real world (with some details changed to protect the anonymity of everyone involved).\n\nThe stakeholder is an online auction site for used construction equipment (front loaders, backhoes, etc.). They want to improve the algorithm that suggests prices to people selling equipment, but they’ve realized that while they have good data on how machinery type impacts prices, their algorithm can’t take into account the condition of equipment being listed. So they’ve hired a data science team to train an image classification model on listings to estimate the condition of each listed piece of machinery.\n\nSo: how would you know if you’ve been successful in solving this stakeholder’s problem?\n\nAt first blush, you might say I would know I was successful if I have a model that has high classification accuracy for equipment condition when fed photos of equipment listed in the past.\n\nBut look more carefully, is that really what the stakeholder cares about? No — because “image classification model” is something young data scientists are familiar with, they tend to latch on to it immediately. “Oh, great, image classification! I can do that. Let’s go!”\n\nNo, the problem motivating the stakeholder is that their price suggestion algorithm doesn’t take into account the condition of equipment going up for sale. Given that, you would know your model was successful if the predicted prices from the model were more in line with final sale prices for equipment of all conditions. That’s the actual goal.\n\nYes, an image classification model might allow the stakeholder to estimate equipment condition which could then be used as training data to revise the pricing model. But is that the best approach?\n\nTo train a model that can differentiate construction machinery in good or bad condition, the first thing you’d need to do is have a person go through and label a lot of old listings as being in good or bad condition. And you’d probably need a lot of them — after all, your model would have to be able to differentiate between indicators of wear that are superficial (dirt, superficial rust, and peeling paint) and indicators of wear that are substantial (cracks, patch welds, etc.), and do so on a range of different types of construction equipment. Then you’d use that to train an image classifier, then you’d have to tune and validate that image classifier, then you could use its classifications to improve the pricing model.\n\nAlternatively, you could just (a) have someone label some old listings and use those labels directly to refine the pricing model, and (b) add a drop-down menu that asks people listing equipment to report the condition of their equipment (so that data is available to the pricing model when someone goes to list a product). Congratulations! You’ve just entirely removed image classification from this task.","type":"content","url":"/solving-the-right-problem#id-1-how-do-you-know-if-youve-been-successful","position":7},{"hierarchy":{"lvl1":"Solving the Right Problem","lvl3":"2. Abstract the Problem","lvl2":"Articulating and Reframing Your Problem"},"type":"lvl3","url":"/solving-the-right-problem#id-2-abstract-the-problem","position":8},{"hierarchy":{"lvl1":"Solving the Right Problem","lvl3":"2. Abstract the Problem","lvl2":"Articulating and Reframing Your Problem"},"content":"A second strategy for better understanding a problem is to try to reframe it at a higher level of generality/abstraction. When you do, you may find your thorny problem is actually just a specific example of a more general type of problem, one that people smarter than either of us have already figured out how to solve.\n\nAlternatively, you may realize that you or your stakeholder has (often unknowingly) introduced constraints to the problem that aren’t actually constraints.\n\nPerhaps my favorite example of this phenomenon comes from a talk given by \n\nVincent Warmerdam at PyData 2019.\n\nThe World Food Program (WFP) is a global leader in food aid provision. As Vincent tells the story — which he reports having heard at an Operations Research Conference — the WFP was struggling with an extremely difficult data science problem: how best to get food from the places it was being grown/stored to the people who needed it most. Essentially, the WFP would receive reports of needs from communities facing food insecurity. One community might report a need for bread and beef, while another might request lentils and meat. The WFP would compile these requests and then set about trying to determine the most efficient way to meet these needs.\n\nThis type of logistics problem is an example of a notoriously difficult problem (essentially a version of the Traveling Salesman Problem, which is NP-Complete, if that means anything to you) that companies like FedEx and UPS buy supercomputers to address. But this particular problem was made extra challenging by all the different types of food the WFP was trying to provide communities.\n\nWhat the WFP realized was that they didn’t actually need to provide bread to the village asking for bread. See, humans don’t need bread to avoid starvation — they need a certain number of calories, a certain amount of protein, and a handful of other nutrients. So when a village asks for bread, rice, or wheat, you can instead think of them asking for carbohydrates. And a village asking for beef or beans is actually asking for protein and iron. So by simply abstracting the task from “How best can we meet all these food requests?” to “How best can we meet the nutritional needs indicated by these requests?” the WFP was able to dramatically reduce the number of constraints being imposed on the logistical optimization problem WFP needed to solve, making its task far simpler.\n\nHow far should you abstract things? To the level that feels most useful. Yes, in the private sector you can abstract almost any problem to “how do we maximize the lifetime discounted profits of the company,” but I don’t think it would be controversial to say that that formulation is not particularly useful if you’re trying to pick the best box sizes for your company to stock for online orders. But there’s also no real cost to thinking about your problem at that level of generality for a little while, so my advice would be: if you haven’t gotten to a level of abstraction that feels silly, you probably haven’t abstracted enough.","type":"content","url":"/solving-the-right-problem#id-2-abstract-the-problem","position":9},{"hierarchy":{"lvl1":"Solving the Right Problem","lvl3":"3. Let Your Articulation Change","lvl2":"Articulating and Reframing Your Problem"},"type":"lvl3","url":"/solving-the-right-problem#id-3-let-your-articulation-change","position":10},{"hierarchy":{"lvl1":"Solving the Right Problem","lvl3":"3. Let Your Articulation Change","lvl2":"Articulating and Reframing Your Problem"},"content":"My last suggestion is to allow your understanding of the problem you are trying to solve evolve. As your project develops, you will learn new things about your problem context, and you should allow those to inform how you are thinking of your problem. This is true not only for you — the data scientist — but also your stakeholder. We’ll discuss stakeholder management more in our next chapter, but you should regularly be asking them: “does the way we’ve articulated the problem we’re trying to solve still feel right to you given everything we’ve learned?”\n\nYes, I recognize that it is wildly indulgent to open a chapter with such a long epigraph. But it’s my book, and if there’s anything to be indulgent about its quotes from Hitchhiker’s Guide to the Galaxy, damn it!\n\nNot least for being the only 5-book trilogy of which I am aware!\n\nAs I understand it, calcium, iron, vitamins A, B1, B2, C, and niacin.","type":"content","url":"/solving-the-right-problem#id-3-let-your-articulation-change","position":11},{"hierarchy":{"lvl1":"Solving The Wrong Problem: Examples"},"type":"lvl1","url":"/solving-the-wrong-problem","position":0},{"hierarchy":{"lvl1":"Solving The Wrong Problem: Examples"},"content":"In the last section, we discussed why understanding your problem is so important, reasons data scientists often fail to do so, and a few suggestions for ways to improve your understanding of the problem you are trying to solve.\n\nIn this section, we will work a longer example to illustrate what “getting the problem wrong, then adapting and getting it right” looks like in practice.","type":"content","url":"/solving-the-wrong-problem","position":1},{"hierarchy":{"lvl1":"Solving The Wrong Problem: Examples","lvl2":"Pizza Ltd. Advertising"},"type":"lvl2","url":"/solving-the-wrong-problem#pizza-ltd-advertising","position":2},{"hierarchy":{"lvl1":"Solving The Wrong Problem: Examples","lvl2":"Pizza Ltd. Advertising"},"content":"Pizza Ltd. is a (fictitious) pizza delivery chain interested in improving their online sales. Last year they increased their online advertising budget three-fold, but saw almost no change in their online sales, despite increasing in-store sales.\n\nYou have been hired to help improve the effectiveness of their advertising. Pizza Ltd. provides you with data on their previous advertising campaigns, including information on ad impressions and clicks broken down by user demographics, geography, and past interactions with Pizza Ltd.\n\n“Well,” you reason, “maybe the problem is that Pizza Ltd’s ads aren’t being shown to the right people. After all, it seems unlikely that any ad for pizza—no matter how appealing—is likely to draw a click if it’s shown to a 75-year-old at 7 am.” And sure enough, the data provided by Pizza Ltd shows that they are not doing a lot of ad targeting — their ads are being shown to an extremely diverse set of users, including many who probably aren’t that interested in pizza!\n\nUsing the data provided, you train a model to answer the question, “given a user’s demographics and online behavior, how likely are they to click on a Pizza Ltd. ad?” You try out a few different models, tune the model parameters, and eventually settle on a neural network model with extremely high precision and recall. Hooray!\n\nAs expected, the model shows that Pizza Ltd. was showing too many ads to people who were probably not even that interested in pizza, when they should have been targeting people who have ordered pizza from Pizza Ltd in the past, people searching for “Pizza Ltd,” and people who live close to Pizza Ltd locations.\n\nYou hand over your model to Pizza Ltd, who immediately reallocate their ads based on their models. Within a week, Pizza Ltd. sees that the share of ad impressions that result in clicks and pizza purchases has increased five-fold. Everyone congratulates you, and you move on to the next project feeling very smug.","type":"content","url":"/solving-the-wrong-problem#pizza-ltd-advertising","position":3},{"hierarchy":{"lvl1":"Solving The Wrong Problem: Examples","lvl3":"The Other Shoe Drops","lvl2":"Pizza Ltd. Advertising"},"type":"lvl3","url":"/solving-the-wrong-problem#the-other-shoe-drops","position":4},{"hierarchy":{"lvl1":"Solving The Wrong Problem: Examples","lvl3":"The Other Shoe Drops","lvl2":"Pizza Ltd. Advertising"},"content":"A few months later, you are called into a meeting with the Pizza ltd advertising team, online sales team, and the company’s Chief Financial Officer (CFO). They’ve been looking over the numbers, and despite the huge rise in ad clicks, ad clicks per impression, ad clicks per dollar spent, and clicks that result in sales, when they crunch their quarterly sale numbers they find that, to their surprise, overall online sales haven’t risen at all. Moreover, in-store sales are stable, searches for Pizza Ltd. haven’t declined, and social media sentiment and posting rates all seem stable, suggesting the fact overall sales haven’t risen isn’t related to a decline in overall demand.\n\nSo, what went wrong?\n\nOK, this is the place in most books where the authors ask you that question, and you look up at the ceiling for a minute, shrug, and then read on.\n\nBut I’m really, really serious about this: close your laptop, stand up, set a 5-minute timer on your phone, and go for a walk. Ponder this example. See if you can figure out what’s going on. This is precisely the kind of problem you will soon face as a professional data scientist, so why not practice trying to think through the problem?","type":"content","url":"/solving-the-wrong-problem#the-other-shoe-drops","position":5},{"hierarchy":{"lvl1":"Solving The Wrong Problem: Examples","lvl3":"Using Our Problem Refinement Skills","lvl2":"Pizza Ltd. Advertising"},"type":"lvl3","url":"/solving-the-wrong-problem#using-our-problem-refinement-skills","position":6},{"hierarchy":{"lvl1":"Solving The Wrong Problem: Examples","lvl3":"Using Our Problem Refinement Skills","lvl2":"Pizza Ltd. Advertising"},"content":"To help us work through this problem, let’s begin by asking the questions we learned in our last reading.\n\nFirst, how will we know if we’re successful? Implicitly, we were assuming that we would know we were successful if the number of impressions that resulted in clicks rose. But as is clear from the concerns raised by Pizza Ltd’s advertising team, online sales team, and CFO, the fact that clicks rose did not indicate success.\n\nWhat would indicate success? As indicated by both the problem statement at the top of this example and by the description of the concerns raised by the Pizza Ltd. CFO, we would know we were successful if we saw an increase in online sales.\n\nOK, but... we got people to click the ads, right? We show ads, we hope people click. And we did a great job of figuring out how to show the ads to people who would click the ads! How is this our fault?\n\nWell, was our problem that not enough people were clicking the ads? What is the goal of an advertisement — online or in the real world? Is it to be clicked on?\n\nNo — often clicking on an ad is an indicator the ad has worked, but in focusing on that immediate (and easy to measure) outcome, we’re missing the point of ads. So let’s abstract our idea of what we’re trying to accomplish. Are we trying to get people who see one of our ads online to click on that ad? No. Are we trying to get people who see one of our ads online to click that ad and buy a pizza? Closer, but still no.\n\nNo, let’s get away from all the specifics of clicks, and clicks that convert into sales. Those are specifics that are distracting us. Fully abstracted and generalized, our problem is that we don’t know how to deploy our ads to increase online sales.\n\nAnd the way to increase sales is to show the ads to the people whose likelihood of buying a pizza will increase the most as a result of seeing the ad. In other words, we want to show our ads to the people on whom they will have the largest effect on the likelihood of buying a pizza.\n\nHow is this different from maximizing clicks or clicks that turn into sales? Simple — consider a person who has already decided to buy a pizza from Pizza Ltd. If they happen to see an ad on their way to buying their pizza, they may click on it to save a few dollars (if there’s a coupon in the ad) or a few keystrokes (have you ever typed the name of a company into google and clicked the top link to get to their homepage — a link that was actually an ad the company paid for?).\n\nEven though that customer clicked the ad, and even though that user bought a pizza, the ad didn’t cause them to buy a pizza. In fact, the ad had no effect on the likelihood they’d buy a pizza. And if the ad included a coupon, then not only has the ad not increased online sales, but it’s reduced profits from the sale because of the coupon and you had to pay for that ad impression and click!\n\nEven though this is not someone you want to show an ad too, however, this is precisely the type of user that a naive model designed to target the people most likely to click an ad would suggest targeting. Not because the statistical model did the wrong thing, but because in answering the question you asked it to answer — “what kind of users are most likely to click on a Pizza Ltd. ad?” — wasn’t a question whose answer helped solve your problem.","type":"content","url":"/solving-the-wrong-problem#using-our-problem-refinement-skills","position":7},{"hierarchy":{"lvl1":"Solving The Wrong Problem: Examples","lvl2":"Counter-Factual Advertising"},"type":"lvl2","url":"/solving-the-wrong-problem#counter-factual-advertising","position":8},{"hierarchy":{"lvl1":"Solving The Wrong Problem: Examples","lvl2":"Counter-Factual Advertising"},"content":"So how should Pizza Ltd. have approached solving their problem? The answer — as we’ll explore in detail in later readings — is that they should have run an A/B experiment. Track a group of users, and show a random subset of those users a Pizza Ltd. ad. Then measure the effect of the ads by comparing online purchase rates between the group that saw ads and the group that didn’t.\n\nThis data can then be used to improve targeting by looking at the difference in purchase rates between the group that saw the ad and the group that didn’t for different demographic sub-populations (younger users, men versus women, users in different geographic areas, etc.). And of course this strategy can also be used to test different ads to figure out what ad is most effective.\n\nThis idea — that the goal of ads is to have an effect on consumer purchase behavior, not to be clicked on — is often referred to as “counter-factual advertising,” and it’s the basis for how nearly all major advertising platforms work today.\n\nIt’s also why companies like Meta and Google are so eager to track user behavior across apps and websites. To demonstrate the effectiveness of ads, these companies need to be able to not only track users after they click an ad (to see whether they eventually make a purchase), but also track users who haven’t seen an ad (so they can establish a behavioral baseline for the “control” group of users who haven’t seen an ad). This allows these companies to estimate the true effect of ads on sales, data they use to improve ad targeting and justify higher prices to advertisers. I could do something on outlier detection — is the goal to detect in training data, or create a tool that can quickly adapt/be tuned by users? \n\nTo be clear, I’m not saying that paying for ads at the top of Google for the name of one’s own company are always a bad idea — they may prevent a competitor pizza chain from buying that spot and convincing the searcher to change their plans and order from the competitor instead. Basically, these ads sometimes amount to paying Google to not sell your business to someone else. But that’s a nuance that’s mostly a distraction at this point.\n\nIf you’ve taken any causal inference courses, you’re reconize that while I’m describing is an “always-taker” — someone who is going to engage in a behavior regardless of whether they are subject to a treatment of interest (here, encountering an ad) or not.\n\nI’m not sure of the first citation for this idea in relation to online advertising, but \n\nthis is one well-cited early paper on the topic.","type":"content","url":"/solving-the-wrong-problem#counter-factual-advertising","position":9},{"hierarchy":{"lvl1":"Stakeholder Management"},"type":"lvl1","url":"/stakeholder-management","position":0},{"hierarchy":{"lvl1":"Stakeholder Management"},"content":"stuff","type":"content","url":"/stakeholder-management","position":1},{"hierarchy":{"lvl1":"Stakeholder Management","lvl3":"Step 0: Recognize Your Role"},"type":"lvl3","url":"/stakeholder-management#step-0-recognize-your-role","position":2},{"hierarchy":{"lvl1":"Stakeholder Management","lvl3":"Step 0: Recognize Your Role"},"content":"If you remember nothing else from this chapter, please remember this: helping your stakeholder better understand their problem is a core part of the job.\n\nBecause most stakeholders are older and domain experts in their field, young data scientists tend to err on the side of deference. It is important to be respectful of your stakeholder’s experience and to use their domain expertise, but it is important to also recognize that data science is about pairing domain expertise with computational methods and quantitative insights, and neither you nor your stakeholder is likely to have expertise in both the substantive domain in question and cutting edge quantitative methods. Indeed, if they did, they probably wouldn’t be hiring you! So don’t hesitate to speak up! Ask questions, raise concerns, and while you should do so with some humility, have confidence in your own expertise.","type":"content","url":"/stakeholder-management#step-0-recognize-your-role","position":3},{"hierarchy":{"lvl1":"Stakeholder Management","lvl3":"Step 1: Don’t Assume Your Stakeholder Knows What They Need"},"type":"lvl3","url":"/stakeholder-management#step-1-dont-assume-your-stakeholder-knows-what-they-need","position":4},{"hierarchy":{"lvl1":"Stakeholder Management","lvl3":"Step 1: Don’t Assume Your Stakeholder Knows What They Need"},"content":"A corollary to Step 0 is to not assume your stakeholder understands what they need. So when I say “helping your stakeholder understand their problem is a core part of the job,” I don’t only mean that it’s part of your job if the stakeholder admits to deep uncertainty about their problem.\" Odds are your stakeholder will come to you with a strong statement of what they think they want, but you should take that as a starting point for discussion, not your mandate.\n\nThis is particularly true if your stakeholder comes to you with really specific technical suggestions. Often you will be approached by a stakeholder who, rather than laying out a problem, announces they would like you to do X using some data science tool Y. Occasionally the stakeholder doing this knows exactly what they’re talking about, and you should use Y to do X.\n\nMore often, however, you’re dealing with a stakeholder with just enough knowledge to be dangerous (and to drop buzzwords), but not enough to know how best to solve their problem.\n\nMost people ask data scientists for help because they don’t know much about data science (or, worse, they think they know about data science but don’t). Again, different rules apply if you’re at Google or Apple, but in most contexts, it’s a good idea to treat implementation details provided by the client as a red herring. Focus on the stakeholder’s needs. Only get into implementation details once you feel you understand the problem well.\n\nFocus on the stakeholder’s needs. Only get into implementation details once you feel you understand the problem well.","type":"content","url":"/stakeholder-management#step-1-dont-assume-your-stakeholder-knows-what-they-need","position":5},{"hierarchy":{"lvl1":"Stakeholder Management","lvl3":"Step 3: Ask Questions (Especially Quantitative Ones!)"},"type":"lvl3","url":"/stakeholder-management#step-3-ask-questions-especially-quantitative-ones","position":6},{"hierarchy":{"lvl1":"Stakeholder Management","lvl3":"Step 3: Ask Questions (Especially Quantitative Ones!)"},"content":"Be sure to ask a lot of questions of your stakeholder. In particular, I would suggest two types: questions about what success would look like, and questions about the problem itself.","type":"content","url":"/stakeholder-management#step-3-ask-questions-especially-quantitative-ones","position":7},{"hierarchy":{"lvl1":"Stakeholder Management","lvl4":"Questions About Success","lvl3":"Step 3: Ask Questions (Especially Quantitative Ones!)"},"type":"lvl4","url":"/stakeholder-management#questions-about-success","position":8},{"hierarchy":{"lvl1":"Stakeholder Management","lvl4":"Questions About Success","lvl3":"Step 3: Ask Questions (Especially Quantitative Ones!)"},"content":"Getting a sense of where the goalposts are for your stakeholder will both help you know what to target and also help you better understand your stakeholder’s understanding of the problem. Make sure to ask questions like:\n\nHow are you measuring the problem? What would you measure to help you know if you were successful in solving the problem?\n\nHow big, in quantitative terms, is this problem?\n\nHow much would you need the current situation to change to call this a success?","type":"content","url":"/stakeholder-management#questions-about-success","position":9},{"hierarchy":{"lvl1":"Stakeholder Management","lvl4":"Questions About the Problem","lvl3":"Step 3: Ask Questions (Especially Quantitative Ones!)"},"type":"lvl4","url":"/stakeholder-management#questions-about-the-problem","position":10},{"hierarchy":{"lvl1":"Stakeholder Management","lvl4":"Questions About the Problem","lvl3":"Step 3: Ask Questions (Especially Quantitative Ones!)"},"content":"The more you know about your client’s needs the better, so ask anything that comes to mind. If the client can answer your question, it will help you better understand the situation; if the client can’t answer your question you may find that they are suddenly really interested in knowing the answer, and you immediately have some of your first Exploratory Questions to try to resolve.\n\nIn the example of the company that wanted to improve recruitment of high-quality employees in the introduction of this book, I suggested that some of the first exploratory questions you might want to investigate would be things like:\n\nHow many job applications are you receiving when you post a job?\n\nWhat share of your current job applicants are of high quality?\n\nWhat share of employees you try to hire accept your offer?\n\nWhat share of employees you do hire turn out to be successful employees?\n\nThese are all questions that I would ask my stakeholder in one of our first meetings.\n\nStakeholder Meetings\n\nIt is always good to go into meetings with your stakeholder with a clear sense of your objectives — what you hope to communicate, and what information and feedback you need to get before the meeting ends. When your stakeholder is someone you don’t get to meet with regularly, it’s good practice to detail these objectives and provide them — in writing — to your stakeholder in advance of your meeting. This will not only ensure that you and your teammates are on the same page (as you will all have reviewed the document before sending it to your stakeholder), but also ensure that your stakeholder has adequete time to reflect on any questions or issues you wish to raise.\n\nWhen it comes to your first meeting, however, this practice can feel impractical as you may feel so uncertain about the project that you only know the first few questions you want to ask.\n\nBut even in a first meeting, preparation is key. Rather than laying out the new issues you wish to raise and questions you want answered, for a first meeting it’s helpful to write out a full tree of lines of inquiry you may wish to propose. In other words, for every question you wish to pose to your stakeholder, try to anticipate some likely responses they make provide, then write down a few followup questions to ask if they provide one of those responses.\n\nTime with your stakeholder is precious, especially early in a project, make the most of that face time through preparation.","type":"content","url":"/stakeholder-management#questions-about-the-problem","position":11},{"hierarchy":{"lvl1":"Stakeholder Management","lvl3":"Step 4: Propose Questions You Might Answer"},"type":"lvl3","url":"/stakeholder-management#step-4-propose-questions-you-might-answer","position":12},{"hierarchy":{"lvl1":"Stakeholder Management","lvl3":"Step 4: Propose Questions You Might Answer"},"content":"As a data scientist, answering questions about the world is the instrument you have to solve problems. So once you think you have a sense of your stakeholder’s needs, turn around and propose a handful of questions and ask them if answering those questions would help solve their problem.\n\nThis is important because many people have only a vague sense of what they are likely to get as a “deliverable” from the data scientist. They usually have a vague sense that they will get some type of magic machine (a “magic model” or “magic algorithm”) that will just make their problem go away. By concretely framing your deliverable as the answer to a question (or a model that would answer a specific question for each entity like a customer or patient that it encounters), you can get much more valuable feedback before you dive into a problem.","type":"content","url":"/stakeholder-management#step-4-propose-questions-you-might-answer","position":13},{"hierarchy":{"lvl1":"Stakeholder Management","lvl4":"Make Your Questions Specific and Actionable","lvl3":"Step 4: Propose Questions You Might Answer"},"type":"lvl4","url":"/stakeholder-management#make-your-questions-specific-and-actionable","position":14},{"hierarchy":{"lvl1":"Stakeholder Management","lvl4":"Make Your Questions Specific and Actionable","lvl3":"Step 4: Propose Questions You Might Answer"},"content":"In developing your questions, it is important to make them specific and actionable. A specific and actionable question makes it very clear what you need to do next. For example, suppose an international aid organization told you they were worried that urbanization in Africa, Asia, and Latin America was impacting efforts to reduce infant mortality. Some examples of specific, actionable questions are: “Is infant mortality higher among recent migrants to urban centers, controlling for income?” or “Are the causes of infant mortality among recent migrants to urban centers different from those living in rural areas?” Reading those questions, you can probably immediately think of what data you’d need to collect, and what regressions you’d want to run to generate answers to those questions.\n\nVague questions would be “Is urbanization impacting efforts to reduce infant mortality?”, or “Does urbanization affect infant mortality?” Note that when you read these, they don’t seem to obviously imply a way forward.\n\nPerhaps the best way to figure out if your question is answerable is to write down what an answer to your question would look like. Seriously -- try it. Can you write down, on a piece of paper, the graph, regression table, or machine learning diagnostic statistics (complete with labels on your axes, names for variables, etc.) that would constitute an answer to your question? If not, it’s probably too vague.","type":"content","url":"/stakeholder-management#make-your-questions-specific-and-actionable","position":15},{"hierarchy":{"lvl1":"Stakeholder Management","lvl3":"Step 5: Iterate"},"type":"lvl3","url":"/stakeholder-management#step-5-iterate","position":16},{"hierarchy":{"lvl1":"Stakeholder Management","lvl3":"Step 5: Iterate"},"content":"And here’s the last but perhaps most important step: iterate. Bring your work back to your stakeholder as often as possible.\n\nMany stakeholders find the idea of data science mysterious and abstract and will struggle to understand what is and is not feasible. By bringing them intermediate results, the whole process will start to become more concrete for the stakeholder, and it will help them provide you with better feedback.\n\nThe way this book is organized suggests a natural flow from problem articulation to answering Exploratory Questions to prioritize efforts, to answering Passive-Prediction Questions to target individuals for extra attention or automate tasks, and finally to Causal Questions to better understand the effects of that extra attention/automation. In reality, however, a good data scientist is always coming back to the stakeholder, updating their plan, and jumping back in the sequence when new questions arise.","type":"content","url":"/stakeholder-management#step-5-iterate","position":17},{"hierarchy":{"lvl1":"Stakeholder Management","lvl2":"Reading Reflection Questions"},"type":"lvl2","url":"/stakeholder-management#reading-reflection-questions","position":18},{"hierarchy":{"lvl1":"Stakeholder Management","lvl2":"Reading Reflection Questions"},"content":"Why should you care if your stakeholder misspecifies their problem?\n\nObviously there are exceptions to this — if you work for a mature tech company like Google or Meta, you may very well end up working under a manager who knows sides of a problem significantly better than you. In my experience, however, is circumstance is the exception, not the rule.","type":"content","url":"/stakeholder-management#reading-reflection-questions","position":19},{"hierarchy":{"lvl1":"Descriptive v. Prescriptive Questions"},"type":"lvl1","url":"/descriptive-v-prescriptive","position":0},{"hierarchy":{"lvl1":"Descriptive v. Prescriptive Questions"},"content":"In the chapters that follow, we will discuss Exploratory, Passive-Prediction and Causal in detail. First, though, we must discuss another important concept: the distinction between descriptive and prescriptive questions.\n\nDescriptive Questions are questions about the state of the world and include all the questions and examples we’ve covered so far in this book. “What kinds of users are clicking our ads?” and “Do high-income and low-income countries emit similar amounts of carbon dioxide?” are examples of Descriptive Questions. And because Descriptive Questions are questions about objective reality, they have right and wrong answers (at least in principle. It may be hard to evaluate whether a given attempt to calculate the answer is actually right or wrong).\n\nBut Descriptive Questions are not the only type of question you will come across in your career.\n\nPrescriptive Questions are questions about how the world should be, not how it actually is. “Should higher income and lower income countries be expected to meet the same carbon emission reduction standards?” or “Do high-income countries have a moral obligation to provide tuberculosis drugs to developing countries for free (or at cost)?” are both examples of Prescriptive Questions.\n\nUnlike Descriptive Questions, Prescriptive Questions don’t have correct answers. That’s because answers to Prescriptive Questions require evaluating the desirability of possible outcomes, which can only be done in the context of a moral/ethical system of values. And as there is no “correct” system of values (in the sense that there is no single universally accepted system of morality), there can be no right or wrong answers to Prescriptive Questions, even in principle.\n\nNote\n\nThe terms “Prescriptive” and “Descriptive” are commonly used for these concepts in the natural sciences, but different academic silos sometimes use different terms. Social scientists, for example, tend to prefer the terms “Positive” in place of Descriptive and “Normative” instead of Prescriptive. These are only difference in nomenclature, however, not substantive meaning.\n\nThe focus of this book is on Descriptive Questions. This is not because Prescriptive Questions are unimportant — indeed, one can easily make the argument that they are more important than Descriptive Questions. Moreover, as we will discuss in future chapters, they will arise frequently in your career as a data scientist. No, the reason that Descriptive Questions are the focus of this book is that those are the only questions data science tools can answer, and thus answering Descriptive Questions is the domain in which the data scientist has a clear comparative advantage.\n\nNow, to be clear, none of this is to mean that the answers you generate as a data scientist will not have a bearing on how people answer Prescriptive Questions. Data science would be a very dull field indeed if it could not speak to the ethical issues of our day. Data science is powerful precisely because it can inform how we answer Prescriptive Questions by helping us understand the relevant stakes. Data science tools can help decision-makers understand the likely consequences of different courses of action, information that can help people make informed decisions about what outcomes they feel are most desirable. To illustrate, let’s consider a few vignettes.","type":"content","url":"/descriptive-v-prescriptive","position":1},{"hierarchy":{"lvl1":"Descriptive v. Prescriptive Questions","lvl2":"Opioid Reductions"},"type":"lvl2","url":"/descriptive-v-prescriptive#opioid-reductions","position":2},{"hierarchy":{"lvl1":"Descriptive v. Prescriptive Questions","lvl2":"Opioid Reductions"},"content":"Suppose you have been hired by a medical regulatory board concerned about the rise in opioid overdoses. They are debating whether they should (there’s that magic word!) make it harder for patients to get opioids. Fundamentally, however, they worry that while restrictions on opioids may reduce overdoses and addiction, they may also prevent some patients with very real pain conditions from getting the care they need.\n\nWhy are they stuck? Well, there may be two causes:\n\nThey may be unsure of the relative moral weight to give preventing overdoses versus ensuring appropriate patient access to opioids, and/or\n\nthey may also be unsure about how much opioid regulations that reduce overdoses by a certain amount would limit access for patients in need.\n\nThe first of these questions is a pure Prescriptive Question — if you could prevent one overdose death at the expense of preventing 10 patients in pain from getting the opioids they need, would you accept that trade-off?\n\nBut the second is actually a Descriptive Question that you — the data scientist — can answer! You could study policies that have been implemented in the past and come up with a rigorous estimate of how much opioid regulations that reduce overdoses also reduce access for patients in need. You could also evaluate different kinds of policies to figure out which is most efficient — maybe some policies (like not allowing any opioid prescriptions at all) are good at stopping overdose deaths but also really limit appropriate access, while other policies are similarly good at reducing overdoses but have a much smaller effect on limiting access.","type":"content","url":"/descriptive-v-prescriptive#opioid-reductions","position":3},{"hierarchy":{"lvl1":"Descriptive v. Prescriptive Questions","lvl2":"The Example of Carbon Emissions"},"type":"lvl2","url":"/descriptive-v-prescriptive#the-example-of-carbon-emissions","position":4},{"hierarchy":{"lvl1":"Descriptive v. Prescriptive Questions","lvl2":"The Example of Carbon Emissions"},"content":"A profoundly difficult Prescriptive Question in debates over carbon reduction is whether developing countries should be held to the same emission reduction targets as more developed countries. On the one hand, developing countries like China and India are the source of most current growth in carbon emissions, and so policies that do not apply to developing countries are unlikely to prevent many of the worst climate change outcomes. On the other hand, these countries produce radically less carbon per capita than Europe or the United States, and the industrial growth creating those emissions has been a major factor in lifting billions of people out of extreme poverty.\n\nHard choices indeed! How does one weigh the improvements in the quality of life of those in extreme poverty against the possible consequences of even greater climate catastrophes?\n\nWhile that question, in part, is a Prescriptive Question that no regression can answer, data scientists can bring data to bear on this question indirectly by helping everyone understand the potential consequences of different carbon targets for developing countries, as well as the feasibility of different strategies for carbon reduction. A data scientist could, for example:\n\nEvaluate the effectiveness of different messages politicians in the US and Europe could use to convince their constituents to support greater carbon reduction targets,\n\nQuantify the magnitude of the effect on global warming caused by different emissions targets for developing countries to help politicians in developing countries weigh the poverty-reducing benefits of carbon-intensive industrialization against the likely direct effect of flooding, droughts, or more severe storms on their own citizens, or\n\nEstimate the cost-effectiveness of developed countries sharing lower emissions industrial technologies with developing countries to ameliorate the tradeoff between poverty reduction and emissions.\n\nIn each of these cases, the data scientist is only answering Descriptive Questions, but in doing so they are helping everyone better understand the consequences of their decisions, and in doing so (hopefully) help the world to make more informed decisions about the trade-offs they are making.","type":"content","url":"/descriptive-v-prescriptive#the-example-of-carbon-emissions","position":5},{"hierarchy":{"lvl1":"Descriptive v. Prescriptive Questions","lvl2":"Recap"},"type":"lvl2","url":"/descriptive-v-prescriptive#recap","position":6},{"hierarchy":{"lvl1":"Descriptive v. Prescriptive Questions","lvl2":"Recap"},"content":"Answering Descriptive Questions — questions about how the world is or would be in different scenarios — is the core competency of the data scientist. In the chapters that follow, we will explore in detail three different kinds of Descriptive Questions: Exploratory, Passive-Prediction, and Causal Questions.\n\nWhile these are the only types of questions that data science tools can answer directly, it is important for you, the data scientist, to also recognize when you encounter Prescriptive Questions — that is, questions about how the world should be, or what we ought to do. These questions can only be answered with respect to a system of values, and as such, do not have right or wrong answers, and cannot be answered by statistical means. Nevertheless, as a data scientist, you are well-prepared to help others (and yourself!) make more informed choices when they decide how to answer Prescriptive Questions for themselves.\n\nIf you know enough epistemology to object to me asserting the existence of an “objective reality,” then I assume you can also understand the point I’m trying to get across in this chapter and will forgive me this philosophical slight.","type":"content","url":"/descriptive-v-prescriptive#recap","position":7},{"hierarchy":{"lvl1":"EDA: The Most Pernicious Term in Data Science"},"type":"lvl1","url":"/eda","position":0},{"hierarchy":{"lvl1":"EDA: The Most Pernicious Term in Data Science"},"content":"In our next reading, we will turn our attention to Exploratory Questions. First, however, it is important to have a candid discussion about what I feel is one of the most problematic concepts in data science education: Exploratory Data Analysis or EDA.\n\nThe problem with the term Exploratory Data Analysis is that, if you asked most data scientists what it means, they probably couldn’t actually give you a straight answer. If you pressed them further, they would probably say something like “when you look at your data before you start fitting your models.”\n\nWhile the idea that data scientists should “get to know their data” before fitting a model is well-meaning (you absolutely should!), the ubiquitous but uncritical use of the term has given young data scientists the sense that the undirected poking at data is worthy of a capitalized three world title, complete with a universally recognized acronym.\n\nThis is problematic because any activity that involves data but lacks a clear motivation is doomed to be unending and unproductive. Data science has emerged precisely because our datasets are far too complex for us to understand directly; indeed, I would argue that the job of a data scientist can be summed up, in part, as a person who identifies meaningful patterns in our data and makes them comprehensible.\n\nBut therein lies the problem — without a clear motivation for why the data scientist is poking at their data, what makes a pattern meaningful is undefined. And without a clear purpose from which a concept of meaningfulness can be derived, there is no end to the ways one can slice and dice the data with no way of knowing when to stop or what is useful.\n\nI would argue that what most people call Exploratory Data Analysis (EDA) can actually be decomposed into three activities.\n\nThe first activity people call EDA is what I call “learning the structure of your dataset” (emphasis on learning about your dataset, not using your data to learn about the world). This consists of answering questions about your dataset like “what constitutes a single observation in this dataset?,” “what variables are included in this dataset?,” “how many observations are there?,” “how are variables coded?,” and “what population is represented in this data?” These are questions about the specific dataset you are working with, not the real world, and answers are likely to be found in the dataset documentation and through basic tools for data introspection.\n\nThe second activity that often falls under the label EDA is what I call “validating your dataset.” It’s a poor data scientist who takes the validity of their data on blind faith, so when faced with a new dataset, one should begin with a few “sanity checks” just to make sure things look reasonable. Does the number of observations seem reasonable given what you know about how the data was collected and who is supposed to be represented in the data? If there are date variables in the data, does their range match what should be in this data? And given the specifics of the data, does the range of variables make sense? For example, if you have data on registered voters 18 and over, you should probably check that the age variable has a minimum value of 18 and a maximum value of something sensible (e.g., not 225).\n\nThe third and final activity people call EDA is... everything one does with the data before they fit a statistical or machine learning model. This is the second major reason that I feel the very concept of EDA has had a pernicious influence on data science — it implicitly devalues anything done with data that doesn’t entail a complicated model as “lesser” or “just a stop on the way towards the “real” analysis,” when nothing could be further from the truth.\n\nThis type of data analysis — looking at summary statistics, calculating distributions of variables, computing tabulations and cross-tabulations of different things to improve one’s understanding of the world — is categorically different from “learning the structure of your data,” because it is inquiry in the service of better understanding the world, not the structure of your dataset. But it is not categorically different analyzing data using statistical models, not just because in many cases generating cross-tabulations or calculating group averages are essentially equivalent to using a statistical method like linear regression, but also because they are both examples of the same enterprise: attempting to answer questions about the world using data in the service of solving problems.\n\nAnd just as one cannot properly fit or tune a model without a clear sense of the question one is seeking to answer and how that answer is meant to be used, nor can one know what cross-tabulations to compute without having a sense of purpose to make clear what constitutes “meaningfulness.”\n\nNote\n\n“But I do EDA all the time without a clear question!” I hear you cry. “Sometimes I just want to see what patterns there are in the data.”\n\nTo you I say: you may not have realized you had questions in mind, but most of your data explorations have been implicitly motivated by a sense of questions you thought might relate to your stakeholder’s problem.\n\nPerhaps you were looking at a store’s retail sales data and decided to see how sales volumes varied by customer age or gender. That may not seem obviously question-motivated, but I put it to you that you had in mind that those are customer demographics to which the store could target advertising or product stocking decisions. And had someone suggested “why don’t you look at how sales volumes vary by customer birth month or whether their name starts with a letter in the first half of the alphabet,” you would have looked at them funny and said “why on Earth would I do that?”\n\nBut the problem with approaching your data with implicit motivations is that (a) it’s hard to reflect on them or evaluate whether they rest on solid assumptions about the stakeholder problem, and (b) without an explicit goal, there’s no way to know when you’ve reached your destination, making it really  easy to get lost in the data.","type":"content","url":"/eda","position":1},{"hierarchy":{"lvl1":"EDA: The Most Pernicious Term in Data Science","lvl2":"Recap"},"type":"lvl2","url":"/eda#recap","position":2},{"hierarchy":{"lvl1":"EDA: The Most Pernicious Term in Data Science","lvl2":"Recap"},"content":"Despite its ubiquity, few data scientists could actually tell you what constitutes Exploratory Data Analysis (EDA). Moreover, some of what people might call EDA in practice — answering questions about the world without complex modeling — should not be called EDA, but rather... well, that’s just data science.\n\nSo in this book, we will acknowledge the important (but distinct!) goal of two purposeful activities often called EDA:\n\nLearning the structure of your dataset (what constitutes a unit of observation, what variables are in the dataset),\n\nValidating your dataset (does the data pass the sniff test? Does it exhibit the basic properties you would expect given what it claims to be?)\n\nBut I will not use the term EDA itself, and when I differentiate between data science enterprises, I will do so by emphasizing differences in the end goals of those activities (answering Exploratory Questions, Passive-Prediction Questions, or Causal Questions), not the methods used to achieve those ends.\n\nIn pandas, this would be things like df.columns to see what variables are in the data, df.info() to get a sense of how data is being represented and the number of rows, and simple tools for tabulating unique values like df[\"first column\"].value_counts().","type":"content","url":"/eda#recap","position":3},{"hierarchy":{"lvl1":"Using Exploratory Questions"},"type":"lvl1","url":"/using-exploratory-questions","position":0},{"hierarchy":{"lvl1":"Using Exploratory Questions"},"content":"The hardest part of a data science project is often properly articulating the problem we wish to solve. That’s because properly specifying a problem requires understanding the problem well enough to state it, and often we call issues “problems” precisely because we don’t really understand them!\n\nEnter Exploratory Questions. Exploratory Questions are questions designed to elicit information about our problem space and aid us in prioritizing our efforts and refining our goals. Exploratory Questions are questions about broader patterns in the world. In their simplest form, they can be answered by simple summary statistics or plots. When more complicated or related to more subtle and contingent patterns, they are likely to be answered through unsupervised machine learning algorithms or the tools of statistical inference, such as regressions and generalized linear models. When used for answering Exploratory Questions, the emphasis of regression or generalized linear models is on what the model coefficients can tell us about how different factors may co-vary in the world. This is distinct from how these same tools may be used to answer Passive-Prediction Questions, however, where the emphasis is on the predicted values these models can generate.\n\nOf the three classes of questions we detail in this book, answering Exploratory Questions often (though not always) requires the least technical sophistication, and as a result, Exploratory Questions often get the least respect. But because of their critical role in improving our understanding of our objectives, learning to ask and answer Exploratory Questions will have a huge influence on your effectiveness as a data scientist.\n\nIn this reading, we will discuss how to use Exploratory Questions to guide your work. Then, in the next reading, we will discuss the challenges inherent to answering Exploratory Questions.","type":"content","url":"/using-exploratory-questions","position":1},{"hierarchy":{"lvl1":"Using Exploratory Questions","lvl2":"Using Exploratory Questions to Prioritize Efforts"},"type":"lvl2","url":"/using-exploratory-questions#using-exploratory-questions-to-prioritize-efforts","position":2},{"hierarchy":{"lvl1":"Using Exploratory Questions","lvl2":"Using Exploratory Questions to Prioritize Efforts"},"content":"Exploratory Questions are questions about the underlying patterns that characterize our world. Given that, answers to Exploratory Questions should make you feel like you understand the contours of the problem you seek to solve better. More than anything else, then, Exploratory Questions help data scientists prioritize their subsequent efforts and investigations.","type":"content","url":"/using-exploratory-questions#using-exploratory-questions-to-prioritize-efforts","position":3},{"hierarchy":{"lvl1":"Using Exploratory Questions","lvl3":"Code Optimization","lvl2":"Using Exploratory Questions to Prioritize Efforts"},"type":"lvl3","url":"/using-exploratory-questions#code-optimization","position":4},{"hierarchy":{"lvl1":"Using Exploratory Questions","lvl3":"Code Optimization","lvl2":"Using Exploratory Questions to Prioritize Efforts"},"content":"If this feels too abstract, let’s use a small example of a problem you’ve probably already come across (and if not, probably should have!) in the classroom to make it more concrete: learning to write performant (i.e., fast) code.\n\nData science is full of computationally intensive tasks that, if approached incorrectly, can leave a data scientist staring at their computer for hours, days, or even weeks (if they allow it). As a result, most data scientists will go through a phase in their development when they start constantly worrying about how to make every line of code they write as fast as possible. They bend over backward to write unnatural, unreadable code to ensure that they aren’t wasting a single CPU clock cycle.\n\nThe problem with this is that humans have incredibly bad intuition about what tasks take a computer a long time. It turns out that even in programs that take huge amounts of time to run, it is often the case that most of the program’s runtime is taken up by a single function or loop. As a result, programmers who fixate on ensuring every line of code they write is optimized for speed end up not only wasting their own time, but also writing code that is less natural, harder to maintain, and more likely to contain errors for effectively no benefit.\n\nIndeed, no less a figure than \n\nDonald Knuth, one of the greatest programmers in history and author of the famous \n\nThe Art of Computer Programming, famously said of this trying to optimize each line of code at the time it is being written (“premature optimization”):\n\nThe real problem is that programmers have spent far too much time worrying about efficiency in the wrong places and at the wrong times; premature optimization is the root of all evil (or at least most of it) in programming. [emphasis added]\n\nSo what is a programmer interested in performance to do? First, write code in as natural a way as possible. Then, if the result is code that is slower than they would like, ask the exploratory question: “What lines of code are contributing most to this program taking so long to run?” And only then, once the programmer has identified the problematic parts of their code, optimize it for performance.\n\nHow is this question answered accomplished? Programmers use tools called profilers that dip into a running program every few milliseconds to see what functions are currently running. Then after the program has finished running, it reports how often each part of the program code was found to be running, giving the user a sense of the overall distribution of time spent running different parts of the code.","type":"content","url":"/using-exploratory-questions#code-optimization","position":5},{"hierarchy":{"lvl1":"Using Exploratory Questions","lvl3":"Picking the Right Target","lvl2":"Using Exploratory Questions to Prioritize Efforts"},"type":"lvl3","url":"/using-exploratory-questions#picking-the-right-target","position":6},{"hierarchy":{"lvl1":"Using Exploratory Questions","lvl3":"Picking the Right Target","lvl2":"Using Exploratory Questions to Prioritize Efforts"},"content":"If the preceding example feels too niche — you want to be a data scientist, after all, not a software engineer! — let’s consider a different example. Suppose you’ve been hired by a new non-profit interested in helping reduce energy use in buildings in the United States. They know that fixed structures (factors, stores, houses, etc.) are responsible for a huge share of US energy consumption, and are interested in figuring out how to drive down that energy use by helping building owners improve the energy efficiency of their buildings (by providing information on things like government subsidies for efficiency improvements and the potential value of energy efficient windows, better heating and cooling, etc.).\n\nYou could start out by trying to build a fancy supervised machine learning model that tried to predict the energy use of every building in the US based on infrared satellite data and weather information. Indeed, that may even be what you were asked to do! (See our discussion of how \n\nstakeholders will often have somewhat wild ideas of what is feasible and what would help most.).\n\nBut given this is a new non-profit, it sounds like their real need is probably to figure out how to target their efforts to be most effective. So maybe we should step back and start by trying to answer a few Exploratory Questions that would help the organization decide where to focus its attention:\n\nWhat type of buildings (industrial, residential, commercial) consume the most power in the US?\n\nThe answer to this question can help you prioritize the types of buildings on which to focus your efforts. For example, if industrial or commercial buildings only represent a few percent of all energy consumed by buildings, you don’t need to worry about addressing their needs!\n\nIn what region of the US are buildings consuming the most power?\n\nIf most energy is being consumed in a specific area, perhaps the non-profit should start by focusing its efforts regionally.\n\nIs there a region of the US where buildings are generating the most CO2?\n\nNot all power is created equal when it comes to climate change! Maybe buildings in California consume a lot of energy, but because they have cleaner power plants, those buildings are indirectly generating less CO2 than those in states in the US South?\n\nDoes the average energy use per building vary by region or building type?\n\nIf the non-profit plans to approach building owners, it may be easier to have an impact working with a few owners of large buildings than lots of residential homeowners. But of course, that also depends on the answer to our previous question about what types of buildings are using the most power/generating the most CO2!\n\nIn what season is most building energy consumed? Is more energy consumed by heating or AC needs, or do the two use similar amounts of power?\n\nAgain, this may impact both the regions the non-profit may wish to focus on, and also the types of efficiency retrofits they may wish to prioritize.\n\nWhere is power most expensive?\n\nBuilding owners are most likely to be interested in efficiency retrofits when power is expensive.\n\nWhile answering these questions is likely to require some significant detective work, and may require some thoughtful data wrangling, none require deeply sophisticated statistical machinery. But that doesn’t mean answering these questions wouldn’t provide huge value to the stakeholder.","type":"content","url":"/using-exploratory-questions#picking-the-right-target","position":7},{"hierarchy":{"lvl1":"Using Exploratory Questions","lvl3":"Collecting, Merging, and Creating New Data","lvl2":"Using Exploratory Questions to Prioritize Efforts"},"type":"lvl3","url":"/using-exploratory-questions#collecting-merging-and-creating-new-data","position":8},{"hierarchy":{"lvl1":"Using Exploratory Questions","lvl3":"Collecting, Merging, and Creating New Data","lvl2":"Using Exploratory Questions to Prioritize Efforts"},"content":"Once you start articulating these questions, you can start to see that there is some important data science to do; that’s because the answers to these questions may not all point in the same direction, and so the non-profit likely needs someone to be able to evaluate how these different factors co-vary, and the relative magnitude of different trade-offs (e.g., if fewer buildings use a lot of power in the US South than California, but the US South is using coal power instead of renewable energy, where should the non-profit focus?).\n\nAnd that, fundamentally, is what Exploratory Questions are about: understanding the patterns and distribution of features you care about in the world, and using that information to better understand the problem you want to solve.\n\nThis also demonstrates one of the key ways that one answers Exploratory Questions: by collecting and merging datasets that had not previously been pulled together. Sometimes this data collection requires no more than finding people who already have the data you need, getting it, and finding a way to merge different data sources (e.g., data on power plant CO2 emissions and data on building energy use), while in other situations this will entail building new datasets yourself by doing things like using Natural Language Processing to make collections of documents (contracts, patient files, public records) analyzable systematically.","type":"content","url":"/using-exploratory-questions#collecting-merging-and-creating-new-data","position":9},{"hierarchy":{"lvl1":"Using Exploratory Questions","lvl4":"But Where Do I Get Data?","lvl3":"Collecting, Merging, and Creating New Data","lvl2":"Using Exploratory Questions to Prioritize Efforts"},"type":"lvl4","url":"/using-exploratory-questions#but-where-do-i-get-data","position":10},{"hierarchy":{"lvl1":"Using Exploratory Questions","lvl4":"But Where Do I Get Data?","lvl3":"Collecting, Merging, and Creating New Data","lvl2":"Using Exploratory Questions to Prioritize Efforts"},"content":"It’s hard to overstate how much data is public these days, but to give you a sense, \n\nhere’s a quick summary of a few terrific sources.","type":"content","url":"/using-exploratory-questions#but-where-do-i-get-data","position":11},{"hierarchy":{"lvl1":"Answering Exploratory Questions"},"type":"lvl1","url":"/answering-exploratory-questions","position":0},{"hierarchy":{"lvl1":"Answering Exploratory Questions"},"content":"In the last reading, we discussed how Exploratory Questions are used by data scientists to help stakeholders better understand their problems and to prioritize subsequent investigations. In this reading, we turn to the questions of what answering Exploratory Questions effectively entails.","type":"content","url":"/answering-exploratory-questions","position":1},{"hierarchy":{"lvl1":"Answering Exploratory Questions","lvl2":"The Three-Part Goal"},"type":"lvl2","url":"/answering-exploratory-questions#the-three-part-goal","position":2},{"hierarchy":{"lvl1":"Answering Exploratory Questions","lvl2":"The Three-Part Goal"},"content":"Whether one uses simple summary statistics (means and medians), plots, or more sophisticated algorithms from the domains of statistical inference and unsupervised machine learning, answering Exploratory Questions always boils down to the same challenge:\n\nCreating (1) understandable summarizations (2) of meaningful patterns in the data, (3) and ensuring they are faithful representations of the data.\n\nWhat is meant by these three components exactly? Let’s take each in turn.","type":"content","url":"/answering-exploratory-questions#the-three-part-goal","position":3},{"hierarchy":{"lvl1":"Answering Exploratory Questions","lvl3":"Understandable Summarizations","lvl2":"The Three-Part Goal"},"type":"lvl3","url":"/answering-exploratory-questions#understandable-summarizations","position":4},{"hierarchy":{"lvl1":"Answering Exploratory Questions","lvl3":"Understandable Summarizations","lvl2":"The Three-Part Goal"},"content":"Creating (1) understandable summarizations (2) of meaningful patterns in the data, (3) and ensuring they are faithful representations of the data.\n\nAnswering Exploratory Questions effectively is all about taking large datasets that, in their raw form, are effectively incomprehensible to humans and summarizing the patterns in that data in a way that can be understood. These summaries of patterns in the data may take many forms — summary statistics, regression coefficients, plots, etc. — but all, when done well, have a similar goal: to represent the salient aspects of data in a way that is accessible to the human mind.\n\nProfessionals from different disciplines often use different terminology to describe this process of summarization. Some like to refer to it as “separating the signal (the thing that’s important) from the noise (all the other variation that doesn’t matter),” others talk about “dimensionality reduction” (basically linear algebra speak for summarization), while still others may talk about “modeling the underlying data generating process that gave rise to the observed data.” Regardless of the terminology one uses, however, these all boil down to the same thing: filtering and discarding the variation the data scientist deems to be irrelevant to make it easier to see and understand the variation deemed important.\n\nThe importance of researcher discretion in deciding what variation to discard as noise and what variation to foreground as “important” is one of the defining challenges of answering Exploratory Questions. Other types of questions — like Passive Prediction Questions — often involve using more mathematically sophisticated modeling tools, and consequently are viewed as more challenging. In my experience, however, learning to understand the stakeholder’s problem context and the variation in a data set well enough to exercise this discretion effectively is actually one of the things young data scientists struggle with most. It requires both good domain knowledge to understand what is meaningful (as we will discuss below), and also for the data scientist to spend a lot of time exploring the data thoughtfully and from different perspectives. This is a hard skill to learn, but with intentionality, patience, and practice, it is a talent that once learned will helps set you apart from the average pytorch-jockey.\n\nSummarizations created to answer Exploratory Questions can differ radically in their ambition. At one end of the spectrum are simple summary statistics, like means, median, and standard deviations. These seek to provide a simple characterization of a single feature of a single variable. Slightly more ambitious are various forms of plots — like histograms (which are substantially richer than the aforementioned summary statistics) or scatter plots and heatmaps (which provide substantial granularity and communicate information about the relationship between different variables). The most ambitious efforts make use of multivariate regressions and unsupervised machine learning algorithms to model what they call the Data Generating Process (DGP) — the actual physical or social processes that gave rise to the data you observe, and which (hopefully) can be represented in a relatively parsimonious manner, much as the relatively simple laws of physics give rise to the orbits of the planets and the complexity of life.\n\nTo illustrate what I mean by trying to deduce something about the data-generating process, suppose you are a medical researcher interested in a poorly understood disease like Chronic Fatigue Syndrome (CFS). It is generally agreed that CFS is more of a label for a constellation of symptoms than an understood physical ailment, and you have a hypothesis that the symptoms of CFS aren’t actually caused by a single biological dysfunction, but rather that multiple distinct biological dysfunctions give rise to similar symptoms that we have mistakenly grouped under this same umbrella term. In other words, you think that the data-generating process that gives rise to patients diagnosed with Chronic Fatigue Syndrome consists of two distinct diseases.\n\nYou’re fortunate enough to have detailed patient data on people diagnosed with the condition, but it’s impossible for you to just look at these gigabytes of thousands of patient records and “see” any meaningful patterns. You need a way to filter out irrelevant data to identify the “signal” of these two conditions. To aid you in this question, you decide to ask “If you were to group patients into two groups so that the patients in each cluster looked as similar as possible, but patients in different clusters looked as dissimilar as possible, how would you group these patients?”\n\nThis, you may recognize, is precisely the question clustering algorithms (a kind of unsupervised machine learning algorithm) are designed to answer! So you apply your clustering algorithm to the patient data and get back a partition of the patients into two distinct groups. This, in and of itself, doesn’t constitute a particularly understandable summarization of your data, but it provides a starting point for trying to investigate diagnostically and biologically relevant differences that exist between these populations. If one cluster included more patients reporting fatigue when doing any exercise, while another cluster reported they felt better when they exercised, but felt a high level of baseline fatigue that didn’t respond to sleep, that might suggest that the data-generating process for these patients was actually driven by two different biological processes. And it gives you a great starting point to prioritize your subsequent investigations into what might explain these differences!","type":"content","url":"/answering-exploratory-questions#understandable-summarizations","position":5},{"hierarchy":{"lvl1":"Answering Exploratory Questions","lvl3":"Meaningful Patterns","lvl2":"The Three-Part Goal"},"type":"lvl3","url":"/answering-exploratory-questions#meaningful-patterns","position":6},{"hierarchy":{"lvl1":"Answering Exploratory Questions","lvl3":"Meaningful Patterns","lvl2":"The Three-Part Goal"},"content":"Creating (1) understandable summarizations (2) of meaningful patterns in the data, (3) and ensuring they are faithful representations of the data.\n\nInherent in creating any summarization is exercising discretion over what variation is relevant (signal) and what variation is not (noise). But just as one person’s trash may be another person’s treasure, so too may one person’s signal be another person’s noise, depending on their goals! Crucially, then, the data scientists’ guiding star when deciding what is important is whether certain variation in the data is meaningful to the stakeholder’s problem.\n\nAs data scientists, we are blessed with an abundance of tools for characterizing different facets of our data. These range from the simple — means, standard deviations, and scatter plots — to the profoundly sophisticated, like clustering algorithms, principal component analyses, and semi-parametric generalized additive models.\n\nRegardless of the specific methods being employed, however, none of these tools can really tell us whether the patterns they identify are meaningful, and that’s because what constitutes a meaningful pattern depends on the problem the stakeholder is seeking to address and the context in which they’re operating.\n\nTo illustrate the importance of context, suppose you are hired by a hospital to learn what can be done to reduce antibiotic-resistant infections. So you grab data on the various bacteria that had been infecting patients and write a web scraper and Natural Language Processing pipeline to systematically summarize all available research on the cause of these antibiotic-resistant bacteria. Your work is amazing, seriously top of the line, and after two months you conclude that in most cases, the cause of antibiotic resistance in the bacteria infecting patients is... the use of antibiotics in livestock.\n\nNow, that analysis may not be wrong — you have properly characterized a pattern in the data — but it isn’t a pattern that’s meaningful to your stakeholder, who has no ability to regulate the livestock industry. That pattern might be meaningful to someone else — like a government regulator — but in this context, with this stakeholder, it just isn’t helpful. The features of the data that are important, in other words, depend on what we may be able to do in response to what we learn. And there’s no summary statistic, information criterion, or divergence metric that can evaluate whether a pattern of this type is meaningful.","type":"content","url":"/answering-exploratory-questions#meaningful-patterns","position":7},{"hierarchy":{"lvl1":"Answering Exploratory Questions","lvl3":"Faithful Representations","lvl2":"The Three-Part Goal"},"type":"lvl3","url":"/answering-exploratory-questions#faithful-representations","position":8},{"hierarchy":{"lvl1":"Answering Exploratory Questions","lvl3":"Faithful Representations","lvl2":"The Three-Part Goal"},"content":"Creating (1) understandable summarizations (2) of meaningful patterns in the data, (3) and ensuring they are faithful representations of the data.\n\nWhat do you means, medians, standard deviations, linear regressions, logistic regressions, generalized additive models (GAMs), singular value decomposition (SVD), principal component analyses (PCAs), clustering algorithms, and anomaly detection algorithms all have in common?\n\nAnswer: unless your dataset is extremely degenerate, you can point any of these tools at your data and they will return a relatively easy-to-understand characterization of the structure of your data.\n\nAt first, that may seem extremely exciting. But if you think about it a little longer you will realize the problem: all of these are designed to give you a relatively understandable summary of radically different properties of your data, and even though they will all provide you with a result, these results can’t all possibly be faithful representations of the dominant patterns in your data.\n\nTo illustrate the point, suppose I told you that in one university math course, the average grade was a B-. You might infer that students were doing pretty well! But now suppose I told you that in a different university math course, 20% of the students had gotten a 0 on the midterm and on the final—you would probably infer something was going seriously wrong in that class. And yet those two statistics could both be true of the same class—the only difference is what patterns in the data I, the data scientist, have decided are meaningful to communicate to you, the reader.\n\nThe example of the math class in which the average grade was a B- and 20% of the students were failing also illustrates one of the great dangers of tools for data summarization: they are so eager to please, they will always provide you with an answer, whether that answer is meaningful or not. I think most readers would agree that learning that the average grade in the class was a B- actually misleads more than it informs (since for the class to have an average grade of 80% and a 20% fail rate, the grade distribution would need to be something like 20% 0’s and 80% 100’s). Indeed, it’s worth emphasizing that while hearing “the average grade is a B-” makes the reader think that most kids are doing ok-ish, the reality is that no one in the class is doing ok-ish! They’re either doing horribly or terrifically!\n\nLess that feel like a contrived example, consider the case of Aimovig, a drug authorized by the FDA in 2018 for treating chronic migraines that was heralded as a “game changer.”\n\nTo get Aimovig authorized, the pharmaceutical companies developing (Amgen and Novartis) had to run a clinical trial in which a random sample of people with chronic migraines was given Aimovig (the treatment group) and a random sample was a placebo (the control group). Patients in the clinical trial self-reported how their migraine frequency changed when in the trial, and the effectiveness of Aimovig was then evaluated by comparing the decrease in self-reported migraines for those taking Aimovig (on average, a decrease of 6-7 migraines a month) to the decrease in self-reported migraines for those taking a placebo (on average, a decrease of 4 migraines a month). This difference of 2-3 migraines a month — called the “Average Treatment Effect” of the trial — was found to be positive and statistically significant, and so the drug was authorized. Indeed, if you see an ad for Aimovig, you’ll probably see the average effect of the drug reported in the same way:\n\nThat’s great! Chronic migraines can be a crippling disability, so any improvement in treatment is exciting. But you would be excused for asking why people were getting so excited about what seems like a relatively small reduction in migraines.\n\nThe answer, as it turns out, is that almost nobody experiences this “average effect.” Instead, most people who take Aimovig see little to no benefit, but some (depending on your criteria, something like 40%) see their migraine frequency fall by 50% or more. Amgen and Novartis don’t yet know how to identify who will benefit and who will not before they try the drug, and we don’t allow drug companies to “move the goalposts” after a clinical trial has already started by changing the way they plan to measure the effectiveness of a drug (for fear they will hunt through the data till they find a spurious correlation that makes it look like the drug works when it really doesn’t), so this average effect remains the only statistic that Amgen and Novartis are allowed to report in their advertising.\n\nBut if you’re a doctor or a patient, it seems clear that this simple average effect — a reduction of 2-3 migraines a month — really does not provide a faithful summary of the underlying variation.","type":"content","url":"/answering-exploratory-questions#faithful-representations","position":9},{"hierarchy":{"lvl1":"Answering Exploratory Questions","lvl3":"But... I Thought Unsupervised Machine Learning Always Found The “Best”","lvl2":"The Three-Part Goal"},"type":"lvl3","url":"/answering-exploratory-questions#but-i-thought-unsupervised-machine-learning-always-found-the-best","position":10},{"hierarchy":{"lvl1":"Answering Exploratory Questions","lvl3":"But... I Thought Unsupervised Machine Learning Always Found The “Best”","lvl2":"The Three-Part Goal"},"content":"“Fine,” I hear you say, “that makes sense for simple summary statistics. Those are computed by simple formulas. But what about unsupervised machine learning algorithms or generalized additive models? Those use numerical optimization to find the best answer!”\n\nWell... yes and no. As you may recall, in the first chapter of the book I posited that all data science algorithms are just fancy tools for answering questions, and even the most sophisticated unsupervised machine learning algorithms are no exception. While it is true that the machinery that underlies these algorithms is much more sophisticated than the formula we use for calculating a variable’s average, it is important to not attribute too much intelligence to these tools.\n\nUnderlying any unsupervised machine learning algorithm is a simple formula that takes as input whatever parameters the algorithm gets to choose (be those factor loads in a PCA model, or the assignment of observations to clusters in a clustering algorithm) and returns as output a single number. Often this number is called “loss,” and the function is called a “loss function,” but occasionally different terminology will be used.\n\nOne way to think of the job of an unsupervised machine learning algorithm is to pick the parameter values that minimize this loss function. A clustering algorithm for example, may try and assign observations to clusters to maximize the similarity of observations within a cluster (say, by minimizing the sum of squared differences between the values of certain variables for all observations within a cluster) while also maximizing the differences between observations in different clusters (say, by maximizing the sum of squared differences between the values of certain variables for all observations not in the same cluster).\n\nBut another way to say that is that the job of an unsupervised machine learning algorithm (or any algorithm, really) is to find the parameter values (coefficients in a regression, observation assignments for a clustering algorithm) that answer the question “If my goal is to minimize [whatever the loss function your specific algorithm seeks to minimize], how should I do it?” But while they are likely to find the best way to accomplish that goal given the parameters they control, they will do so whether or not the “best” solution is actually a “good” solution! Point a clustering algorithm at any data and ask it to split the data into 3 clusters, and it will pick the best way to split the data into three clusters, even if the three clusters are almost indistinguishable. In other words, clustering algorithms assign observations to clusters... even when there’s no real clustering of the data! Dimensionality reduction algorithms will always tell you a way to drop dimensions, and anomaly detection algorithms will always find (relative) outliers.\n\nMoreover, just because your clustering algorithm finds what it thinks is the best solution doesn’t mean there isn’t a substantively very different solution that was just a little less good it hasn’t told you about.\n\nIt’s up to you, the data scientist, to evaluate whether the answers these algorithms provide to relatively myopic questions give a meaningful picture of the data.","type":"content","url":"/answering-exploratory-questions#but-i-thought-unsupervised-machine-learning-always-found-the-best","position":11},{"hierarchy":{"lvl1":"Answering Exploratory Questions","lvl3":"Myopic Tools","lvl2":"The Three-Part Goal"},"type":"lvl3","url":"/answering-exploratory-questions#myopic-tools","position":12},{"hierarchy":{"lvl1":"Answering Exploratory Questions","lvl3":"Myopic Tools","lvl2":"The Three-Part Goal"},"content":"This last point is illustrative of a more general point: data science tools are incredibly powerful at finding answers to questions of the form “If my goal is to minimize X, how should I do it?” type questions — answers you may have never figured out in millions of years! — but their power lies in figuring out the best way to accomplish an articulated goal, not in figuring out what goal to pursue.\n\nThis is true at both the macro level (doesn’t make sense to look for clusters in my data?) and also at the micro level (when assigning observations to clusters, how do I measure success?). Hidden inside nearly all algorithms you use are a handful of baked-in choices you may not even realize are being made for you. Take clustering, for example. In general, when clustering observations, one has two objectives: maximize the similarity of observations within each cluster and maximize the dissimilarity of observations in different clusters. But what you might not have thought about very much is that there’s an inherent tension between these two objectives — after all, the best way to maximize the similarity of observations within each cluster is to only assign observations to the same cluster if they are identical (a choice that creates lots and lots of very small clusters). And the best way to maximize dissimilarity between clusters is to only put really really different observations in different clusters (resulting in a few really big clusters). So how is your clustering algorithm balancing these two considerations? Is the algorithm’s choice of how to balance them in any way a reflection of the balance that makes the most sense in the context of your stakeholder’s problem? (I’ll give you a hint — the algorithm sure can’t answer that question, so you’d better be able to!)\n\nDiscretion: it’s everywhere, and you’re exercising it, whether you realize it or not. \n## Netflix Movie Clusters\n\n![Netflix movie suggestion categories](images/netflix_clusters.jpeg)\n\nNetflix doesn’t just need to figure out what movie you would enjoy watching most; it needs you to understand why the movie is something you were likely to enjoy so you buy into it.  This issue isn't limited to simple summary statistics, though. Unsupervised machine learning algorithms have the same problem—ask a clustering algorithm to divide a dataset into three clusters, and it will, even if the differences between the groups is *very* small. And ask a Principal Component Analysis algorithm to find a vector that minimizes the sum of squared distances between all points and the vector and it will, even if that vector isn't really measuring any kind of central tendency in the data.\n\nAnswering Exploratory Questions will not always entail gathering and merging new sources of data; in some cases, answering Exploratory Questions is about making sense of existing data sets by identifying hidden (latent) patterns. This can be accomplished by a range of tools, but this practice is most commonly associated with *unsupervised machine learning* and statistical inference.\n\nAnswering Exploratory Questions always boils down to the same challenge: taking datasets that aren't comprehensible in their raw form, and identify **meaningful** patterns in the data that can be summarized in a manner that humans can actually wrap their heads around. And why is this hard? Because by definition, answering exploratory questions requires trying to find ways to make the incomprehensible comprehensible by identifying *meaningful* patterns. And while we have many tools for calculating specific types of data summaries—means, medians, clustering algorithms, principal component analyses, etc.—none of these can evaluate whether the summaries they generate are *faithful and meaningful* to the question you are seeking to answer. And it is therefore up to you, the data scientist, to decide what summaries of the data provide a faithful and meaningful representation of the underlying data.  \n## The Danger of the Helpful Computer\n\nWhat do we mean by \"faithful\" summaries? To illustrate, suppose that you have been hired by the US state of Florida to help with a financial problem they're having. They buy a lot of electricity that's generated with natural gas, but as a result, their electricity costs keep bouncing up and down with natural gas prices. As this makes it hard for them to do financial planning, they've asked you to find a financial asset the city can buy that will smooth out these fluctuations. More specifically, they want an asset that will pay out more when natural gas prices are high (so they can use the money to offset their increased electricity costs), and less when natural gas is low.\n\nThey've given you data on four potential assets, and so you run a linear regression looking at the relationship between the value of these assets and natural gas prices. You analyse the data by looking at the correlation between the asset's payout and natural gas prices, and by fitting a linear regression with natural gas prices and asset payouts. You find that all four assets have essentially identical relationships with natural gas prices—a correlation of about 0.8, and a regression coefficient of about 0.5, suggesting that when natural gas prices rise by a dollar, asset payouts will increase by 0.50 dollars. Perfect, right? All four assets would work equally well, and all four could help limit budget fluctuations for Florida!\n\nWell... no. If we dig a little deeper, we see that these summary statistics are not telling us all the meaningful information in the data; our summary statistics are technically *correct*, but they aren't faithfully representing everything that matters given the problem we want to solve.\n\nWe can see this by plotting the data[^anscombesquartet]:\n\n[^anscombesquartet]: Anscombe's quartet. (2022, October 21). [Image from Wikipedia Commons.](https://en.wikipedia.org/wiki/Anscombe%27s_quartet).\n\n![plot of all four regression fits with scatter points](images/anscombes_quartet_naturalgas.png)\n\nClearly, the relationship between these different assets and natural gas prices are *not* all the same! Buying the asset in the top left would likely do a good job of smoothing out the state's budget, but in nearly all years, the asset in the bottom right would be useless for smoothing the state's budget since in most years the asset's payoff doesn't change at all!\n\nThis is obviously a simple example and one where a simple plot is sufficient to allow us to see the problem. But this problem is inherent to answering *any* exploratory question—whether we're calculating simple statistics or using sophisticated unsupervised machine learning techniques; when we summarize data, it is our job as data scientists to ensure that our summaries are representing the *relevant* patterns in the data in a faithful and meaningful manner. And because what is relevant depends on the problem we are trying to solve, it's something we as data scientists have to evaluate, not something an algorithm can do for us.  \n--------\n\n## Unsupervised Machine Learning\n\nIf you are familiar with machine learning techniques already, you are likely most familiar with *supervised machine learning*, in which we tell our algorithms what we want to do by providing lots of examples of the behavior we want them to emulate in a training dataset. For example, if we want a supervised machine learning algorithm to identify pictures that contain dogs, we might give them lots of pictures with and without dogs that include labels for whether there's a dog in each picture. From these examples, the algorithm then learns to emulate the demonstrated behavior.\n\nThe choice of three here is arbitrary, and in practice, one would generally run their clustering algorithm for clusters of 2, 3, 4, etc., and compare the results for patterns that seemed meaningful based on the researchers' medical knowledge.\n\n### Choosing What To Ask and Present\n\nOK... by now you've probably noticed that I've been saying you want to make sure you faithfully represent the \"important\" and \"critical\" properties of your data, but I haven't defined those terms. And here's why: there are no objective definitions of these terms. What is *important* depends both (a) on the context, and (b) on the value system of you (the data scientist) and your stakeholder.\n\n#### Context\n\n#### Values\n\nIn our previous reading, we talked about how some questions *explicitly* invoke our value systems—prescriptive questions, like \"should murders be eligible for parole?,\" or \"is it fair that Americans with more money can donate unlimited amounts of money to Political Action Committees in the United States?\"—while others are ostensibly just questions about objective reality. But now we have to blur that line ever so slightly, because even when dealing with questions about objective reality (descriptive questions), our values come into play. How?\n\nSuppose you are a policymaker choosing between two possible policies for reducing $CO_2$ emissions in the United States. You are told:\n\n- Policy A would reduce $CO_2$ emissions by 95%, have only a minimal impact on unemployment and business profits, and would require a 100 million dollar tax.\n- Policy B would reduce $CO_2$ emissions by only 90%, would have a moderate impact on unemployment and business profits, and would require a 200 million dollar tax.\n\nWhich would you choose?\n\nNow suppose I also told you that the 100 million dollars in taxes from Policy A would come entirely from taxing people who live below the poverty line, while the 200 million dollar tax for Policy B would be collected from all Americans in proportion to their income. Does that change how you see the issue?\n\n**People tend to make decisions based on the information that is available to them,** and so what questions get asked (and what data is thus presented) can have a *huge* impact on how decisions are made. And as a data scientist, you will often be in control of what questions are being asked, and so it is incumbent upon you to ensure that your stakeholders are presented with all the data that *you* feel is important for them to know.\n\nThis is actually one of the big reasons that the lack of diversity in data science is such a problem—it's not that White men are intrinsically misogynistic or racist, but because our life experiences influence what we think is important, and thus what we ask our data (both authors of this book are White men).\n\nConsider this infamous (though thankfully low stakes) illustrative example of a major tech failure (seriously, [go watch the video](https://www.youtube.com/watch?v=t4DT3tQqgRM)): the camera that only sees White people. We can't know exactly what went wrong, but I think it's safe to say that if there were more Black developers working at HP, surely *one of them* would have stopped to ask the question \"does this work as well for Black faces as White faces?\" But no one did, and so this product shipped. But OK, HP isn't a very *good* tech company. A better tech company like Google would never make that mistake. Oh wait... [Google's Photos product tagged photos of dark-skinned people as \"Gorillas\". And how do we know? Yup, because they released that product too.](https://www.theverge.com/2018/1/12/16882408/google-racist-gorillas-photo-recognition-algorithm-ai)\n\nOK, fine, you say—but those are just low-stakes settings. Surely that wouldn't happen when it *counts*. [Cue: facial recognition's differential error rate for men and women, and for people with light versus dark skin tones.](https://sitn.hms.harvard.edu/flash/2020/racial-discrimination-in-face-recognition-technology/) And that technology is being used by police, border agents, and so much more.\n\nTo be clear, the problem is not *just* that these companies created discriminatory algorithms—as we'll discuss later in this book, almost any machine learning tool trained on public data will end up reflecting all the racist and misogynistic biases of our society. The problem is that *they shipped the racist products!* No one in these companies thought to stop and ask the question: \"hey, before we roll this out, should we check to see how this behaves with people who don't look like our predominantly light-skinned workforce?\"\n\n(Yes, these are machine learning examples, not Exploratory Questions per se. Machine learning examples get a lot more press, so it's easier to demonstrate to these kinds of news stories. But while the principle that the questions we ask reflect our values is especially important in Exploratory analyses, it also has broad salience, as illustrated here.)\n\nSo remember: when deciding what to look at and report in your analyses, remember that people will make decisions based on the patterns *you* have decided are important, so if you don't stop to ask a question about, say, gender or racial bias, odds are it won't be something considered by your stakeholders.\n\nThis example is awful and the plot doesn't have labels. Need better!  \nsimpler representations that we can wrap our heads around to help us understand the world around us. Dropping a giant dataset with the CO2 emissions and latitude and longitude of every power plant in the US alongside a business survey of energy consumption by different companies broken down by building on the desk of the CEO of the environmental non-profit in the example above would clearly not aid them in the slightest to understand the world any better, just as a thumb drive with hundreds of gigs of patient data isn't helpful to a medical researcher in its raw form. The sheer *amount* of data embodied by those datasets is just too great.\n\nA map showing CO2 emissions by region, or a summary of the features that are most common within each patient cluster, by contrast, *is* something humans can wrap their heads around. And the *reason* it is understandable is due in large part to the fact that these are simple representations of the patterns in the data that matter for the question we seek to answer with all the noise that isn't critical removed. In information theoretic terms, we've taken a huge amount of noisy information and reduced it to just the signal we care about, which can be communicated with far less information.\n\nBut there's a challenge that's inherent to this type of process of simplification which you may already be noticing: answering Exploratory Questions requires identifying what is important *and throwing everything else away*. And it is for this reason that answering Exploratory Questions well is dependent on the judgment of the data scientist.  clustering algorithms / naming the clusters / Netflix infections by, say, removing fabric chairs that are hard to disinfect, the location of infections is likely important. If, by contrast, you were brought in by someone studying how the ways antibiotics were prescribed impacted infections, you would instead want to focus on the treatment histories of patients. And if you were hired by the hospital itself which just wanted to reduce infections by any means possible, you'd want to study both to know where future efforts might be best targeted. \n\nAlthough I am far from convinced that the discipline has tried particularly hard to teach it (\n\nsee my screed against “EDA”).\n\nA placebo is a “fake” treatment given to patients in clinical trials. Despite not being biologically active — placebos are often simple saline or sugar pills — most patients on placebos see their condition improve when dealing with subjective conditions, like pain.","type":"content","url":"/answering-exploratory-questions#myopic-tools","position":13},{"hierarchy":{"lvl1":"Internal versus External Validity"},"type":"lvl1","url":"/exploratory-questions-internal-external","position":0},{"hierarchy":{"lvl1":"Internal versus External Validity"},"content":"It is at this point I have to come clean about having employed a... small indirection. At the top of this reading, I introduced the idea that answering Exploratory Questions boiled down to creating (1) understandable summarizations (2) of meaningful patterns, and (3) ensuring those summaries faithful represent the data. But that three-part objective is actually only one-half of answering an Exploratory Question. More specifically, those are the three components of ensuring high internal validity when answering an Exploratory Question. But to generate a truly useful answer to an Exploratory Question, your analysis must also have high external validity.\n\nEssentially, internal validity is a measure of how well you have analyzed the data you have, while external validity is how well you expect the answer you generated from that data to generalize to your stakeholder’s context. Internal and external validity arise when answering any data science question, and so these two concepts are ones that we will return to time and again in this book.\n\nWhile the idea of internal validity will feel familiar to anyone who has taken a statistics of machine learning course, external validity is often less discussed in the classroom. This is not because it is less important than internal validity. One reason for this is that it is harder to evaluate external validity using statistical methods, causing some instructors to think of it as “outside the scope” of a statistics course. But the second reason I suspect this occurs is more subtle: while a given analysis may be said to have good or bad internal validity, it cannot be said to have good or bad external validity. Rather, the external validity of a study must always be evaluated with respect to a specific context to which one wishes to generalize the findings.\n\nThis means that external validity is different from internal validity in an important way: when faced with the same facts about a study, everyone should generally agree on the internal validity of a study, but the external validity of a study really depends on how you want to use the results. A study of medical care provided to Duke undergraduates may have very good external validity with respect to undergraduate students at Emory, UNC, Vanderbilt, and other elite universities with associated research hospitals (that is, the conclusion of the study of Duke students is likely to also be valid for those other students). But that same study may have poor external validity with respect to lower income students attending community colleges that have less comprehensive student health insurance and no top-tier associated hospital system. And it would certainly have terrible external validity with respect to all Americans, never mind people living in other countries.","type":"content","url":"/exploratory-questions-internal-external","position":1},{"hierarchy":{"lvl1":"Internal versus External Validity","lvl2":"Interval v. External Validity: An Example"},"type":"lvl2","url":"/exploratory-questions-internal-external#interval-v-external-validity-an-example","position":2},{"hierarchy":{"lvl1":"Internal versus External Validity","lvl2":"Interval v. External Validity: An Example"},"content":"To illustrate what is meant by these terms, suppose you’ve been hired by a car manufacturer. Through extensive market research, they have determined that if they can improve the safety of their cars, they could dramatically improve the image of their brand. They have turned to you, their in-house data scientist, to help them determine what safety enhancements they should focus on developing.\n\nTo help them prioritize their efforts, you decide it would be useful to begin by better understanding the predominant causes of major accidents. After all, if 95% of accidents were caused by mechanical failures, bad weather, and drunk drivers, then even a perfect system for preventing drowsy driving accidents could only reduce accidents by 5% at best!\n\nThe best source of accident investigations of which you are aware is the \n\nUS National Highway Traffic Safety Administration’s National Center for Statistics and Analysis (NCSA). Using their Crash Reporting Sampling System, the NCSA collects and publishes data from “nationally representative sample of police-reported traffic crashes, which estimates the number of police-reported injury crashes and property-damage-only crashes in the United States,” as well as data on all fatal accidents collected through their Fatality Analysis Reporting System.\n\nThe NCSA provides you with data on police-reported accidents from the Crash Reporting Sampling System and all fatal accidents from the Fatality Analysis Reporting System from the past 5 years (2018-2023). As you turn to using this data to analyze the causes of severe accidents for your stakeholder, what internal and external validity concerns might you have in the back of your mind?","type":"content","url":"/exploratory-questions-internal-external#interval-v-external-validity-an-example","position":3},{"hierarchy":{"lvl1":"Internal versus External Validity","lvl3":"Internal Validity Concerns","lvl2":"Interval v. External Validity: An Example"},"type":"lvl3","url":"/exploratory-questions-internal-external#internal-validity-concerns","position":4},{"hierarchy":{"lvl1":"Internal versus External Validity","lvl3":"Internal Validity Concerns","lvl2":"Interval v. External Validity: An Example"},"content":"Internal validity concerns, in this context, relate to your ability to properly characterize the causes of severe accidents in this data. The first of these concerns are those discussed in our previous two readings — namely, whether the summarizations of accident causes you generate from this data are meaningful and faithful representations of the patterns in the data.\n\nBut internal validity concerns also extend to things like concerns over the accuracy with which things are measured. For example, it’s reasonable to ask “How well do police accident reports capture the true causes of an accident?” Some factors — like whether a driver was intoxicated — are easy to verify after the fact in major accidents. Other factors, however, may have contributed to accidents — and be easier to address with driver assistance systems — but may have been too hard to verify for the police to put in their reports. For example, maybe weak headlights prevented the driver from seeing a change in the speed limit (causing the documented cause of the accident: speeding). Or perhaps one driver was unable to see an approaching vehicle on a cross street due to width of the A-piller (that piece of metal running vertically between the front windshield and front side window). Or “weather” may be invoked as a cause in an accident when what was really at play was that the driver had the wipers on too low of a setting (and automatic wipers would have adjusted more quickly, preventing the accident).\n\nAll of these are question about whether our summarization of the data provides a proper characterization of the world for the period and group we think are covered.","type":"content","url":"/exploratory-questions-internal-external#internal-validity-concerns","position":5},{"hierarchy":{"lvl1":"Internal versus External Validity","lvl3":"External Validity Concerns","lvl2":"Interval v. External Validity: An Example"},"type":"lvl3","url":"/exploratory-questions-internal-external#external-validity-concerns","position":6},{"hierarchy":{"lvl1":"Internal versus External Validity","lvl3":"External Validity Concerns","lvl2":"Interval v. External Validity: An Example"},"content":"But worrying about whether we really understand the world covered by our data is only half the battle. After all, our stakeholders aren’t planning to go back in time 5 years and add a new driver safety system to their cars starting in 2018; they’re thinking of developing this safety system to use in the future. So what do we think is the external validity of findings from 2018-2023 to the next ten years?\n\nTo answer this question, we need to consider how the next ten years might differ from the last five in ways that are relevant to the phenomenon we care about (here, the causes of car accidents).\n\nFirst, since time will have passed between when the crash data was collected and when the new feature rolls out, one might reasonably assume that trends in accident causes during the 2018-2023 period are likely to continue. In light of that, a thoughtful data scientist may wish to pay extra attention to whether there are clear trends in accident causes, and in what direction they are trending.\n\nBut one might also pause to ask whether there was anything exceptional about the “data generating process” during the 2018-2023 period that would not obtain in later years. Something like... a pandemic?\n\nAnd indeed, one would be right to worry. The figure below shows Vehicle Miles Travelled (VMT) and Fatalities in 2019 (pre-pandemic) and 2020 (the pandemic began in force in March, if you’ve forgotten). As the figure shows, driving plummeted during this period, and so too did Fatalities.\n\nSource: Taken from the US Department of Transportation NHTSA’s \n\nOverview of Motor Vehicle Crashes in 2020\n\nGiven that, a thoughtful data scientist may wish to be sure that any patterns identified in this five-year period are robust to exclusion of 2020-2022 before making any predictions about the likelihood these patterns would persist in later years.","type":"content","url":"/exploratory-questions-internal-external#external-validity-concerns","position":7},{"hierarchy":{"lvl1":"Internal versus External Validity","lvl4":"Other Contexts","lvl3":"External Validity Concerns","lvl2":"Interval v. External Validity: An Example"},"type":"lvl4","url":"/exploratory-questions-internal-external#other-contexts","position":8},{"hierarchy":{"lvl1":"Internal versus External Validity","lvl4":"Other Contexts","lvl3":"External Validity Concerns","lvl2":"Interval v. External Validity: An Example"},"content":"The preceding discussion assumed an interest in US accidents, but of course most car companies that sell cars in the US also sell cars in Asia and Europe. The issues raised above are examples of what I would contend are relatively small threats to the external validity of findings based on data from 2018-2023 with respect to near-future US accidents (at least provided the patterns aren’t driven by the pandemic period).\n\nBut external validity to Asian or European markets would be a much bigger concern. Because traffic laws, speed limits, alcohol laws, and how roads are constructed and laid out are all very different in different regions of the world, it seems quite unlikely that patterns identified in US accident data would have much external validity to Asian or European auto markets.","type":"content","url":"/exploratory-questions-internal-external#other-contexts","position":9},{"hierarchy":{"lvl1":"Internal versus External Validity","lvl2":"Conclusion"},"type":"lvl2","url":"/exploratory-questions-internal-external#conclusion","position":10},{"hierarchy":{"lvl1":"Internal versus External Validity","lvl2":"Conclusion"},"content":"Internal and External Validity are both key concepts for being an effective data scientist, and they are concepts to which we will return regularly in this book. Moreover, they are goals that are sometimes in tension — the more control one has over a study context, the more likely one is to have good Internal Validity; but that control can often create an artificiality to limits External Validity. Thus Internal and External Validity should not necessarily be thought of as things to try and simultaneously maximize at all costs; rather, they are best thought of as distinct features of any analysis that should always be considered. I would also add that, of the two, I would argue that External Validity — while not more important in and of itself — is the more often overlooked.","type":"content","url":"/exploratory-questions-internal-external#conclusion","position":11},{"hierarchy":{"lvl1":"Internal versus External Validity","lvl2":"Reading Reflection Questions"},"type":"lvl2","url":"/exploratory-questions-internal-external#reading-reflection-questions","position":12},{"hierarchy":{"lvl1":"Internal versus External Validity","lvl2":"Reading Reflection Questions"},"content":"Why is the External Validity of a study only defined with respect to a given context?\n\nA group of Duke doctors wishes to understand exercise behavior in patients who have recently experienced cardiac surgery. To measure exercise behavior, they surveyed their patients post-surgery about their exercise behavior. But one doctor on the team is concerned that people may mis-report their exercise (the patients know they’re supposed to be exercising, so the doctor is concerned they will report they are exercising even if they are not). Is this an Internal or External Validity concern?\n\nAfter these Duke doctors published their results, word of the study reached a doctor in rural Louisiana. Looking at the study, however, she found that the patients treated by the Duke doctors tended to be younger and healthier than the patients she sees. Is this an Internal or External Validity concern? ## External Validity\n\nExternal validity is fundamentally about the *generalizability* of a study: whether the causal estimate found in a study is likely to also be a good guess for the causal effect in a different context.\n\nExternal validity is one of the most important things to think about as a *consumer* of other people's research, because when you read other people's research, you're usually doing so because you're looking for information you can use to address a specific problem you face. In these situations, it's critical that you always ask yourself: are the results from this study likely to also be valid in the context of my problem?\n\nOf course, when asking about the external validity of a study, we have to specify the setting to which we want to generalize its results. A study that looks at how Duke undergraduates' consumer behavior changes when faced with different types of ads on google may have good external validity in terms of its generalizability to other elite Univerities like Emory, Vanderbilt, or UNC. But it might not generalize to the US population as a whole.\n\n### External Validity Considerations\n\nThere are many reasons that the results of a study may not generalize to a new context. Here are a handful of the most common issues to bear in mind:\n\n**The study population may be different from the population in the new context.**\n\nAlmost by definition, the entities in the new context will be different from the entities in the original study (even if we're working with the same people, we're looking at them at a different time). But the key question for external validity is whether the entities in the new context are different *in a way that would impact their response to a given treatment*.\n\nIt's not hard to think of reasons that different populations may respond differently to a given treatment. For example, suppose a company finds ads for luxury cars increase sales among rich people in New York. It's hard to imagine that the same ad run in a poor neighborhood in Detroit would have the same effect.\n\nAs you think about population differences, make sure you consider not only standard demographic attributes (age, gender, wealth, education), but also cultural or social differences. Many issues businesses deal with -- especially advertising and brand image -- may be culturally specific, and so may not generalize to all communities.\n\nThis may all seem obvious as you read it, but using unrepresentative samples in research and medicine, then making recommendations for the general public is a huge problem in the real world.\n\nWhite men are massively over-represented in [medical trials](https://www.theatlantic.com/health/archive/2016/06/why-are-health-studies-so-white/487046/), for example. Unsurprisingly, this means that when the results of those trials are generalized to the population as a whole, we suddenly discover (SURPRISE) that the predicted results didn't always hold for women or people of color! (e.g. [drug doses set for men are often too high for women](https://www.theguardian.com/lifeandstyle/2015/apr/30/fda-clinical-trials-gender-gap-epa-nih-institute-of-medicine-cardiovascular-disease); some heart drugs work great for White men, [but often interact poorly with a gene common in Asians and Pacific Islanders; and Multiple sclerosis turns out to be drive by a different mutation in Black patients than European descendants](https://www.vice.com/en/article/mbjjnp/medical-studies-still-exclude-people-of-color)).\n\nAnd for the longest time, psychology research was based almost entirely on studies conducted using student volunteers. But of course, students at elite universities are not a representative population -- they're disproportionately Western, Educated, from Industrialized, Rich, and Democratic countries (they're WEIRD). And as a result, our academic model of human behavior is really just a [model of a bunch of WEIRD kids](https://slate.com/technology/2013/05/weird-psychology-social-science-researchers-rely-too-much-on-western-college-students.html).\n\nUnrepresentative training data is also one of the reasons that so many machine learning algorithms are just plain racist (this isn't causal inference, but it's the same idea) -- if you train a facial recognition algorithm using predominantly white faces, turns out that they will either [not see Black faces](http://www.cnn.com/2009/TECH/12/22/hp.webcams/index.html), or worse, mis-identify people of color (which is a [really bad thing when those algorithms are being used by the police](https://www.wired.com/story/best-algorithms-struggle-recognize-black-faces-equally/)).\n\nSo while internal validity issues may seem more sophisticated and thus interesting, don't overlook the importance of these kinds of external validity issues!\n\n**The treatment might differ between study and new context**\n\nA study may declare that it has measured the effect of billboard ads on sales, or an infinite scroll on engagement. But it's always important to remember that while we may interprete studies in these general terms, the reality is that that billboard study probably measured the effect *of a specific set of billboard ads* on sales, and the infinite scroll study looked at the effect of infinite scroll *in a specific app*.\n\nSo always be careful to think about what *exactly* the treatment in a study was, and whether its likely to generalize to the case you study about.\n\n**There may be scaling effects**\n\nOften times when we're thinking about external validity, we're not just thinking re-using a treatment or intervention; we're thinking about scaling them up.\n\nBut an intervention that works on a few people / is only in place for a short period may not be a perfect model for what happens when that same intervention is applied at scale or permanently. For example, the returns to showing people a TV ad about your company for the first time is probably not the same as the returns to airing that ad the 1,000,000th time. Or sales from selling a special product at one store for a limited time may not be a good indicator of the sales you would see if your \"special product\" were available everywhere all the time.\n\nPeople may also respond differently to an intervention when it gets big or becomes permanent. To illustrate, I'd like to tell a story about a famous experiment in India ([paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2826809/)).  \n\nRural health clinics in India have a huge problem: nurse absenteeism. To try and address the problem, in the late 2000s an NGO (along with some MIT economists) decided to see if they could fix the problem. The NGO started keeping track of when nurses clocked in and out, and then shared the information with the government, who then applied fines or punishments to nurses who weren't showing up for work.\n\nInitially, the intervention was successful, leading to very large increases in attendance (doubling it in fact!) after a few months. But as nurses came to realize this wasn't just a little study but actually something that was going to be around for a while, they mobilized politically, and soon administrators were allowing nurses to claim an increasing number of \"exempt days\", avoiding punishment. And so sure enough, nurses stopped coming to work, and absenteeism had returned to pre-intervention levels 16 months after the program began.\n\nThis is an example of what economists call a \"general equilibrium\" effect -- when we introduce a treatment to the world, the world responds. But often these responses don't happen in small trials the same way they do when policies go big, creating serious generalizability problems.\n\nRelatedly: if you are a public policy person or an economic development person, I cannot recommend [this paper](https://www.nber.org/papers/w22595) by Angus Deaton and Nancy Cartwright enough for discussing the limitations of RCTs for learning about the effects of policy or nature of social processes. It's a long, very thoughtful paper, but it's really, *really* good. \n\nIt is worth noting that if the goal of the company is to improve brand image and sales — rather than improve safety as much as possible — then what matters is not what actually causes the most accidents, but rather what customer perceive causes the most accidents. But let us assume — for the sake of this exercise — that your employer’s interest in reducing accidents is sincere. If there is a divergence between customer perceptions and the reality of accident causes, that could be addressed with additional information embedded in any advertisements of the feature being developed.","type":"content","url":"/exploratory-questions-internal-external#reading-reflection-questions","position":13},{"hierarchy":{"lvl1":"Using Passive Prediction Questions"},"type":"lvl1","url":"/using-passive-prediction-questions","position":0},{"hierarchy":{"lvl1":"Using Passive Prediction Questions"},"content":"In the past few chapters, we explored the role of Exploratory Questions in helping data scientists better understand the problems they seek to solve and to prioritize subsequent efforts. While useful, however, answering Exploratory Questions is rarely sufficient to solve a stakeholder’s problem in and of itself. To really solve problems, often data scientists must turn to answering Passive Prediction Questions — the focus of this chapter — and/or Causal Questions (a topic we will return to in future chapters).\n\nAs discussed in the introduction of this book, Passive Prediction Questions are questions about the future or potential outcomes of individual entities (customers, patients, stores, etc.). “How likely is Patient X to experience a heart attack in the next two years?,” for example, or “How likely is it Mortgage Holder Y will fail to make their mortgage payment next month?”\n\nUnlike Exploratory Questions, data scientists don’t generally come up with “an answer” to Passive Prediction Questions; rather, data scientists answer Passive Prediction Questions by developing statistical models that take the attributes of an entity as inputs and spit out a unique answer for each entity. A company interested in spam detection, for example, might hire a data scientist to develop a model that takes the content of an email as input and, for every email a person receives, answers the question “If the recipient of this email looked at it, would they consider it spam?” The exact statistical machinery one uses will vary across applications, but answering these questions is the realm where terminology like “supervised machine learning” is most likely to be used.\n\nSince Passive Prediction Questions don’t usually have “an answer,” a data scientist faced with a Passive Prediction challenge will often start by considering the feasibility of developing a model to give individual-level answers to a Passive Prediction Question. “Given data on new customer behavior on my website,” for example, “can I predict how much a customer is likely to spend over the next year?” At the end of the day, however, what a stakeholder cares about is not whether one can predict future spending; they care about the actual answer to the question, “Given this new customer’s behavior on my website, are they likely to spend a lot over the next year?” for a given customer. For that reason — and because understanding exactly what question a model is answering is key to its effective use — this individual-level question will be our focus here.","type":"content","url":"/using-passive-prediction-questions","position":1},{"hierarchy":{"lvl1":"Using Passive Prediction Questions","lvl2":"Flavors of Passive Prediction Questions"},"type":"lvl2","url":"/using-passive-prediction-questions#flavors-of-passive-prediction-questions","position":2},{"hierarchy":{"lvl1":"Using Passive Prediction Questions","lvl2":"Flavors of Passive Prediction Questions"},"content":"Passive Prediction Questions come in two flavors, corresponding to the two primary business purposes detailed above.\n\nThe first flavor of Passive Prediction Questions is questions about what is likely to occur in the future for a specific individual. Answering these questions is useful for identifying individuals for additional care or attention. For example, a hospital might want to know “How likely is Patient A to experience complications after surgery?” so they can decide whether the patient should receive extra nursing attention during recovery, or a factory owner might ask “How likely is this machine to break down in the next month?” to help them determine when to take the machine offline for maintenance. This is the more intuitive flavor of Passive Prediction Question, as it accords nicely with the normal meaning of the term “predict.”\n\nThe second favor of Passive Prediction Questions is questions about what would happen in different circumstances. Answering this type of question is the key to automation, as the “different circumstance” in question is often one in which a job is being done by an actual person. For example, a statistical model that can answer the question “if a radiologist were to look at this mammogram, would they conclude it showed evidence of cancer?” effectively is a model that automates the review of mammograms. A model that can answer the question “if you showed this email to its intended recipient, would they say it is spam?” is an algorithm that automates spam detection.","type":"content","url":"/using-passive-prediction-questions#flavors-of-passive-prediction-questions","position":3},{"hierarchy":{"lvl1":"Using Passive Prediction Questions","lvl3":"OK, but... Doesn’t This Feel a Little Contrived?","lvl2":"Flavors of Passive Prediction Questions"},"type":"lvl3","url":"/using-passive-prediction-questions#ok-but-doesnt-this-feel-a-little-contrived","position":4},{"hierarchy":{"lvl1":"Using Passive Prediction Questions","lvl3":"OK, but... Doesn’t This Feel a Little Contrived?","lvl2":"Flavors of Passive Prediction Questions"},"content":"You would be forgiven for asking whether I’ve gone a little too far in trying to force the simple task of automation into the “all data science tools are tools for answering questions” framework of the book. Yes, I see how you could call an algorithm that automates the review of mammograms a tool for answering the question “if a radiologist were to look at this mammogram, would they conclude it showed evidence of cancer?” But that seems awfully convoluted. Why can’t we just call it an algorithm that looks for cancer in mammograms?\n\nThe answer is that while it is certainly less succinct, but as we discussed in the introduction, because of how these models are developed, it is more accurate to say that our mammogram reading algorithm is trying to answer the question “if a radiologist were to look at this mammogram, would they conclude it showed evidence of cancer?” than to say that it’s “looking for cancer.” The way that most statistical models are developed (“trained”) to answer Passive Prediction Questions is using a large dataset of “training examples” — that is, data in which the outcome we care about is included in the dataset. For predicting individual-level future outcomes, this will be historical data in which outcomes — like surgery complications or factory machine failures — have already occurred. For automation, this will be data in which a person has already completed the task, and their conclusions or actions have been recorded. To train a mammogram reading algorithm, in other words, you first need a database of mammograms that radiologists have already labeled as indicating cancer or not. And what the model is actually trained to do is not “find cancer” but rather to “give the same answers given by human radiologists.”\n\nAnd this is where the distinction between “predicting what a radiologist would say” and “detecting cancer” becomes important: because this kind of statistical model was trained to emulate the behavior of radiologists in labelled mammograms, the model will recapitulate any systematic biases held by the human radiologists who reviewed the mammograms in the training data. Did the radiologists struggle to detect cancer in dense breast tissue? So too will the algorithm trained on their labels.\n\nThe tendency for algorithms to replicate human biases present in training data, unfortunately, extends to gender and racial biases. In 2018, for example, Reuters reported that Amazon was forced to scrap an effort to use machine learning to automatically review resumes because it turned out the \n\nalgorithm — trained on historic hiring data — was biased against women. The exact details of the source of the bias is unclear — for obvious reasons Amazon is not eager to report on the failure — but my suspicion is that things went wrong in one of two ways.\n\nThe first is that the algorithm was given data on all past Amazon applicant resumes, along with data on which applicants had actually been hired. The algorithm was then effectively trained to answer the question “If an Amazon hiring manager looked at this resume, is it likely they would be hired?” In that case, the algorithm was recapitulating the gender bias of previous hiring managers.\n\nMy second guess is that the algorithm was given the resumes of current employees along with employee reviews. In that case, the algorithm was effectively being asked to answer the question “Given this resume, is it likely this is a person a current manager would rate highly once employed?” In that case, the algorithm was recapitulating gender biases in employee reviews.\n\nIn either case, these are examples of an alignment problem: the people developing these models wanted the algorithm to pick the applicants who would be the most productive employees, but the model they actually developed was trying to identify employees who looked like previously successful applicants. Had the previous hiring system been effective, this wouldn’t be a problem, but because the previous system included a gender bias, so too did the resulting algorithm. But because the engineers developing these tools did not think carefully enough about the question the model was actually being taught to answer, the problem was not identified until it was too late.","type":"content","url":"/using-passive-prediction-questions#ok-but-doesnt-this-feel-a-little-contrived","position":5},{"hierarchy":{"lvl1":"Using Passive Prediction Questions","lvl2":"Differentiating Between Exploratory and Passive Prediction Questions"},"type":"lvl2","url":"/using-passive-prediction-questions#differentiating-between-exploratory-and-passive-prediction-questions","position":6},{"hierarchy":{"lvl1":"Using Passive Prediction Questions","lvl2":"Differentiating Between Exploratory and Passive Prediction Questions"},"content":"If you have not felt a little confused about the distinction between Exploratory and Passive-Prediction Questions previously, there’s a good chance you find yourself struggling with that issue here, and for understandable reasons.\n\nThe first thing to emphasize is that the distinction between Exploratory and Passive Prediction Questions is a distinction in one’s goal, not the statistical machinery one might use to achieve that goal.\n\nWith Passive-Prediction Questions, our interest is in the values that get spit out of a model for each entity in the data. When answering a Passive-Prediction Question, the only thing we care about is the quality of those predictions, and so we evaluate the success of a model that aims to answer a Passive-Prediction Question by the quality of those predictions (using metrics like AIC, AUC, R-Squared, Accuracy, Precision, Recall, etc.). Thus, when using a logistic regression to answer a Passive-Prediction Question, we don’t actually care about what factors are being used to make our predictions, just that they improve the predictions. Our interest is only the quality of our predicted values, and a good model is one that explains a substantial portion of the variation in our outcome.\n\nWith Exploratory Questions, our interest is in improving our understanding of the problem space, not in making precise predictions for each entity in our data. Thus, in the example of logistic regression, our interest is in the factors on the “right-hand side” of our logistic regression and how they help us understand what shapes outcomes, not the exact accuracy of our predictions. A good model, in other words, doesn’t actually have to explain a large share of variation at the level of individual entities, but it does have to help us understand our problem space.\n\nA model that looked at the relationship between individuals’ salaries and their age, education, and where they live might tell us a lot about the importance of a college degree to earnings (which we could see by the large and statistically significant coefficient on having a college degree), even if it only explains a small amount of overall variation in salaries (e.g., the R-Squared might only be 0.2).\n\nThis distinction also has important implications when working with more opaque supervised machine learning techniques, like deep learning, random forests, or SVMs. These techniques are often referred to as “black boxes” because exactly how different impute factors relate to the predictions that the model makes is impossible to understand (in other words, it’s like the input data is going into a dark box we can’t see into, and then predictions are magically popping out the other side). These models can be very useful for answering Passive-Prediction Questions, as they can accommodate very unusual, non-linear relationships between input factors and predicted values, but because these relationships are opaque to us, the data scientist, they don’t really help us understand the problem space.","type":"content","url":"/using-passive-prediction-questions#differentiating-between-exploratory-and-passive-prediction-questions","position":7},{"hierarchy":{"lvl1":"Using Passive Prediction Questions","lvl2":"The “Passive” in Passive Prediction"},"type":"lvl2","url":"/using-passive-prediction-questions#the-passive-in-passive-prediction","position":8},{"hierarchy":{"lvl1":"Using Passive Prediction Questions","lvl2":"The “Passive” in Passive Prediction"},"content":"The term “passive” in “Passive Prediction Questions” is meant to emphasize the distinction between Passive Prediction Questions and Causal Questions. Both Passive Prediction Questions and Causal Questions can be thought of as trying to “predict” some future outcome, but they differ in the contexts in which their predictions are valid. A full accounting of the distinction between Passive Prediction Questions and Causal Questions will have to wait until we have covered Causal Questions in detail, for the moment, we can get a sense of things by introducing a very casual definition of what it means for some cause X to effect some outcome Y.\n\nIn causal parlance, when we say that some factor X causes outcome Y (and that X is not merely correlated with Y), what we usually mean is that if we were to go out and actively change X, Y would change as a result. This isn’t a fully rigorous definition, but it drives home that causation is about what happens when we actively manipulate X.\n\nTo see how this distinction illustrated, let’s return to the example of a hospital interested in predicting which patients are likely to experience complications after surgery. Using past patient data, you are able to develop a model that very accurately answers the question “Given their pre-surgery vitals, how likely is a patient to experience complications after surgery?” Hooray! The hospital uses this model to determine which patients should get extra nursing visits and extra attention during recovery. You’ve done a great job answering a Passive Prediction Question by discovering a pattern in the world — a set of correlations between measurable variables — you can take advantage of.\n\nNow in the course of developing this model, suppose you discover that one of the strongest predictors of complications after surgery is patient blood pressure — patients with high blood pressure are substantially more likely to experience complications than those with normal blood pressure. This leads you to wonder whether treating patients with high blood pressure with pressure-reducing medications prior to surgery might reduce complications. In other words, you now want to know the effect of going into the world and manipulating patient blood pressure — a Causal Question.\n\nIn the first case, you really don’t care if blood pressure is causing the surgical complications, by which we mean you don’t care if reducing blood pressure would reduce complications, or whether high blood pressure is just an easily observable symptom of an underlying condition that is the root cause of surgical complications (like leading a stressful life, or having relationship problems at home). In either case, the correlation is sufficient for your purposes of identifying patients you need to keep tabs on.\n\nBut if you want to know what would happen if you directly manipulated blood pressure, knowing that blood pressure and complications are correlated is not sufficient. After all, if living alone results in high blood pressure and difficulty recovering from surgery, then treating patient blood pressure may have no effect at all!\n\nWhen answering Passive Prediction Questions, we are searching for correlations we can leverage to make accurate predictions, not causal relationships we can directly manipulate to shape outcomes. Indeed, those who specialize in answering Passive Prediction Questions (like computer scientists who specialized in supervised machine learning) don’t really care that “correlation does not (necessarily) imply causation.”","type":"content","url":"/using-passive-prediction-questions#the-passive-in-passive-prediction","position":9},{"hierarchy":{"lvl1":"Using Passive Prediction Questions","lvl2":"How do Large Language Models (LLMs) Fit Into This?"},"type":"lvl2","url":"/using-passive-prediction-questions#how-do-large-language-models-llms-fit-into-this","position":10},{"hierarchy":{"lvl1":"Using Passive Prediction Questions","lvl2":"How do Large Language Models (LLMs) Fit Into This?"},"content":"Given their emergence as one of the most high profile examples of something people call “AI” these days, it’s worth directly addressing how LLMs like chatGPT, Llama, Bard, etc. fit into this framework.\n\nOne of the most powerful ways to understand LLMs is to think of them as tools for answering “If I came across this text [whatever text is in the LLMs prompt, pre-prompts, or other inputs in the model’s context window] while wandering around the internet, what word am I most likely to encounter next?” LLMs then ask this question over and over, adding the newly selected word to the context window one at a time and then feeding the updated “conversation” back into itself as input to help it predict the next word. Indeed, this repetitiveness is why the technology behind most LLMs is called a recurrent neural network — because it keeps adding a word to the “conversation” you are having (it’s “context window”), then feeding the updated conversation back into the model as an updated input.\n\nTo be clear, this is a little reductionist. First, LLMs are able to abstract away from literal text to something like the meaning of words — they recognize that “pet” and “dog” have similar meanings in the sentences “I took my dog for a walk” and “I took my pet for a walk” — but even these abstractions are the result of looking for common patterns across existing text. And second, LLMs are also “finetuned” by having humans rate responses. But these nuances don’t change the fact that fundamentally LLMs are tools for recapitulating text and ideas that already exist in the world, with a strong bias towards what humans have tended to write most on the internet — a truth that both explains some of their power, but also helps to explain their fundamental limitations (e.g., their complete lack of fidelity to the truth, the fact they reflect societies’ gender and racial biases, etc.).\n\nA more accurate way to phrase this would be “If I came across this text in my training data...” For most LLMs, “my training data” is a corpus that consists of both text that is not on the internet — like every book every published — and fails to include many things that are on the internet but which are difficult to crawl in an automated way. You can learn more about the corpus of internet text used by many LLMs — the 9.5 petabyte Common Crawl dataset — \n\nhere. But it does seem very clear the vast majority of training data comes from the internet. LLMs makers are becoming increasingly caggy about what data they use for training — in part because they don’t wish to make copyright lawsuits against them too easy — but books made up only \n\n4.5% of the training data for Meta’s first version of LLaMa.","type":"content","url":"/using-passive-prediction-questions#how-do-large-language-models-llms-fit-into-this","position":11},{"hierarchy":{"lvl1":"Passive Prediction Questions and Internal Validity"},"type":"lvl1","url":"/passive-prediction-internal","position":0},{"hierarchy":{"lvl1":"Passive Prediction Questions and Internal Validity"},"content":"As with Exploratory Questions, when answering Passive Prediction Questions there are two major types of concerns: those related to internal validity, and those related to external validity.","type":"content","url":"/passive-prediction-internal","position":1},{"hierarchy":{"lvl1":"Passive Prediction Questions and Internal Validity","lvl2":"Internal Validity"},"type":"lvl2","url":"/passive-prediction-internal#internal-validity","position":2},{"hierarchy":{"lvl1":"Passive Prediction Questions and Internal Validity","lvl2":"Internal Validity"},"content":"Of all the places where data science is fragmented, none is more evident than in how data scientists evaluate how effectively we think a model is representing our data, especially when focused on prediction.\n\nThe first data science perspective on evaluating the internal validity of a model comes from the field of statistics. Statisticians have approached evaluating model fit with, unsurprisingly, methods based on the idea of random sampling and the properties of statistical distributions. They make assumptions about the distributions underlying data and use those to derive theoretically-motivated metrics. That’s the origin of statistics like Akaike Information Criterion (AIC), Bayesian Information Criterion (BIC), as well as the emphasis on the validity of the standard errors assigned to factors on the right-hand side of the regression.\n\nWhen computer scientists were first developing their own machine learning techniques... I’m editorializing a little here, but I think it’s safe to say that initially they either didn’t know about a lot about these metrics, or they thought that they could do a better job investing their own. So they developed the “split-train-test” approach to model evaluation: they split their data into two parts, train their model on part of the data, then test how well the model is able to predict the (known) outcomes in the test dataset.\n\nOf course, over time these two fields have largely converged in adopting one another’s methods, and some—like cross-validation—live comfortably in the middle. But if you’re ever wondering why, when you get to a machine learning class, it seems like everything you learned in stats has been abandoned (or end up in a stats class and have the opposite experience), it’s largely an artifact of parallel development of methods of model evaluation in computer science and statistics departments.\n\nBut the ins and outs of fitting machine learning or statistical models is not the comparative advantage of this text, and so our time is better spent turning to External Validity.","type":"content","url":"/passive-prediction-internal#internal-validity","position":3},{"hierarchy":{"lvl1":"Passive Prediction Questions and External Validity"},"type":"lvl1","url":"/passive-prediction-external","position":0},{"hierarchy":{"lvl1":"Passive Prediction Questions and External Validity"},"content":"Where internal validity is a measure of how well a model captures the meaningful variation in the data we already have, external validity is a measure of how well we think that our model is likely to perform when faced with new data.\n\nAs we learned before, the external validity of a model is specific to the context in which a model is being used. A model will generally have very high external validity when used to answer Passive-Prediction Questions in a setting that is very similar to the setting from which the data used to train the model was collected, but low external validity when applied in geographically, temporally, or socially different settings.\n\nSome of the factors that influence the External Validity to Passive Prediction Questions are the same as those that shape the External Validity of Exploratory Questions, such as the population represented in the data (patterns in data from one country will often differ from patterns in data from another country), the time period in question (consumer behavior may vary across seasons, and many patterns in data change over longer timespans). But there are other concerns that are a little more specific to Passive Prediction Questions:","type":"content","url":"/passive-prediction-external","position":1},{"hierarchy":{"lvl1":"Passive Prediction Questions and External Validity","lvl2":"Extrapolation and Training Parameter Ranges"},"type":"lvl2","url":"/passive-prediction-external#extrapolation-and-training-parameter-ranges","position":2},{"hierarchy":{"lvl1":"Passive Prediction Questions and External Validity","lvl2":"Extrapolation and Training Parameter Ranges"},"content":"Tools for evaluating internal validity help ensure that statistical and machine learning models will tend to fit the data on which they are trained relatively well. However, while most statistical models are capable of generating predicted values over a very broad range of input values, their reliable outside the range of values on which they were trained is often very limited. Asking a model to make predictions for inputs on which the model wasn’t trained is called extrapolating, and is a great way to get oneself into trouble.\n\nTo illustrate, consider the two models in the figure below (\n\nsource)—one a linear fit, and one a higher-order polynomial. Both model the data similarly in the range for which data is available — and so will perform similarly when one uses the metrics described above to evaluate the model’s internal validity — but make very different predictions when asked to extrapolate values of x below 0 or above 2.\n\nIn addition to reducing overfitting, strategies like regularization are designed to constrain the “wonkiness” of models outside the domain on which they were trained, but almost by definition, absent data in those extended ranges, there’s no way to know for certain whether the model will generalize.","type":"content","url":"/passive-prediction-external#extrapolation-and-training-parameter-ranges","position":3},{"hierarchy":{"lvl1":"Passive Prediction Questions and External Validity","lvl3":"What Constitutes Extrapolation?","lvl2":"Extrapolation and Training Parameter Ranges"},"type":"lvl3","url":"/passive-prediction-external#what-constitutes-extrapolation","position":4},{"hierarchy":{"lvl1":"Passive Prediction Questions and External Validity","lvl3":"What Constitutes Extrapolation?","lvl2":"Extrapolation and Training Parameter Ranges"},"content":"In the example above, the term extrapolation refers to predicting values below 0 and above 2. But what constitutes an extrapolation depends in part on the complexity of the model. With a nice, interpretable linear model, it’s not hard to have confidence that the model will make a reasonable prediction for x=0.5, even though that specific value wasn’t in the training data. But when one begins to work with highly non-linear models that allow for interactions and aren’t easily interpretable — such as deep learning neural networks — the only place one can feel sure of the behavior of the model is at the exact data points in the training data. The same flexibility that allows these models to accommodate unusual non-linear relationships can also lead to bizarre behavior between actual points in the training data. A credit risk model may make perfectly reasonable predictions for a married 45-year-old women of Hispanic descent who lives in Colorado and a married 47-year-old women of Hispanic descent who lives in Colorado because both of those profiles were present in the training data, but make a crazy prediction for a a married 46-year-old women of Hispanic descent who lives in Colorado or a married 45-year-old women of Hispanic descent who lives in Montana.\n\nIndeed, it’s precisely for this reason that for many high stakes decisions, regulators are increasingly requiring the use of interpretable models that include guarantees (like monotonicity).\n\nBasically, the more flexible the model, the more data points are required to constrain the model’s behavior (the so-called “curse of dimensionality”), and the more cautious you should become. There’s a reason that LLMs hallucinate despite being fed unfathomably large amounts of data.\n\nNote\n\nA common misconception among young data scientists is that the split-train-test workflow commonly used in machine learning innoculates against external validity concerns. After all, the idea of split-train-test is that models are trained on one set of observations and evaluated against an entirely different set of observations.\n\nWhile split-train-test can help reduce external validity concerns by guarding against over-fitting, a fundamental limitation of the workflow is that training observations and test observations both come from the same context. Indeed, because test and training datasets are created by taking a single dataset and randomly splitting the observations, they should always have the same properties (at least in expectation) — a guarantee one certainly won’t get when moving from the data used to build a model to a real world deployment.","type":"content","url":"/passive-prediction-external#what-constitutes-extrapolation","position":5},{"hierarchy":{"lvl1":"Passive Prediction Questions and External Validity","lvl2":"Adversarial Users"},"type":"lvl2","url":"/passive-prediction-external#adversarial-users","position":6},{"hierarchy":{"lvl1":"Passive Prediction Questions and External Validity","lvl2":"Adversarial Users"},"content":"Another external validity concern for Passive Prediction Models is adversarial users. Adversarial users are users who deliberately attempt to subvert a statistical or machine learning model. The idea of adversarial users might seem like the stuff of spy novels, but they’re actually much more common than you might think.\n\nTo illustrate, consider the Essay RoboGrader. Training an algorithm to answer the question “if a human English professor read this essay, what score would they give it?” is relatively straightforward — get a bunch of essays, give them to some English professors, then fit a supervised machine learning algorithm to that training data. What could go wrong?\n\nThe problem with this strategy is that the training data was generated by humans who knew they were writing essays for humans to read. As a result, they wrote good essays. The machine learning algorithm then looked for correlations between human essay rankings and features of the essays, and as a result it could easily predict essay scores, at least on a coarse scale.\n\nBut what happens when humans realize they aren’t being graded by humans? Well, now instead of writing for a human, they will write for the algorithm. They figure out what the algorithm rewards — big, polysyllabic words (don’t worry, doesn’t matter if they’re used correctly), long sentences, and connecting phrases like “however” — and stuff them into their essays.\n\nThis works because the essay writers who used polysyllabic words and long sentences in the training data happened to also be the students who were writing good essays. These were reliable predictors of scores in essays people wrote for humans. But they aren’t a reliable predictor of essay quality in a world where students know the essays aren’t being written for humans, just machines.\n\nAnother way of thinking about this is that we’re back to the classic problem of alignment problems: they want the algorithm to reward good writing, but that’s not actually what they trained it to do. In this case, however, the alignment problem is rearing its head because people are actively trying to exploit this difference.\n\nWhile these examples are fun, not all are, and adversarial users is a HUGE and never ending problem for spam filters, network intrusion detection, credit and fraud monitoring, and more.","type":"content","url":"/passive-prediction-external#adversarial-users","position":7},{"hierarchy":{"lvl1":"Passive Prediction Questions and External Validity","lvl3":"Goodhart’s Law, Cambell’s Law, and the Lucas Critique","lvl2":"Adversarial Users"},"type":"lvl3","url":"/passive-prediction-external#goodharts-law-cambells-law-and-the-lucas-critique","position":8},{"hierarchy":{"lvl1":"Passive Prediction Questions and External Validity","lvl3":"Goodhart’s Law, Cambell’s Law, and the Lucas Critique","lvl2":"Adversarial Users"},"content":"It’s worth noting that the threat of adversarial users is not a new phenomenon unique to the age of machine learning. Indeed, the idea of adversarial users is closely linked to at least three much older ideas:\n\n“When a measure becomes a target, it ceases to be a good measure.”\n\nGoodhart’s Law, named for Charles Goodhart.\n\n“The more any quantitative social indicator is used for social decision-making, the more subject it will be to corruption pressures and the more apt it will be to distort and corrupt the social processes it is intended to monitor”\n\nCampbell’s Law, named for Donald Campbell\n\n“Given that the structure of any [statistical] model consists of optimal decision rules of economic agents, and that optimal decision rules vary systematically with changes in the structure of series relevant to the decision maker, it follows that any change in policy will systematically alter the structure of [statistical] models.”\n\nLucas Critique, named for Robert Lucas\n\nAnd since no idea is serious until it’s been importalized in an XKCD comic:\n\nI cannot for the life of me find the podcast where I first discovered this phenomenon being discussed, but it had lots of great colorful examples of school kids doing this. For now all I can find are these articles: \n\nhere, \n\nhere, \n\nhere, \n\nhere and \n\nhere.","type":"content","url":"/passive-prediction-external#goodharts-law-cambells-law-and-the-lucas-critique","position":9},{"hierarchy":{"lvl1":"The Right Way To Be Wrong"},"type":"lvl1","url":"/passive-prediction-errors","position":0},{"hierarchy":{"lvl1":"The Right Way To Be Wrong"},"content":"With the rise of online machine learning competitions like Kaggle and an academic literature fixated on publishing papers showing marginal improvements in performance metrics on standard benchmarks, you could be forgiven for thinking that the hardest part of data science is finding the right model and features to max out standard metrics like Area Under the Curve (AUC), Accuracy (share of cases correctly classified) or F1 scores.\n\nHowever, this is far from the case when it comes to solving real-world problems. Yes, advancement in academic computer science is often tied to one’s ability to write a new algorithm that performs marginally better on standard benchmarks, and most problem sets or online competitions you encounter will pre-specify how model performance will be evaluated.\n\nBut when it comes to solving real-world problems, determining what success looks like is actually a core part of your job as a data scientist. And what makes this task difficult is not how you measure your model’s successes — the number of true positives and true negatives the model generates — but in determining the types of mistakes it makes when it gets things wrong.\n\nUnderstanding how a model fails is just as important as minimizing mistakes in the first place (i.e., maximizing accuracy). Depending on the context, there can be huge asymmetries regarding the consequences of false positives and false negatives. Tell someone with cancer they’re fine (false negative), and the result may be the death of the patient from an easily treatable condition; tell someone healthy there’s a chance they have cancer, and you may cause stress and additional tests, but the patient death is very unlikely.\n\nSimilarly (but in a much less scary context), classify a credit card applicant as a “good credit risk” who is not actually credit-worthy (a false positive), and your company may lose the credit limit on the card they issue; classify someone as high risk who is actually not, and your company may lose the transaction fees that customer would have generated, but they won’t lose tens of thousands of dollars in unpaid bills.\n\nWhen answering Passive Prediction Questions, the choice of how to balance true positives, true negatives, false positives, and false negatives is the bridge between the math of statistics and machine learning and the specifics of real-world problems. And as a result, an ability to speak thoughtfully about how to balance these interests is one of the most important differentiators between data scientists who have only ever fit models for problem sets and data scientists business leaders trust to solve their problems.\n\nNote\n\nIn case you need more motivation to care about how best to distribute your true and false positives and negatives to best solve your stakeholder’s problem, allow me to offer the following: if you are comfortable just endorsing a single success metric (accuracy, F1 score, AUC), most Passive Prediction Questions can be answered relatively well by automated tools. And that means that if the only thing that differentiates you from the next data scientist (or generation of chatGPT) is that you can get a slightly higher AUC than the person sitting next to you, how much value do you think you are likely bringing to your stakeholder (and thus how well paid)?\n\nDon’t believe me? Consider scikit-learn — by design, nearly all of the algorithms in that package have the exact same APIs — you run test_train_split(), .fit(), and .predict(). That means it’s almost trivially easy to write a program that just loops over all the models in the library, fits them, and checks their performance against the simple metric you chose. Indeed, products exist that do just this, often under names like AutoML.\n\nWill these do as well as a well trained data scientist? Not yet — there’s skill in feature engineering and choosing which path to go down when computationally constrained. And if you’re someone working at the forefront of developing new machine learning algorithms or infrastructure, then this does not apply to you. But if you are someone who is primarily interested in applying the best tools of data science to solve real world problems, then you should also bear in mind that anything easily computable lends itself to automation.\n\nThinking carefully about your stakeholder’s problem and being able to get them to articulate the relative value they place on true and false positives and negatives, then translating that domain expertise into an optimization problem — that is a task that requires substantially more critical thinking and interpersonal skills, and consequently is less likely to be made obsolete any time soon.","type":"content","url":"/passive-prediction-errors","position":1},{"hierarchy":{"lvl1":"The Right Way To Be Wrong","lvl2":"The Problem with Accuracy"},"type":"lvl2","url":"/passive-prediction-errors#the-problem-with-accuracy","position":2},{"hierarchy":{"lvl1":"The Right Way To Be Wrong","lvl2":"The Problem with Accuracy"},"content":"Let’s begin our discussion about balancing true and false positives and negatives with my least favorite metric for classification problems: Accuracy.\n\nThere is perhaps no better way for a data scientist to demonstrate they don’t know what they’re doing than for them to proudly proclaim that their model has an accuracy score of ninety-something percent without additional context. And yet it is a mistake that I see constantly. It is as though, being students, young data scientists implicitly assume that accuracy scores, like grades, exist on an absolute scale, where values in the 90s are \"A\"s and something to celebrate and values in the 70s are \"C\"s and something to feel bad about, when in reality neither is necessarily the case.\n\nReporting Accuracy Without Context\n\nThere is perhaps no better way for a data scientist to demonstrate they don’t know what they’re doing than for them to proudly proclaim that their model has an accuracy score of ninety-something percent without additional context.\n\nHow do I know this fallacy is common, you ask? As Director of Admissions for the \n\nDuke Masters of Interdisciplinary Data Science (MIDS) program, I read hundreds of Statements of Purpose essays and resumes every year from aspiring data scientists from around the world. And despite having done this for years, I continue to be shocked by the number of applicants who proudly proclaim something like “I fit a model using XYZ method and was able to achieve a 95% accuracy score,” or report an accuracy score in the 90s in their resume as though those numbers, absent context, were meaningful.\n\nSo why is reporting accuracy scores without context such a problem? There are at least three reasons.","type":"content","url":"/passive-prediction-errors#the-problem-with-accuracy","position":3},{"hierarchy":{"lvl1":"The Right Way To Be Wrong","lvl3":"Accuracy and Imbalanced Data","lvl2":"The Problem with Accuracy"},"type":"lvl3","url":"/passive-prediction-errors#accuracy-and-imbalanced-data","position":4},{"hierarchy":{"lvl1":"The Right Way To Be Wrong","lvl3":"Accuracy and Imbalanced Data","lvl2":"The Problem with Accuracy"},"content":"Most data you will encounter in your career will be imbalanced, meaning that one of the outcomes you are trying to predict with your model (assuming a classification task) will be much, much less prevalent than the other. In these situations, because accuracy is just “the share of cases correctly classified,” getting high acccuracy can be achieved trivially by always predicting the more prevalent outcome.\n\nTo illustrate, consider routine mammograms. Mammograms are x-rays of women’s breast tissue used to screen for early signs of breast cancer. In the United States, it is recommended that all women over 40 get a mammogram every two years. Unsurprisingly, therefore, vast majority of routine mammograms are medically unremarkable. According to the Susan G. Komen society, roughly 90% of routine mammograms are perfectly normal and require no followup. Thus a “model” that reports that any routine mammogram it is given is normal will immediately achieve an accuracy score of 90%.\n\nMoreover, most data scientists wouldn’t even consider 90/10 data to be particularly imbalanced. In any given year in the United States, only about 3% of single-family residential mortgages are in a state of delinquency, and fraudulent credit card purchases \n\nmake up less than one-tenth of 1% of all credit card transactions. That means a “model” that reports all mortgages are in good standing or that all credit card transactions are valid will immediately have accuracy scores of 97% and > 99.9%, respectively.","type":"content","url":"/passive-prediction-errors#accuracy-and-imbalanced-data","position":5},{"hierarchy":{"lvl1":"The Right Way To Be Wrong","lvl3":"Relative to What?","lvl2":"The Problem with Accuracy"},"type":"lvl3","url":"/passive-prediction-errors#relative-to-what","position":6},{"hierarchy":{"lvl1":"The Right Way To Be Wrong","lvl3":"Relative to What?","lvl2":"The Problem with Accuracy"},"content":"The second problem with reporting accuracy scores absent context is that the value of a model can only ever be evaluated relative to what came before. A model with a 93% accuracy score is unlikely to be of particular value to a business if the model they were using before you arrived had an accuracy score of 98%, and your model does not have any other benefits to offset its lower accuracy. Similarly, a model with an accuracy score of 70% may constitute a considerable innovation to a business that could not make predictions more accurately than with 50%-50% odds.\n\nIndeed, a related issue with treating accuracy as an absolute scale akin to academic grades is that model performance depends on the amount of signal in the data on which it is trained. Data only has so much predictive information in it, and in theory, the way a model should be evaluated is in terms of how close it comes to harnessing that full predictive potential of the data on which it is being trained. Of course, we are not gods, and so we will never know the exact predictive potential of a given dataset, but the principle is one to bear in mind — the potential of a model is bounded by the data on which is being trained, and the only way to get a model that exceeds that true performance frontier is by overfitting your data (creating an illusion of better performance that will not hold up when the model is actually deployed).","type":"content","url":"/passive-prediction-errors#relative-to-what","position":7},{"hierarchy":{"lvl1":"The Right Way To Be Wrong","lvl3":"But What About The Mistakes?","lvl2":"The Problem with Accuracy"},"type":"lvl3","url":"/passive-prediction-errors#but-what-about-the-mistakes","position":8},{"hierarchy":{"lvl1":"The Right Way To Be Wrong","lvl3":"But What About The Mistakes?","lvl2":"The Problem with Accuracy"},"content":"The third reason reporting accuracy scores without context — and indeed the reason that accuracy is a problematic metric in general — is that it tells you nothing about the types of misclassifications your model is making. Are all its errors false positives? Are they all false negatives? In what ratio do they occur?\n\nAccuracy says nothing about how different types of mistakes are being balanced, which is why accuracy is sometimes a fun statistic to use on problem sets but a terrible metric in the real world.","type":"content","url":"/passive-prediction-errors#but-what-about-the-mistakes","position":9},{"hierarchy":{"lvl1":"The Right Way To Be Wrong","lvl2":"ROC and Area Under the Curve (AUC)"},"type":"lvl2","url":"/passive-prediction-errors#roc-and-area-under-the-curve-auc","position":10},{"hierarchy":{"lvl1":"The Right Way To Be Wrong","lvl2":"ROC and Area Under the Curve (AUC)"},"content":"“OK, fine,” I hear you say, “but no one uses accuracy anymore — we all use ROC AUC scores!”\n\nFirst, again, I can tell you from reading hundreds of essays and looking at hundreds of resumes, accuracy is still an extremely commonly used metric. But setting that aside...\n\nYes, AUC is certainly a more holistic metric than accuracy. Where accuracy evaluates the share of cases correctly classified, AUC averages the share of correct positive predictions across the full range of classification thresholds (one of the reasons it is commonly used in competitions). But it is not a substitute for thinking carefully about the correct metric for the specific problem you are seeking to solve.\n\nFirst, most models are deployed at a specific classification threshold, so averaging across all classification thresholds may create a good general purpose indicator of a model’s performance, but it makes AUC poorly suited to evaluating how well a model will perform in any specific context (i.e., at a specific classification threshold).\n\nSecond, the ROC AUC metric is myopically focused on the proportion of correct positive predictions. But depending on our problem, we may also care about the ratio of false negatives to false positives or other properties of our negative predictions.","type":"content","url":"/passive-prediction-errors#roc-and-area-under-the-curve-auc","position":11},{"hierarchy":{"lvl1":"The Right Way To Be Wrong","lvl2":"Choosing the Best Way to be Wrong"},"type":"lvl2","url":"/passive-prediction-errors#choosing-the-best-way-to-be-wrong","position":12},{"hierarchy":{"lvl1":"The Right Way To Be Wrong","lvl2":"Choosing the Best Way to be Wrong"},"content":"How, then, should one approach being more thoughtful about model evaluation?\n\nThe first step is always to evaluate the relative value of the four different types of classifications: true positives, true negatives, false positives, and false negatives. Writing a model that reviews the results of blood tests for signs of a terminal but treatable disease? You probably want to associate a strong negative value with false negatives (where you tell a sick patient they’re healthy) and a smaller negative value with false positives (being told you might have a lethal condition is stressful, even if later tests (which may have their own risks) may show it to be a false positive!). And you may then normalize your true positives and true negatives to zero.\n\nYou can then fit your classification model and, for each classification threshold, calculate the “cost” of the resulting distribution of true and false positives and negatives. Find the model and classification threshold that minimizes this problem-specific cost function, and you’ve identified the model and threshold that’s best for your specific problem.\n\nWhere do these values come from? Sometimes your stakeholder will be able to tell you the actual financial cost of different types of errors (e.g., when deciding whether to issue someone a credit card), but other times these values are more subjective. What’s the relative cost of falsely telling someone they may have a terminal disease condition? How might that vary depending on the risks associated with any followup procedures required to confirm a diagnosis or the amount of time it takes for the diagnosis to be confirmed? Those are hard, subjective questions you may not have the domain expertise to answer yourself. But because you understand the role of these values in how your eventual model will operate, you can raise these questions with your stakeholder (who should have better domain knowledge) and solicit values from them.\n\nNote\n\nUp until now, we’ve emphasized how we manage errors in the context of discrete, binary classification tasks, but it is worth emphasizing that this is only because binary classification is the easiest context in which to think about these problems. However, the issues raised her apply equally to classification tasks with more than two categories, and to efforts to answer Passive Prediction Questions about continuous outcomes. Latent in any model you use is a cost function, and implicit in that cost function is how mistakes are evaluated.\n\nLinear regression, for example, minimizes the sum of squared errors across all observations, and (by default) it gives equal weight to the squared error associated with each observation. But if you don’t feel that’s an appropriate weighting scheme, you are not bound to it — weighted linear regression is a version of linear regression where the user provides a set of weights to associate with each observation. Have some customers you know are more valuable to your company? Perhaps you want to have the model give more weight to errors associated with those customers so the final model performs better for those customers. Or working with data from stores with different sales volumes? Maybe you want to give more weight to stores with larger sales volumes.\n\nDon’t want to work with squared errors at all? Great! There’s a whole discipline called \n\nrobust linear modeling that uses different norms for evaluating errors (often with the goal of reducing the influence of outliers, as the name implies, but all they are doing is modifying how the errors the model seeks to minimize are handled).","type":"content","url":"/passive-prediction-errors#choosing-the-best-way-to-be-wrong","position":13},{"hierarchy":{"lvl1":"The Right Way To Be Wrong","lvl2":"The Ethics of Misclassifications"},"type":"lvl2","url":"/passive-prediction-errors#the-ethics-of-misclassifications","position":14},{"hierarchy":{"lvl1":"The Right Way To Be Wrong","lvl2":"The Ethics of Misclassifications"},"content":"How our models make mistakes is often not just a financial decision; when statistical models are used to make high stakes decisions — like who is sent to prison and who is let out on bail pending trial — how errors are distributed can often be deeply, deeply ethically frought issue.\n\nTo illustrate, let’s consider the example of Risk Assessment models. Risk Assessment models are models used in the US criminal justice system that are designed to help judges and parole boards determine the risk that a criminal defendant or incarcerated person may re-offend if released from jail. These are increasingly commonly used for purposes like determining whether arrested individuals should be released while they await trial and whether incarcerated individuals should be paroled (released before the end of their prison sentence to a half-way house or monitored release).\n\nThe way Risk Assessment models are being used in the US has many, many problems. But a recent debate about an aspect of one of the most commonly used models — the COMPAS Risk Model — is illuminating about the moral issues that arise when handling misclassifications. If you would like to learn more about this debate and difference concepts of algorithmic fairness, I strongly recommend \n\nBias In, Bias Out (2019), a Yale Law Journal article by \n\nSandra G. Mayson.\n\nIn 2016, the investigative news outlet ProPublica published a piece about COMPAS called \n\nMachine Bias. In it, journalists Julia Angwin, Jeff Larson, Surya Mattu and Lauren Kirchner used data from Florida to evaluate how well the COMPAS risk assessment model predicted criminal recitivism (the term for when a criminal defendant commits another crime in the future).\n\nThe \n\nProPublica analysis determined, in part, that:\n\nBlack defendants were often predicted to be at a higher risk of recidivism than they actually were. Our analysis found that black defendants who did not recidivate over a two-year period were nearly twice as likely to be misclassified as higher risk compared to their white counterparts (45 percent vs. 23 percent).\n\nIn other words, the false positive rate for Black defendants was higher than it was for White defendants.\n\nWhile apparently rather damning of the model, COMPAS’ response was that this was actually a consequence of the fact that their model generated equal True Positive Rates across Black and White defendants. And while I am generally loath to defend COMPAS, as I think it has many problems and should not be in use, in this particular case they have a point.\n\nAs Sandra Mayson points out in her paper, the issue is that the likelihood someone will be arrested for a future crime (be arrested for recitivism) is imbalanced by race. As a consequence, a model that has the same True Positive Rate for Black and White defendants (i.e., the share of people predicted to re-offend who do re-offend is the same for both groups) will necessarily have different False Positive Rates for the two groups.\n\nTo illustrate, consider the following figure from Mayson’s paper with two groups, drawn as grey and black. Solid outlines are individuals who do not recitivate, while hollow figures are those who are re-arrested. In the grey group, 2/10 individuals are re-arrested, while only 1/10 are re-arrested in the black group. The vertical line represents the classification threshold used by the model.\n\nNote that this implies the grey outlines are in the situation akin to that of Black Americans (more likely to be arrested for recitivism) and the black outlines are in the position of White Americans (less likely to be rearrested), which is a little confusing.\n\nWith the line in the location shown in the figure, we can see that the model has the same True Positive Rate for both populations — grey and black (50%). But as a result, the False Positive Rate is higher for the grey individuals (2/8). Thus while the ProPublica finding is true — the False Positive Rate of COMPAS is higher for Black defendants — the only way to even this out would be to shift the classification threshold for the black outlines over, as illustrated in Figure 2 from her paper:\n\nThis balances the False Positive Rates for the two groups, but in doing so results in the True Positive Rate being lower for the black outlines.\n\nCan we do better? Well, we could get equal True Positive Rates and False Positive Rates, but only by accepting differential False Negative rates, as illustrated in Mayson’s Figure 3:\n\nAs Mayson writes:\n\nAs this example illustrates, if the base rate of the predicted outcome differs across racial groups, it is impossible to achieve (1) predictive parity; (2) parity in false-positive rates; and (3) parity in false-negative rates at the same time (unless prediction is perfect, which it never is). Computer scientists have provided mathematical proofs of this fact. When base rates differ, we must prioritize one of these metrics at the expense of another. Race neutrality is not attainable.\n\nNote\n\nPlease note that in the discussion of imbalanced recitivism arrest rates, I said arrested for recitivism — a huge problem with all of these risk assessment models is that we know from many studies that even in situations where Black and White Americans commit crimes at similar rates (like drug use), Black Americans are substantially more likely to be arrested for those crimes. Thus, an imbalance in arrests for recitivism do not necessarily imply differences in actual recitivism.\n\nIndeed, this form of inequity is also a problem on the input side — Risk Assessment models take into account whether a defendant has prior convictions, but given Black Americans are more likely to be arrested even in situations where were know criminal behavior occurs at similar rates for Black and White Americans, and Black Americans are likely to have lower-incomes and thus less likely to have lawyers who can get charges dismissed, these models tend to treat them as higher risk.\n\nSo what is the right answer? Well, there isn’t one — each of these different schemes is defensible under different ethical frameworks. And that’s the problem — there’s no algorithm or machine learning metric that can tell you the “right” answer in a situation like this — it requires critical thought, engagement with \n\nprescriptive Questions, and careful discussion with your stakeholder.\n\nAn idea closely related to a point made by Steven Pinker in his 1994 book The Language Instinct: “The main lesson of thirty-five years of AI research is that the hard problems are easy and the easy problems are hard. The mental abilities of a four-year-old that we take for granted – recognizing a face, lifting a pencil, walking across a room, answering a question – in fact solve some of the hardest engineering problems ever conceived... As the new generation of intelligent devices appears, it will be the stock analysts and petrochemical engineers and parole board members who are in danger of being replaced by machines. The gardeners, receptionists, and cooks are secure in their jobs for decades to come.”\n\nThe vast majority of the roughly 10% of scans that are abnormal are eventually determined to be false positives.\n\nIn other words, they have failed to make a mortgage payment for at least a certain period of days.\n\nSee Alexandra Chouldechova, Fair Prediction with Disparate Impact: A Study of Bias in Recidivism Prediction Instruments, 5 BIG DATA 153 (2017) and Jon Kleinberg et al., Inherent Trade-offs in the Fair Determination of Risk Scores, LEIBNIZ INT’L PROC. INFORMATICS, Jan. 2017, at 43:1, 43:4.","type":"content","url":"/passive-prediction-errors#the-ethics-of-misclassifications","position":15},{"hierarchy":{"lvl1":"Performance Differential Is (Often) A Myth"},"type":"lvl1","url":"/interpretable-models","position":0},{"hierarchy":{"lvl1":"Performance Differential Is (Often) A Myth"},"content":"","type":"content","url":"/interpretable-models","position":1},{"hierarchy":{"lvl1":"Performance Differential Is (Often) A Myth"},"type":"lvl1","url":"/interpretable-models#performance-differential-is-often-a-myth","position":2},{"hierarchy":{"lvl1":"Performance Differential Is (Often) A Myth"},"content":"There’s just only so much signal in the data.","type":"content","url":"/interpretable-models#performance-differential-is-often-a-myth","position":3},{"hierarchy":{"lvl1":"Regulatory Compliance"},"type":"lvl1","url":"/interpretable-models#regulatory-compliance","position":4},{"hierarchy":{"lvl1":"Regulatory Compliance"},"content":"","type":"content","url":"/interpretable-models#regulatory-compliance","position":5},{"hierarchy":{"lvl1":"Trusting Model == Trusting Data"},"type":"lvl1","url":"/interpretable-models#trusting-model-trusting-data","position":6},{"hierarchy":{"lvl1":"Trusting Model == Trusting Data"},"content":"","type":"content","url":"/interpretable-models#trusting-model-trusting-data","position":7},{"hierarchy":{"lvl1":"Ethical Transparency"},"type":"lvl1","url":"/interpretable-models#ethical-transparency","position":8},{"hierarchy":{"lvl1":"Ethical Transparency"},"content":"","type":"content","url":"/interpretable-models#ethical-transparency","position":9},{"hierarchy":{"lvl1":"Ease of Adoption"},"type":"lvl1","url":"/interpretable-models#ease-of-adoption","position":10},{"hierarchy":{"lvl1":"Ease of Adoption"},"content":"(Cite study)","type":"content","url":"/interpretable-models#ease-of-adoption","position":11},{"hierarchy":{"lvl1":"No Magic, Not Undue Deference"},"type":"lvl1","url":"/interpretable-models#no-magic-not-undue-deference","position":12},{"hierarchy":{"lvl1":"No Magic, Not Undue Deference"},"content":"Most models internal, where IP-black-box doesn’t matter\n\nHandoff and implementation easier\n\nEthical review.","type":"content","url":"/interpretable-models#no-magic-not-undue-deference","position":13},{"hierarchy":{"lvl1":"Using Causal Questions"},"type":"lvl1","url":"/using-causal-questions","position":0},{"hierarchy":{"lvl1":"Using Causal Questions"},"content":"In our last reading, we learned a little about what it means to measure a causal effect, and why it is inherently difficult. That is a topic we will return to shortly, as understanding why measuring causal effects is hard is key to being able to measure them effectively. But first, take a moment to discuss how Causal Questions come up and are addressed in practice to help contextualize the more technical readings that will follow.\n\nIn our previous readings, we learned how answering different types of questions can help us better understand the world around us. By answering Exploratory Questions, we can better understand the contours of our problem — where our problem is most acute, whether there are groups who have figured out how to get around the problem on their own, etc. This, in turn, can help us prioritize our subsequent efforts. By answering Passive Predictive Questions, we can help identify individual entities — patients, customers, products, etc. — to whom we may wish to pay extra attention or recommend certain products. By answering Passive Predictive Questions, we can also automate tasks by predicting how a person (or more complicated process) would have classified an entity.\n\nIn both cases, however, answering these questions only helps us better understand the world around us. But to the extent to which, as data scientists, we want to intervene to directly address problems, we are rarely interested in just knowing about the world around us — we want to act on the world, and wouldn’t be great if data science could provide us with a set of tools designed to help us predict the consequences of our actions?\n\nEnter Causal Questions. Causal Questions ask what effect we can expect from acting — that is, actively manipulating or intervening — in the world around us in some way. For example, if we pay to show an ad to a specific customer, what will the effect of that choice be the likelihood they buy something on our website? Or if we choose to give a new drug to a patient, what will the effect of that choice be on their disease?\n\nBecause of their potential to help us understand the future consequences of our actions, it should come as no surprise that the ability to answer Causal Questions is of profound interest to everyone from companies to doctors and policymakers. At the same time, however, it may also come as no surprise that answering Causal Questions is an inherently challenging undertaking.\n\nIn this reading, we will discuss where Causal Questions arise in practice, and the workflow one goes about answering them, glossing over the nuances of how exactly we answer Causal Questions. Then in our next reading, we will turn from workflows to theory and discuss in detail what it actually means to measure the effect of an action X (e.g., administering a new drug to a patient, or showing an ad to a user) on an outcome Y (patient survival, customer spending, etc.). This section will, at times, feel a little abstract and woo-woo, but please hang in there. Answering Causal Questions is as much about critical thinking as it is about statistics, and the concepts introduced here will prove crucial to your ability to be effective in this space. We call these two objectives of a study *internal validity* (how well the study answers the Causal Question *in the setting the study is conducted*) and *external validity* (how well the results of the study generalize to the context the stakeholder cares about). And to provide value to a stakeholder, a data scientist's analysis must have both.\n\nInstead, to answer Causal Questions we have to find situations that *approximate* one of these two states of the world. For example, if we were running a website we could change how the website looks for some users, then compare those users' behavior to the behavior of a different group of users who still see the old version of the site. In doing so, we're using the second group of users as a stand-in for what we think the first users would be doing if they still encountered the old site.\n\nSimilarly, we could measure a patient's cholesterol prior to giving the patient an experimental cholesterol drug, then measure it again after they've been on the medication for a few weeks as a way of estimating the effect of the drug. Essentially, we're using the patient before receiving the medication as a stand-in for what we think the patient's cholesterol would have been a few weeks later if they hadn't received the new drug.\n\nBut as we will see, none of these strategies are perfect. In the example of changing the website design for only some users, it's always possible that differences in user behavior between the two groups wasn't the result of the different website, but other differences in the users (like age or gender). And while we can compare our patient's cholesterol before and after taking the experimental drug, it's always possible that the patient's cholesterol was going to change over time anyway, regardless of the medication!\n\nAs these simple examples illustrate while answering Causal Questions is one of the most exciting things we get to do in data science, it is also one of the hardest. And perhaps more than in any other domain of data science, answering Causal Questions—a practice referred to as *causal inference*—will require a *lot* of critical thinking on the part of the data scientist, and a lot of humility. ","type":"content","url":"/using-causal-questions","position":1},{"hierarchy":{"lvl1":"Using Causal Questions","lvl2":"When Do Causal Questions Come Up?"},"type":"lvl2","url":"/using-causal-questions#when-do-causal-questions-come-up","position":2},{"hierarchy":{"lvl1":"Using Causal Questions","lvl2":"When Do Causal Questions Come Up?"},"content":"Causal Questions arise when stakeholders want to do something — buy a Superbowl ad, change how the recommendation engine in their app works, authorize a new prescription drug — but they fear the action they are considering may be costly and not actually work. In these situations, stakeholders will often turn to a data scientist in the hope that the scientist can “de-risk” the stakeholder’s decision by providing guidance on the likely effect of the action before the action is undertaken at full scale.\n\nUsually, the action the stakeholder is considering will not have been pulled out of a hat. Rather, a stakeholder will generally pose a Causal Question because they have some reason to suspect a given course of action may be beneficial. Indeed, Causal Questions often emanate from patterns discovered when answering Exploratory or Passive Predictive Questions.","type":"content","url":"/using-causal-questions#when-do-causal-questions-come-up","position":3},{"hierarchy":{"lvl1":"Using Causal Questions","lvl3":"Where Causal Questions Come From — An Example","lvl2":"When Do Causal Questions Come Up?"},"type":"lvl3","url":"/using-causal-questions#where-causal-questions-come-from-an-example","position":4},{"hierarchy":{"lvl1":"Using Causal Questions","lvl3":"Where Causal Questions Come From — An Example","lvl2":"When Do Causal Questions Come Up?"},"content":"For example, suppose the Chief of Surgery at a major hospital is interested in reducing surgical complications. They begin by asking “What factors predict surgical complications?” (a Passive Predictive Question) and develop a predictive model that allows the hospital to identify patients who are likely to have issues so that caretakers can provide additional support to these patients during recovery.\n\nIn the course of developing this model, the Chief discovers that one of the strongest predictors of surgical complications is patient blood pressure — patients with high blood pressure are substantially more likely to experience complications than those with normal blood pressure.\n\nThis leads the Chief to wonder about whether they could reduce surgical complications if they treated patients with high blood pressure with pressure-reducing medications prior to surgery. In other words, the Chief Surgeon wants to know “What effect treating patients with high blood pressure would have on surgical complication rates?”\n\nBut rather than just starting to give all patients with high blood pressure new drugs (and delay their surgeries while the drugs take effect), the Chief wants you to provide a more rigorous answer to their question. After all, high blood pressure may be causing the complications (and thus the medicine may help), but it could also be that high blood pressure isn’t the cause of the complications, but rather the symptom of a third factor that causes both high blood pressure and complications that makes people with high blood pressure different from those with low blood pressure — like leading an overly stressful life. The Chief doesn’t need to know whether high blood pressure is the cause of complications or just a “warning light” that identifies people at risk to use that information for directing additional support to those patients during recovery; but it does matter for determining whether it makes sense to delay surgeries to teach patient high blood pressure!\n\nThis is, of course, just one example, and it’s not hard to imagine others. Perhaps your online retailer stakeholder has noticed that one of your competitors has stopped showing customer reviews in the search results, for example, so they suspect it must be improving sales for your competitor and want to know if it would work for your site too! But the point is that Causal Questions generally don’t appear out of the blue, but rather because someone has noticed a pattern in the world and wants to act on it. Thus, many Causal Questions may actually take the form of hypotheses or hunches that your stakeholder wants to be investigated.","type":"content","url":"/using-causal-questions#where-causal-questions-come-from-an-example","position":5},{"hierarchy":{"lvl1":"Using Causal Questions","lvl2":"The Two-Fold Challenge of Causal Questions"},"type":"lvl2","url":"/using-causal-questions#the-two-fold-challenge-of-causal-questions","position":6},{"hierarchy":{"lvl1":"Using Causal Questions","lvl2":"The Two-Fold Challenge of Causal Questions"},"content":"In our last reading, we discussed how answering Causal Questions is difficult in part because measuring the effect of any action on any outcome is a definitionally difficult endeavor. But answering Causal Questions is also difficult for a more practical — less epistemological — reason: risk aversion!\n\nAs we noted above, stakeholders generally turn to data scientists because they want to know the likely consequences of an action before they actually undertake the action at full scale. This may seem obvious, but it bears repeating — not only is answering Causal Questions hard because we never get to measure outcomes in both a universe where our treatment occurs and also a universe where it does not (the Fundamental Problem of Causal Inference), but also because stakeholders want to know about the likely consequences of an action they aren’t ready to actually undertake!\n\nAs a result, the job of a data scientist who wants to answer a Causal Question is to design a study that not only measures the effect of a treatment, but also does so in a setting that is enough like the context in which the stakeholder wants to act that any measured effect will generalize to the stakeholder’s context.\n\nWe call these two objectives of a study internal validity (how well the study answers the Causal Question in the setting the study is conducted) and external validity (how well the results of the study generalize to the context the stakeholder cares about). And to provide value to a stakeholder, a data scientist’s analysis must have both.","type":"content","url":"/using-causal-questions#the-two-fold-challenge-of-causal-questions","position":7},{"hierarchy":{"lvl1":"Using Causal Questions","lvl3":"Internal and External Validity: An Example","lvl2":"The Two-Fold Challenge of Causal Questions"},"type":"lvl3","url":"/using-causal-questions#internal-and-external-validity-an-example","position":8},{"hierarchy":{"lvl1":"Using Causal Questions","lvl3":"Internal and External Validity: An Example","lvl2":"The Two-Fold Challenge of Causal Questions"},"content":"To illustrate, suppose you work for a medical device company in Boston that wants the US Food and Drug Administration (FDA) to authorize a new cochlear implant your company has developed (a partially surgically implanted device for helping those with certain types of hearing loss regain hearing). Before authorizing the device, the FDA wants to be sure that it’s safe and effective — in other words, it wants to know what the effect of authorizing the device for patients throughout the United States would be on patient health.\n\nYour job, therefore, is to conduct a study that (a) convincingly measures the effect of the device on patients (has high internal validity), and (b) does so in a way that convinces the FDA that the findings from your study are likely to be the same as what would be seen if the device were being used across the United States (has external validity to the context the FDAs cares about).\n\nIn medical trials, internal validity is usually ensured by conducting a randomized experiment — referred to as a Randomized Control Trial (RCT) in medical circles — according to a set of FDA requirements. We’ll discuss what features must be present for us to have confidence in the results of a randomized experiment soon, but they are things like making sure that the people in the control group look like the people in the treatment group in terms of things we can measure (age, gender, etc.) to help us feel confident that when people were randomly assigned to control and treatment groups, we didn’t end up in a really unlikely situation where, purely by chance, only men ended up in control group and only women ended up in treatment group.\n\nExternal validity, by contrast, comes from things like who is enrolled in the trial. The average age of children getting cochlear implants is between 2 and 3, so if your study only included children between 12 and 18 months of age, the FDA may worry that the results of the study would not generalize to the US population as a whole.\n\nIn the context of a clinical trial, this issue of external validity may seem easy to address — just get a sample of people who “look like” the US population (when applying for US FDA approval)! Historically, however, \n\nwomen and \n\nminorities have been underrepresented in clinical trial participants. Moreover, the people designing clinical trials often limit enrollment to participants who, aside from the specific condition being treated, are healthy to avoid complications. This reduction in complications may increase the internal validity, but as many patients face more than one health challenge, it may reduce external validity.\n\nOutside of drug or medical device trials, however, external validity can much harder to establish. For example, the functionality of many internet services and apps depends on network effects — testing out a new social feature on Instagram by making it available to only a handful of users in a randomized trial (an A/B test, in the language of tech companies) may not give you a meaningful sense of how the feature would be used if it was visible to all users. And the way that bank customers use a new budgeting app in the context of a two-week study may not be indicative of how they would use it over the long run when the feature is no longer new.","type":"content","url":"/using-causal-questions#internal-and-external-validity-an-example","position":9},{"hierarchy":{"lvl1":"Using Causal Questions","lvl3":"External Validity To What","lvl2":"The Two-Fold Challenge of Causal Questions"},"type":"lvl3","url":"/using-causal-questions#external-validity-to-what","position":10},{"hierarchy":{"lvl1":"Using Causal Questions","lvl3":"External Validity To What","lvl2":"The Two-Fold Challenge of Causal Questions"},"content":"Throughout this text, we will refer to whatever course of action the stakeholder is actually considering pursuing as the “stakeholder’s context.” As a result, when discussing the external validity of a study, we will implicitly be referring to its external validity to the stakeholder’s context. But it is worth emphasizing that while the internal validity of a study is a single things — you have some level of confidence that the study measured the effect they set out to measure — external validity is relative. A study conducted in a hospital in Denver, Colorado may have good external validity from the perspective of a doctor in a Pheonix, Arizona hospital, but that same study may not have very good external validity from the perspective of a doctor at a hospital in Pune, India. So always remember that external validity is not an absolute property of an analysis, but a property that is relative to the context to which one wishes to generalize the results.","type":"content","url":"/using-causal-questions#external-validity-to-what","position":11},{"hierarchy":{"lvl1":"Using Causal Questions","lvl2":"The Causal Question Work Flow"},"type":"lvl2","url":"/using-causal-questions#the-causal-question-work-flow","position":12},{"hierarchy":{"lvl1":"Using Causal Questions","lvl2":"The Causal Question Work Flow"},"content":"Before we dive into the technical details of answering Causal Questions, it’s worth starting with a high-level overview of how data scientists approach answering Causal Questions.","type":"content","url":"/using-causal-questions#the-causal-question-work-flow","position":13},{"hierarchy":{"lvl1":"Using Causal Questions","lvl3":"Identify Relevant Previous Studies","lvl2":"The Causal Question Work Flow"},"type":"lvl3","url":"/using-causal-questions#identify-relevant-previous-studies","position":14},{"hierarchy":{"lvl1":"Using Causal Questions","lvl3":"Identify Relevant Previous Studies","lvl2":"The Causal Question Work Flow"},"content":"Once a Causal Question has been posed, the next step is to identify any research that has already been done that may help answer your causal question. It’s hard to overstate how often this step is overlooked by data scientists, but it’s such a no-brainer once you think of it! There’s no reason to spend days or weeks trying to design a study to answer a question if someone else has already put the time and money into doing it for you!\n\nIf your stakeholder is somebody who works in public policy or medicine, then the first place to look for previous studies is in academic medical or policy journals. But don’t assume that if you aren’t working on a medical or public policy question you won’t be able to find an answer to your question in academic or pseudo-academic publications — lots of data scientists present research done at private companies at ``industry’’ conferences like the \n\nMIT Conference on Digital Experimentation (CODE@MIT) or the \n\nNetMob Cellphone MetaData Analysis Conference!\n\nAnd if you are at a company, ask around! Someone at your own company may have looked into a similar question before, and talking to them could save you a lot of effort.","type":"content","url":"/using-causal-questions#identify-relevant-previous-studies","position":15},{"hierarchy":{"lvl1":"Using Causal Questions","lvl3":"Evaluate Previous Studies","lvl2":"The Causal Question Work Flow"},"type":"lvl3","url":"/using-causal-questions#evaluate-previous-studies","position":16},{"hierarchy":{"lvl1":"Using Causal Questions","lvl3":"Evaluate Previous Studies","lvl2":"The Causal Question Work Flow"},"content":"If you do find studies, then for each study you will have to ask yourself two questions:\n\nDid the study authors do a good job of answering the Causal Question? in the context they were studying?\n\nDo I believe that the context in which the study was conducted is similar enough to my own context that their conclusions are relevant to me?\n\nThis first question is about the internal validity of the study, and we’ll talk at length about how to evaluate that in the context of causal inference in the coming weeks. The second question is about the external validity (i.e., the generalizability) of the study to your context. There are lots of extremely well-conducted studies in the world that may be seeking to answer the same question as you, but if, for example, they investigated the effect of a new drug in young patients, and your hospital only treats very old patients, you may not be comfortable assuming their results are good predictors for what might happen in your hospital.","type":"content","url":"/using-causal-questions#evaluate-previous-studies","position":17},{"hierarchy":{"lvl1":"Using Causal Questions","lvl3":"Plan A New Study","lvl2":"The Causal Question Work Flow"},"type":"lvl3","url":"/using-causal-questions#plan-a-new-study","position":18},{"hierarchy":{"lvl1":"Using Causal Questions","lvl3":"Plan A New Study","lvl2":"The Causal Question Work Flow"},"content":"If you were unable to find any studies that answer your Causal Question satisfactorily (either on their own or in combination), then it may be time to do a study of your own!\n\nWhen most people think about answering Causal Questions, their minds immediately jump to randomized experiments. Randomized experiments are often the best strategy for trying to answer Causal Questions, but they are not always the best choice.\n\nStudies designed to answer Causal Questions can be divided into roughly two types: experimental studies and observational studies.\n\nIn an experimental study, a researcher has control over everything that happens in the study, including who enrolls in the study and also who in the study gets assigned to the treatment group and who gets assigned to the control group. Nearly all clinical trials, A/B tests where the version of a website or app users see is randomly determined, and field experiments where, say, voters are randomly assigned to receive different types of mailers from political campaigns to measure their effect on voter turnout are all examples of “experimental studies.”\n\nIn an observational study, by contrast, researchers use data from a context where the researchers did not control who was treated and who was not. This includes data from public opinion surveys, data on user behavior and demographics, or census data.\n\n(We say studies can be divided into roughly two types because some studies fall into a category sometimes called “quasi-experimental.” In these studies, researchers were not in control over who was treated and who was not, but they have some reason for thinking that something in the world — like a chance storm, or a draft lottery — caused who was treated and who was not to be determined randomly. But these types of studies tend to be more relevant for academics than applied data scientists, and evaluating them is incredibly difficult, so we will largely ignore them in this text.)\n\nWhile it is sometimes believed that only experimental studies can generate valid answers to Causal Questions, this is unequivocally untrue, as is the slightly more generous version of this claim, that experimental studies always constitute the best form of evidence for answering Causal Questions. As we will explore in great detail in the coming days, the validity of conclusions drawn from both experimental and observational studies rests on whether a number of fundamentally untestable assumptions hold. As a result, both types of studies are capable of providing meaningful answers to causal questions and of being deeply misleading.\n\nMoreover, while experimental studies often (but not always) have greater internal validity (they are often better able to ensure that they have measured the true causal effect in the lab), this often comes at the expense of lower external validity, because ensuring the researchers can control who is treated and who is not requires operating the study take place in a highly monitored, often artificial and unrealistic setting. Observational studies, by contrast, are often based on data collected in the real world, and as a result may yield answers that tell us more about what is likely to happen in our own real-world application, even if they have somewhat lower internal validity.","type":"content","url":"/using-causal-questions#plan-a-new-study","position":19},{"hierarchy":{"lvl1":"Using Causal Questions","lvl2":"Wrapping Up and Next Steps"},"type":"lvl2","url":"/using-causal-questions#wrapping-up-and-next-steps","position":20},{"hierarchy":{"lvl1":"Using Causal Questions","lvl2":"Wrapping Up and Next Steps"},"content":"Hopefully, this reading has given you a better sense of how Causal Questions are used to solve stakeholder problems, and when and where they come up in the life of a practicing data scientist. In the readings that follow, we will turn first to the details of the Potential Outcomes Model, a rigorous, formal statistical framework for understanding the Counterfactual Model of Causality. This framework will not only provide a presentation of the Counterfactual Model of Causality that may be appealing to those who draw intuition from mathematical formalism, but also machinery that we can use to evaluate how much confidence we can have in answers generated using different methods of answering Causal Questions — including both experimental and observational studies.\n\nIn 1977, the FDA actually banned enrollment of women of “childbearing potential” from Phase 1 and Phase 2 clinical trials in the \n\ninterest of avoiding birth defects.\n\nThis seems likely to be due, in part, to hesitancy to enroll in clinical trials by individuals aware of past abuses of minority patients, as in the \n\nTuskegee Syphilis Study.","type":"content","url":"/using-causal-questions#wrapping-up-and-next-steps","position":21},{"hierarchy":{"lvl1":"Answering Causal Questions"},"type":"lvl1","url":"/answering-causal-questions","position":0},{"hierarchy":{"lvl1":"Answering Causal Questions"},"content":"In this reading, we turn the surprisingly slippery question “What do we mean when we say X causes Y, and how do we measure the effect of an action X (e.g., administering a new drug to a patient, or showing an ad to a user) on an outcome Y (patient survival, customer spending, etc.)?”\n\nThis section will, at times, feel a little abstract and woo-woo, but please hang in there. Answering Causal Questions is as much about critical thinking as it is about statistics, and the concepts introduced here will prove crucial to your ability to be effective in this space.","type":"content","url":"/answering-causal-questions","position":1},{"hierarchy":{"lvl1":"Answering Causal Questions","lvl2":"What Does It Mean for X to Cause Y?"},"type":"lvl2","url":"/answering-causal-questions#what-does-it-mean-for-x-to-cause-y","position":2},{"hierarchy":{"lvl1":"Answering Causal Questions","lvl2":"What Does It Mean for X to Cause Y?"},"content":"To understand what it means to answer a Causal Question, and why answering Causal Questions is intrinsically hard, we must start by taking a step back to answer the question: “what do we mean when we say some action X causes a change in some outcome Y?”\n\nSeriously, what do we mean when we say “X causes Y?” Try and come up with a definition!\n\nWhile this question may seem simple, it turns out that this question has been the subject of serious academic debate for hundreds of years by philosophers no less famous than David Hume. Indeed, even today there is still debate over how best to answer this question.\n\nIn this course, we will make use of the Counterfactual Model of Causality (sometimes called the Neyman-Rubin causal model). In plain English, it posits that for “doing X to cause Y”, it must be the case that if we do X, then Y will occur, and if we did not do X, then Y would not occur. This is by far the most used definition of causality today, and yet remarkably, it only emerged in the 20th Century and was only really fleshed out in the 1970s. Yeah... that recently.\n\nCounterfactual Model of Causality\n\nFor it to be the case that doing X causes Y\", it must be the case that if we do X, then Y will occur, and if we did not do X, then Y would not occur.","type":"content","url":"/answering-causal-questions#what-does-it-mean-for-x-to-cause-y","position":3},{"hierarchy":{"lvl1":"Answering Causal Questions","lvl2":"Measuring the Effect of X on Y"},"type":"lvl2","url":"/answering-causal-questions#measuring-the-effect-of-x-on-y","position":4},{"hierarchy":{"lvl1":"Answering Causal Questions","lvl2":"Measuring the Effect of X on Y"},"content":"At first blush, this definition may seem simple. But its simplicity belies a profoundly difficult practical problem. See, this definition relies on comparing the value of our outcome Y in two states of the world: the world where we do X, and the world where we don’t do X. But as we only get to live in one universe, we can never perfectly know what the value of our outcome Y would be in both a world where we do X and one where we don’t do X for a given entity at a given moment in time. As such, we can never directly measure the causal effect of X on Y for a given entity (say, a given patient or customer) at a given moment in time — a problem known as the Fundamental Problem of Causal Inference (causal inference being what people call the practice of answering Causal Questions).\n\nTo illustrate, suppose we were interested in the effect of taking a new drug (our X) on cancer survival (our Y) for a given patient (a woman named Shikha who arrived at the hospital on June 18th 2022). We can give her the drug and evaluate whether she is still alive a year later, but that alone can’t tell us whether the new drug caused her survival according to our counterfactual model of causality — after all, if she survives maybe she would have survived even without the drug! To actually know the effect of the drug on Shikha by direct measurement, we would have to be able to measure her survival both in the world where we gave her the drug and the world where we did not and compare outcomes.\n\nSince we can never see both states of the world — the world where we undertake the action whose effect we want to understand and the world where we don’t — almost everything we do when trying to answer Causal Questions amounts to trying to find something we can measure that we think is a good approximation of the state of the world we can’t actually see.\n\nA quick note on vocabulary: by convention, we refer to the action whose effect we want to understand as a “treatment,” and the state of the world where an entity receives the treatment as the “treated condition.” Similarly, we refer to the state of the world where an entity does not receive the treatment as the “control condition.” We use this language even when we aren’t talking about medical experiments or even experiments at all. We also refer to the state of the world we cannot observe as the “counterfactual” of the world we can observe — so the world where Shikha does not get the cancer drug is the counterfactual condition to the world where Shikha does get the drug.\n\nIt’s at this point most people start throwing out “but what about...”'s, and that’s good! You should be — that’s exactly the kind of thinking you have to do when trying to answer Causal Questions. For example, “what about if we measured the size of Shikha’s tumor before she took the drug and compared it to the size of her tumor after? If the tumor got smaller as soon as she started the drug, then surely the drug caused the tumor to shrink!”\n\nMaybe! Implicitly, what you have done is asserted that you think that the size of Shikha’s tumor before we administered the drug is a good approximation for what you think the size of Shikha’s tumor would have been had we not given her the drug.\n\nBut this type of comparison will always fall short of the Platonic ideal given by our definition of causality. Yes, Shikha’s tumor may have stayed the same size if we had not given her the drug (in which case the size of the tumor before she took the drug would be a good approximation), but it is also possible that regardless of whether we’d given her the drug, her cancer would have shrunk on its own.\n\nAccording to the Counterfactual Model of Causality, we could only ever know if taking the drug caused a decrease in tumor size if we could both administer the drug and observe the tumor and also observe a parallel world in which the same person at the same moment in time was not given the drug for comparison. And since we can never see this parallel world — the counterfactual to the world we observe — the best we can do is come up with different, imperfect tricks for approximating what might have happened in this parallel world, like comparing the tumor size before and after we administer the drug, imperfect though that may be.\n\nSo does that mean we’re doomed? Yes and no. Yes, it does mean that we’re doomed to never be able to take the exact measurements that make it possible to directly answer a Causal Question. But no, that doesn’t mean we can’t do anything — in the coming weeks, we will learn about different strategies for approximating counterfactual conditions, and in each case we will learn about what assumptions must be true for our strategy to provide a valid answer to our Causal Question. By making the assumptions that underlie each empirical strategy explicit, we will then be able to evaluate the plausibility of these assumptions.\n\nIn the example of Shikha, for example, we know that our comparison of tumor size before taking the drug to tumor size after taking the drug is only valid if her tumor would not have gotten smaller without the drug. This is something we can’t measure directly, but we can look to other patients with similar tumors, or the history of her tumor size to evaluate how often we see tumors get smaller at the rate observed after she took the drug. If it’s very rare for these types of tumors to ever get smaller, than we can have more confidence that a decrease in tumor size was the result of the drug.\n\nWe are also sometimes in a position to be more proactive than our effort to answer Causal Questions. Rather than trying to make inferences from the world around us using what is termed “observational data” (data that was generated through a process we did not directly control, a process we only “observe”), we can sometimes generate our own data through randomized experiments.\n\nRandomized experiments — perhaps the most familiar tool for answering Causal Questions — are also just another way of approximating the unobservable counterfactual condition. In a randomized experiment — also known as “Randomized Control Trials (RCTs)”, or “A/B Tests” whether you’re hanging out with statisticians, doctors, or web developers — participants are assigned to either receive the treatment (the treatment group) or not (the control group) based on the flip of a coin, a roll of a die, or more commonly a random number generator on a computer. Provided we have enough participants, the Law of Large Numbers then promises that, on average, the people assigned to the control group will (probably) be “just like” the people assigned to the treatment group in every possible way (save being treated). Subject to a few other assumptions we’ll discuss in great detail later, that means that the outcomes of the control group — being just like the treatment group on average — will be a good approximation of what would have happened to the treatment group in a world where they did not receive the treatment.\n\nRandomized experiments are not a silver bullet, however. The validity of experimental comparisons still rests on a number of assumptions, many of which cannot be directly tested. For example, we can never be entirely sure that when we randomly assigned people to control and treatment groups, the process was truly random, or that we ended up with people who were similar in both groups (the law of large numbers only promises that getting similar groups becomes more likely as the size of the groups increases, not that it will happen with certainty!). Moreover, conducting a randomized experiment requires working in a context where the researcher can control everything, and that can sometimes generate results that may not generalize to the big messy world where you actually want to act.","type":"content","url":"/answering-causal-questions#measuring-the-effect-of-x-on-y","position":5},{"hierarchy":{"lvl1":"Answering Causal Questions","lvl2":"So where does that leave us?"},"type":"lvl2","url":"/answering-causal-questions#so-where-does-that-leave-us","position":6},{"hierarchy":{"lvl1":"Answering Causal Questions","lvl2":"So where does that leave us?"},"content":"For many data scientists, this will feel profoundly dissatisfying. Many people come to data science because of the promise that it will provide direct answers to questions about the world using statistics. But because of the Fundamental Problem of Causal Inference, this will never be possible when answering Causal Questions. Rather, the job of a data scientist answering Causal Questions is a lot like the job of a detective trying to solve a crime — your task is to determine what probably happened at a crime scene. You can gather clues, collect forensic evidence, and interview suspects, all in an effort to come up with the most likely explanation for a crime. But no matter how hard you try, you can’t go back in time to witness the crime itself, so you will never be able to be entirely sure if you are right or not.\n\nBut just as we investigate and prosecute crimes despite our inability to ever be 100% certain an arrested suspect is guilty, so too must businesses and governments make decisions using the best available evidence, even when that evidence is imperfect. But it is our job, as data scientists, to help provide our stakeholders with the best available evidence, and also to help them understand the strength of the evidence we are able to provide.","type":"content","url":"/answering-causal-questions#so-where-does-that-leave-us","position":7},{"hierarchy":{"lvl1":"Answering Causal Questions","lvl2":"Why Passive-Prediction Is Not Enough"},"type":"lvl2","url":"/answering-causal-questions#why-passive-prediction-is-not-enough","position":8},{"hierarchy":{"lvl1":"Answering Causal Questions","lvl2":"Why Passive-Prediction Is Not Enough"},"content":"At this point, it is worth pausing to reflect on a question it may not have occurred to you to ask above — if answering Causal Questions is usually about predicting what would happen if we were to act on the world in a certain way, then how/why is it different from answering the kind of Passive-Prediction Questions we discussed previously?\n\nThere are a number of different ways one can frame the answer to this question, but the one I like most for Data Scientists is that  when answering a Passive-Predictive Question, we can usually achieve our goals simply by identifying correlations that we think are likely to persist into the future. For example, suppose we run the maintenance department for a rental car company. The fact that a car whose Check Engine light is on is a car that is likely to break down if it isn’t taken to a mechanic is enough for us to identify cars in trouble! Obviously, the Check Engine light isn’t causing the cars to break down, but it doesn’t have to to be useful.\n\nBut when seeking to answer Causal Questions, we wish to go beyond just identifying cars in trouble, and instead predict what might happen to cars if we chose to act in different ways. This requires going beyond simple Passive-Prediction because, in choosing to act, we are asking about how things might turn out in a world where we are behaving differently than we are currently — in other words, we are no longer being passive.\n\nThus, in a sense, answering Causal Questions is therefore always an example of “out-of-sample extrapolation” or “out-of-sample prediction”, because by definition we are saying we want to know what happens in a world where at least one major agent — us! — changes their behavior. And indeed, there’s a very real sense in which that’s what we mean by a causal relationship: a relationship between our actions and an outcome that would persist even if we change our behavior!\n\nWhat’s a situation where a correlation is sufficient for Passive Prediction but not answering a Causal Question? Well, let’s go back to our example of the rental car maintenance manager — suppose rather than using Check Engine lights to identify cars that needed more attention, the manager decided to just cut the cables that run to all the Check Engine lights! After all, the cars that are breaking down all have their Check Engine light on, and the cars that don’t have their Check Engine lights almost never break down! So why not just disable the Check Engine lights on all these cars so they stop breaking down?\n\nNow that we’ve been clear about what we mean when we ask “does X cause Y?”, we can now understand why this is a perfect example of why correlation does not always imply causation.\n\nFundamentally, the manager is asking “would cutting the cables to the Check Engine lights prevent our cars from breaking down?” For that to be true, we know that in an ideal universe, we would want to compare a car on the verge of breaking down that has its Check Engine light intact to that same car in a world where we cut the Check Engine light — then we can see if there is a difference in whether these cars break down!\n\nBut this is not the data our manager has turned to draw their conclusion — rather, they are comparing cars with their Check Engine lights on and cars without their Check Engine lights on. And it turns out that cars without their Check Engine lights on are not a good approximation for the cars with their Check Engine lights on because the cars without the light on are different from the cars with the light on in ways that matter for the likelihood of breaking down (they have engine problems!) other than the Check Engine light!\n\nDepending on what classes you may have taken in the past, you may have heard these differences referred to as “confounders” or “omitted variables” — those are just different words or ways of talking about the same idea! Confounders or omitted variables are just different words for features that are different between the “treated” and “untreated” observations being examined that the untreated observations are bad approximations of the counter-factual condition for the treated observations!","type":"content","url":"/answering-causal-questions#why-passive-prediction-is-not-enough","position":9},{"hierarchy":{"lvl1":"Answering Causal Questions","lvl2":"Next Steps"},"type":"lvl2","url":"/answering-causal-questions#next-steps","position":10},{"hierarchy":{"lvl1":"Answering Causal Questions","lvl2":"Next Steps"},"content":"In this reading, we learned — in an intuitive sense — why answering Causal Questions is inherently hard. But this explanation, while accurate, is a little informal to be rigorous. In the readings that follow, we will be introduced to the Potential Outcomes Framework — the formal statistical framework that underlies the Neyman-Rubin Counterfactual Model of Causality. This framework will help us reason more systematically about how and when methods like randomized experiments, linear regression, matching, and differences-in-differences can help us answer Causal Questions.\n\nBut first, in the interest of not losing perspective on the forest for the trees, a discussion of how Causal Questions are used in practice.\n\nThe fact that diseases naturally change over time on their own is known as a disease’s “natural history.”","type":"content","url":"/answering-causal-questions#next-steps","position":11},{"hierarchy":{"lvl1":"The Potential Outcomes Framework"},"type":"lvl1","url":"/potential-outcomes","position":0},{"hierarchy":{"lvl1":"The Potential Outcomes Framework"},"content":"We’ve all heard the saying “correlation does not imply causation.” And that’s true, as far as it goes. But the saying would be more accurate (albeit less catchy) if it were “correlation does not necessarily imply causation.” That’s because while it is true that correlation does not always imply causation, it does under certain circumstances.\n\nIn this chapter, we will learn about the Potential Outcomes Framework. The Potential Outcomes Framework introduces mathematical notation to our discussion of parallel universes, and in doing so allows us to reason far more rigorously about causal effects.\n\nCrucially, the Potential Outcomes Framework will also allow us to be very precise about what it is we are measuring when we measure a correlation, what we need to measure in order to answer a Causal Question, and what must be true for those two quantities to be the same.","type":"content","url":"/potential-outcomes","position":1},{"hierarchy":{"lvl1":"The Potential Outcomes Framework","lvl2":"The Potential Outcomes Set Up"},"type":"lvl2","url":"/potential-outcomes#the-potential-outcomes-set-up","position":2},{"hierarchy":{"lvl1":"The Potential Outcomes Framework","lvl2":"The Potential Outcomes Set Up"},"content":"The potential outcomes framework is built around the idea that we all have well-defined potential outcomes that would be observed if we were to be exposed to a treatment, and also potential outcomes that would be observed if we were not (i.e., we were exposed to a “control” condition). These potential outcomes are fixed and defined values within each of us. But, of course, the challenge is that we can only ever observe ourselves in one state of exposure.\n\nLet’s suppose that we are interested in the effect of some treatment T on an outcome Y for a population of individuals i \\in {1, 2, 3... N}.\n\nFor ease of exposition, we will begin by assuming that our treatment T is a binary treatment, meaning it can only take on two values: T \\in \\{0, 1\\}. There’s nothing special about binary treatments, but they simplify notation, and so we often use them when discussing the potential outcomes framework, though everything we discuss here generalizes to continuous treatments.\n\nWarning\n\nAlthough we use the terminology treatment and control — terms you have most often encountered in the context of clinical trials — there is no, I repeat, no notion of randomization here. We can read T=1 as “with the causal factor of interest present” and T=0 as “without the causal factor of interest present,” where the reason for the presence or absence of the causal factor of interest is unknown.\n\nThis is often a source of confusion, so it bears repeating. We call this a treatment, but in doing so we do not imply that the receipt of treatment came from a randomized application. Instead, we are simply saying that T=1, for instance, indicates a state in which the causal factor of interest is present.\n\nCorresponding to the two values of our treatment variable, we also have two values of our outcome variable — Y_i — for each individual. In particular, an individual i has both a potential outcome under the treatment condition (i’s value of Y in a world where i receives the treatment):Y^{T=1}_i \\equiv Y^{1}_i\n\nand a potential outcome under the control condition (i’s value of Y in a world where i does not receive the treatment):Y^{T=0}_i \\equiv Y^{0}_i\n\nWe can think about these individual-level realizations of the random variable as the potential outcomes in different theoretical states of the world that we all carry within ourselves. We have a potential outcome for if the world is T=1, and we have a potential outcome for if the world is T=0. They both exist simultaneously in us, though we are only able to observe one.","type":"content","url":"/potential-outcomes#the-potential-outcomes-set-up","position":3},{"hierarchy":{"lvl1":"The Potential Outcomes Framework","lvl3":"The Observed Outcomes Set Up","lvl2":"The Potential Outcomes Set Up"},"type":"lvl3","url":"/potential-outcomes#the-observed-outcomes-set-up","position":4},{"hierarchy":{"lvl1":"The Potential Outcomes Framework","lvl3":"The Observed Outcomes Set Up","lvl2":"The Potential Outcomes Set Up"},"content":"Now that we have defined the potential outcomes, let’s discuss the set up for observed outcomes. Where T was in effect the theoretical treatment condition that allowed us to define potential outcomes for a theoretically applied causal factor, we use D to refer to the observed receipt of either treatment or control.D \\in \\{0,1\\}\n\nAs with T, whether D is equal to zero or one is not (necessarily) a function of randomization. We should read D_i = 1 as “observed with the causal factor of interest” and read D_i = 0 as “observed without the causal factor of interest.”\n\nBecause D is observed, not just potential, it is not possible for an individual to simultaneously be observed in treatment and control. Therefore, for individual iD_{i} = 0 \\text{ or } D_{i} = 1\n\nEither we have an individual observed with the causal factor of interest present, or without the causal of interest present, but not both.\n\nIt follows that, for a given value of D — that is, for the given observed presence of the causal factor of interest or not — we will only ever be able to observeY^0_i  \\text{ if } D_{i} = 0\n\norY^1_i  \\text{ if } D_{i} = 1\n\nBut for any individual i, we cannot observe both.\n\nNote\n\nWhy D? Honestly, I’m not sure, but I think it’s related to the term “dummy variable,” which is another term for an indicator variable. When analyzing actual, observed data, one often finds a dummy variable in the data that indicates whether a given observation was exposed to treatment or not. Since that dummy is indicating the actual, observed treatment status of an observation, it (kind of) makes sense to call this variable D.\n\nWarning\n\nThere is a natural tempatation to think of T and D symmetrically, given that both take on two values and are related to treatment exposure. Avoid this temptation.\n\nWhere the potential outcome frameworks assumes all entities have outcomes defined under both conditions of T (Y^0_i and Y^1_i), any given entity has only one value of D_i. In the world we live, each entity either did or did not experience the treatment.\n\nSo while T relates to a pretty abstract notion of parallel worlds, D just defines two different populations of entities in the data.)\n\nD_i just defines two different populations of entities in the data.","type":"content","url":"/potential-outcomes#the-observed-outcomes-set-up","position":5},{"hierarchy":{"lvl1":"The Potential Outcomes Framework","lvl2":"Defining The Causal Effect"},"type":"lvl2","url":"/potential-outcomes#defining-the-causal-effect","position":6},{"hierarchy":{"lvl1":"The Potential Outcomes Framework","lvl2":"Defining The Causal Effect"},"content":"Now that we have that notation out of the way, let’s apply it to the definition of causation we introduced in our previous readings. We previously said that the effect of some treatment T on Y for an individual i is the difference in i’s outcomes in a world where the individual receives the treatment and i’s outcomes in a world where they do not. In our new notation, we can call this quantity \\delta_i, and write it as:\\delta_i = Y^1_i - Y^0_i\n\nThat is, for individual i, the causal effect, defined as \\delta_i, is the difference between the individual potential outcome for the state of the world where the causal factor is present, minus the potential outcome for the state of the world where the causal factor is not present.\n\nOf course, this is clearly a quantity we’ll never be able to observe — no person is ever able to be both subject to the treatment and not be subject to the treatment. And so for reasons that will become obvious later, we’ll need to move from estimating an individual quantity to estimating a quantity for a population.\n\nWhen we move from the individual to the population, the causal effect needs to be defined as some sort of summary statistic that incorporates the information from the realization of the random variables Y^{T} for all individuals.\n\nThe first quantity we will investigate is the Average Treatment Effect, abbreviated as the ATE. We can define this quantity as:\\begin{aligned}\n    ATE =& \\frac{1}{N}\\sum_{i \\in {1, 2, 3 ... N}}\\delta_i \\\\\n    =& \\frac{1}{N}\\sum_{i \\in {1, 2, 3 ... N}}Y^1_i - Y^0_i\n\\end{aligned}\n\nTo avoid the constant need for summation notation, however, let’s assume our data is a random sample from the population we care about and move to working with expectations (E()):\n\n$$\n\\begin{aligned}ATE & = E(\\delta_i) \\\\\n& = E(Y^1_i - Y^0_i) \\\\\n& = E(Y^1_i) - E(Y^0_i)\n\n\\end{aligned}\n$$\n\n(We can bring the expectation inside the parentheses in this last step because the expectation is a linear operator.)\n\nThe equation above is similar in look and interpretation to \\delta_i at the individual level further above. And the logic is exactly the same. We have simply moved from assessing the causal effect for an individual to assessing an average causal effect for a population, and thus taken the expected value of the individual-level causal effects for our entire population.\n\nWhy do we care about the Average Treatment Effect? While not perfect, it is our best guess for the average change in our outcome of interest we would observe if everyone in the population we are studying were subject to treatment. Thinking about authorizing a new prescription drug? You want to know the average effect it will have across all patients who take it. Thinking about launching a big advertising campaign? You want to know the average effect it will have on all the consumers who see it. ATE, in other words, is the quantity your stakeholder — who wants you to answer a Causal Question because they want you to predict the effect of some action they’re thinking of taking — wants to know.","type":"content","url":"/potential-outcomes#defining-the-causal-effect","position":7},{"hierarchy":{"lvl1":"The Potential Outcomes Framework","lvl2":"What Is a Correlation?"},"type":"lvl2","url":"/potential-outcomes#what-is-a-correlation","position":8},{"hierarchy":{"lvl1":"The Potential Outcomes Framework","lvl2":"What Is a Correlation?"},"content":"Having established the quantity we want to measure — the Average Treatment Effect for a population, ATE = E(Y^1_i) - E(Y^0_i) — let’s pause for a moment to come at things from the other side.\n\nWe have established that ATE is what we want to measure. But the fact we will never be able to observe both Y^0 and Y^1 for our full populations — and thus we can never directly observe E(Y^1_i) - E(Y^0_i) — remains true. So let’s pause for a moment to ask: “What can we observe?”\n\nThe first thing we can observe is outcome Y^0_i for all i that weren’t actually subject to treatment (i.e., for whom D_i = 0). Given that, we can estimate:E(Y^0_i | D_i = 0)\n\nAnd we can observe Y^1_i for all i that were actually subject to treatment (i.e., for whom D_i = 1). So we can also estimate:E(Y^1_i | D_i = 1)\n\nAnd if we estimate the difference between the outcomes for these two populations — those who were treated (D_i =1) and those who were not (D_i = 0) — we get the following quantity:E(Y^1_i | D_i = 1) - E(Y^0_i | D_i = 0)\n\nWhat is this? Well, it turns out that, for a binary treatment, this is the correlation between being treated and our outcome Y. It is, in fact, the exact quantity you get from a linear regression of Y on D!\n\nAnd this is where all this notational work gets interesting. Most statistics students throw up a slide at the end of any presentation that says “but of course correlation does not imply causation” and move on — invoking this saying like an incantation they hope will protect them from critical questions. But we don’t have to be like most statistics students anymore.\n\nNow that we’ve rigorously defined what we measure when we estimate an empirical correlation, and we know what need to measure in order to measure a causal effect, we can ask: when are these two equal? Because if we can detail the conditions under which these two quantities are the same, then we’ve identified the situations in which correlation does imply causation.\n\nNote\n\nIf this type of conditioning notation (the | D_i = 1 inside expectation) feels foreign, just think of it as subsetting the population for which you are estimating average outcomes. Again, D is just a variable for differenting between the two populations in our data — those that were exposed to the treatment and those that were not.","type":"content","url":"/potential-outcomes#what-is-a-correlation","position":9},{"hierarchy":{"lvl1":"The Potential Outcomes Framework","lvl2":"Correlation and Causation"},"type":"lvl2","url":"/potential-outcomes#correlation-and-causation","position":10},{"hierarchy":{"lvl1":"The Potential Outcomes Framework","lvl2":"Correlation and Causation"},"content":"Let’s begin by giving the empirical correlation between treatment and outcomes a name. As we’re trying to estimate the Average Treatment Effect (ATE), we will use the convention of adding a “hat” to a variable to indicate it is an empirically estimated quantity (rather than the “true”) quantity. Thus our correlation betweens:\\widehat{ATE} = E(Y^1_i | D_i = 1) - E(Y^0_i | D_i = 0)\n\nSo when does this equal E(Y^1_i) - E(Y^0_i)? Let’s apply a few manipulations to see if we can get \\widehat{ATE} to look like ATE.\n\nFirst,  we use that classic math trick of adding and subtracting a carefully chosen term to an equation. This addition and subtraction offsets, so this is the same as adding 0 (and is thus allowed), but ends up being very helpful. In particular, we will add and subtract E(Y_i^0|D_i = 1):\\widehat{ATE }=  E(Y_i^1|D_i = 1) - E(Y_i^0|D_i = 0) + \\underbrace{E(Y_i^0|D_i = 1) - E(Y_i^0|D_i = 1)}_\\text{(Add up to zero)}\n\nWe can then shuffle these terms around to isolate two distinct quantities of interest: The Average Treatment Effect on the Treated (ATT), and Baseline Differences:\n\n$$\n\\begin{aligned}\n\n\\widehat{ATE }&=  E(Y_i^1|D_i = 1) - E(Y_i^0|D_i = 0) + E(Y_i^0|D_i = 1) - E(Y_i^0|D_i = 1) \\\n&= \\underbrace{E(Y^1_i|D_i = 1) - E(Y_i^0|D_i = 1)}\\text{ATT} + \\underbrace{E(Y^0_i|D_i = 1) - E(Y_i^0|D_i = 0)}\\text{Baseline Difference}\n\n\\end{aligned}\n$$","type":"content","url":"/potential-outcomes#correlation-and-causation","position":11},{"hierarchy":{"lvl1":"The Potential Outcomes Framework","lvl3":"Baseline Differences","lvl2":"Correlation and Causation"},"type":"lvl3","url":"/potential-outcomes#baseline-differences","position":12},{"hierarchy":{"lvl1":"The Potential Outcomes Framework","lvl3":"Baseline Differences","lvl2":"Correlation and Causation"},"content":"Let’s actually start with the second of these quantities, Baseline Differences.  In substantive terms, Baseline Differences is just the difference in our outcome Y that would exist between our two groups (who actually did receive the treatment (D_i = 1) and the people who didn’t (D_i = 0)) in a world where no one was treated. That’s why we call these “baseline” differences — they are differences in outcomes that we would observe even in a world that the treatment we are interested didn’t exist.\n\nWhile I will use the term Baseline Differences for this quantity in this book, it also corresponds to the concept of “confounders” — factors that create a difference in outcomes between the treated group and the untreated group that are not caused by the treatment.\n\nUnsurprisingly, therefore, the first condition that must be met for our correlation to imply causation (for \\widehat{ATE} to equal ATE) is for there to be no baseline differences:\n\nNo Baseline Differences:0 = E(Y^0_i|D_i = 1) - E(Y_i^0|D_i = 0)\n\nWhen true, our equation for \\widehat{ATE} simplifies substantially from:\\widehat{ATE} = \\underbrace{E(Y^1_i|D_i = 1) - E(Y_i^0|D_i = 1)}_\\text{$ATT$} + \\underbrace{E(Y^0_i|D_i = 1) - E(Y_i^0|D_i = 0)}_\\text{Baseline Difference}\n\nto\\widehat{ATE} = \\underbrace{E(Y^1_i|D_i = 1) - E(Y_i^0|D_i = 1)}_\\text{$ATT$}\n\nSo what, then, is ATT?","type":"content","url":"/potential-outcomes#baseline-differences","position":13},{"hierarchy":{"lvl1":"The Potential Outcomes Framework","lvl3":"Average Treatment Effect on the Treated (ATT)","lvl2":"Correlation and Causation"},"type":"lvl3","url":"/potential-outcomes#average-treatment-effect-on-the-treated-att","position":14},{"hierarchy":{"lvl1":"The Potential Outcomes Framework","lvl3":"Average Treatment Effect on the Treated (ATT)","lvl2":"Correlation and Causation"},"content":"Perhaps the easiest way to understand ATT is to directly compare the formulas for ATT with ATE:\n\n$$\n\\begin{aligned}\n\nATT =& E(Y^1_i|D_i = 1) - E(Y_i^0|D_i = 1) \\\nATE =& E(Y^1_i) - E(Y_i^0)\n\n\\end{aligned}\n$$\n\nAs you can see, the only difference between the two terms is that ATT is just the ATE *for the population of entities that were actually subject to the treatment (D_i = 1).\n\nSo for our estimated correlation \\widehat{ATE} to be the same as the Average Treatment Effect ATE we are most interested in, it must be the case that ATT = ATE. When does that happen?\n\nWell, as you may recall, the Average Treatment Effect is just an average effect of the treatment for everyone being studied. That means that if λ is the share of the population for which D_i = 1, then ATE is:\n\n$$\n\\begin{aligned}\n\nATE =& E(Y^1_i) - E(Y_i^0) \\\n=& \\lambda \\left(\\underbrace{E(Y^1_i | D_i = 1) - E(Y_i^0 | D_i = 1)}\\text{ATT}\\right) + (1-\\lambda) \\left(\\underbrace{E(Y^1_i | D_i = 0) - E(Y_i^0 | D_i = 0)}\\text{Avg Treatment Effect on Untreated}\\right)\n\n\\end{aligned}\n$$\n\nSo when does ATT = ATE? When E(Y^1_i | D_i = 1) - E(Y_i^0 | D_i = 1) = E(Y^1_i | D_i = 0) - E(Y_i^0 | D_i = 0). Or, in substantive terms, when the average effect of our treatment is the same for the subpopulation we observe experiencing the treatment as it is for the subpopulation that we observe not experiencing the treatment:\n\nNo Differential Treatment Effects:\n\n$$\n\\begin{aligned}\n\nATT &= E(Y^1_i|D_i = 0) - E(Y_i^0|D_i = 0) \\\nE(Y^1_i|D_i = 1) - E(Y_i^0|D_i = 1) &= E(Y^1_i|D_i = 0) - E(Y_i^0|D_i = 0)\n\n\\end{aligned}\n$$(eqn:condition_2)\n\nNote\n\nWhat would it look like for different populations to respond differently to treatment, and why might that happen in the real world? Well, it turns out it happens a lot when you aren’t doing randomized experiments.\n\nSuppose you polled your classmates after an exam, and they all had headaches. Half of your classmates then choose for themselves to use acetaminophen (Tylenol) (D_i=1), and immediately feel better. Should you infer, then, that the ATE of acetomenophen is 100%?\n\nWell... probably not. While it sounds like the ATT may be 100%, it’s worth asking why the other half of students didn’t take acetaminophen. What if they didn’t take acetaminophen because they knew from past experience that acetaminophen doesn’t alleviate their headache pain? In other words, the students who didn’t take acetaminophen (D_i = 0) chose to not take acetaminophen precisely because they already knew that its effect on them is 0. Then we have a clear situation where ATT \\neq ATE.","type":"content","url":"/potential-outcomes#average-treatment-effect-on-the-treated-att","position":15},{"hierarchy":{"lvl1":"The Potential Outcomes Framework","lvl2":"Wrapping It Up"},"type":"lvl2","url":"/potential-outcomes#wrapping-it-up","position":16},{"hierarchy":{"lvl1":"The Potential Outcomes Framework","lvl2":"Wrapping It Up"},"content":"We started off this chapter by noting that correlation does not necessarily imply causation. But there are certain condition under which correlation does imply causation, and we now know what those conditions are.\n\nFirst, for our observed correlation between treatment and our outcome of interest to imply a causal effect, it must be the fact that there are no Baseline Differences. If there are Baseline Differences between the treated and untreated, then we just don’t have a way to know what portion of the difference between these groups is the effect of treatment and what differences were pre-existing.\n\n(Some of you may be saying “But wait! Can’t I use a regression to estimate what share of differences are down to observable differences?” Yes, and we’ll discuss that soon, but the key word is “observable” — regression can help address Baseline Differences if we can measure the factors that give rise to those differences.)\n\nIf we don’t have Baseline Differences, then our correlation is at least a good estimate of the Average Treatment Effect on the Treated (ATT) — that is, the causal effect of our treatment on the subpopulation that we observed experiencing to treatment. And there will be times that the best we can do is get a good estimate of ATT.\n\nBut if we really want to get a good estimate of the Average Treatment Effect for the full population we’re studying — something we want if we want to be able to estimate the effect of our treatment if we roll it out to everyone — then we also need it to be the case that the people we observe receiving the treatment (D_i = 1) respond to the treatment in the same way as those that don’t (D_i = 0).","type":"content","url":"/potential-outcomes#wrapping-it-up","position":17},{"hierarchy":{"lvl1":"The Potential Outcomes Framework","lvl3":"Testability of Assumptions","lvl2":"Wrapping It Up"},"type":"lvl3","url":"/potential-outcomes#testability-of-assumptions","position":18},{"hierarchy":{"lvl1":"The Potential Outcomes Framework","lvl3":"Testability of Assumptions","lvl2":"Wrapping It Up"},"content":"Any now the big catch: we need two conditions to be true to be sure we are getting a good estimate of a causal effect:\n\n$$\n\\begin{aligned}\n\n0 & = E(Y^0_i|D_i = 1) - E(Y_i^0|D_i = 0)\\\nE(Y^1_i|D_i = 1) - E(Y_i^0|D_i = 1) &= E(Y^1_i|D_i = 0) - E(Y_i^0|D_i = 0)\n\n\\end{aligned}\n$$\n\nBut neither of these are directly observable. In the case of No Baseline Differences, we can never directly observe E(Y^0_i|D_i = 1). And in the case of No Differential Treatment Effects, neither E(Y_i^0|D_i = 1) nor E(Y_i^0|D_i = 1) are observable.\n\nAs a result, it is only through critical thinking and domain knowledge that we can do our best to reason about whether we believe these conditions are met in any given situation. And that is why causal inference is hard.","type":"content","url":"/potential-outcomes#testability-of-assumptions","position":19},{"hierarchy":{"lvl1":"Using and Interpreting Indicator (Dummy) Variables"},"type":"lvl1","url":"/interpreting-indicator-vars","position":0},{"hierarchy":{"lvl1":"Using and Interpreting Indicator (Dummy) Variables"},"content":"We often gloss over indicator variables in our statistics courses, but not only are they (in my view) one of the most powerful tools in a data scientist’s tool box, but I cannot tell you how much I see people struggle with interpreting indicator variables in their regressions. So in this tutorial, I’ll try to give them the treatment they deserve, and hopefully by the end, you’ve have a firm understanding not only of how to use and interpret Indicator Variables.\n\n","type":"content","url":"/interpreting-indicator-vars","position":1},{"hierarchy":{"lvl1":"Using and Interpreting Indicator (Dummy) Variables","lvl2":"What are indicator variables?"},"type":"lvl2","url":"/interpreting-indicator-vars#what-are-indicator-variables","position":2},{"hierarchy":{"lvl1":"Using and Interpreting Indicator (Dummy) Variables","lvl2":"What are indicator variables?"},"content":"Indicator variables -- sometimes also referred to as dummy variables, though I don’t know why -- are variables that take on only the value of 0 and 1, and are used to indicate whether a given observation belongs to a discrete category in a way that can be used in statistical models.\n\nFor example, indicator variables can be used to indicate if an survey respondent is a woman (if the variable is 1 for women, 0 otherwise) or a Democrat (if the variable is 1 for democrats, 0 otherwise). In addition, as discussed in more detail below, collections of indicator variables can also be used to code categorical variables that take on more than 2 variables using a method called \"one-hot encoding). This allows use to work with variables that have many levels, like an individual’s political party registration (which could be Democrat, Independent, or Republican).\n\n","type":"content","url":"/interpreting-indicator-vars#what-are-indicator-variables","position":3},{"hierarchy":{"lvl1":"Using and Interpreting Indicator (Dummy) Variables","lvl2":"The ONE thing that you must understand when using indicator variables:"},"type":"lvl2","url":"/interpreting-indicator-vars#the-one-thing-that-you-must-understand-when-using-indicator-variables","position":4},{"hierarchy":{"lvl1":"Using and Interpreting Indicator (Dummy) Variables","lvl2":"The ONE thing that you must understand when using indicator variables:"},"content":"When you put an indicator variable in a regression model, there are two things you must always keep in mind about interpreting the coefficients associated with the indicator variable:\n\nThe coefficient on an indicator variable is an estimate of the average DIFFERENCE in the dependent variable for the group identified by the indicator variable (after taking into account other variables in the regression) and\n\nthe REFERENCE GROUP, which is the set of observations for which the indicator variable is always zero.\n\nIf you always remember that the coefficient on an indicator variable is an estimate of a DIFFERENCE with respect to a REFERENCE GROUP (also sometimes referred to as the “omitted category”), you’re 90% of the way to understanding indicator variables.\n\nI recognize this may feel obvious, but trust me: I’ve literally reviewed papers from tenured faculty at major Universities that get this wrong. This is something people get confused about constantly, so I promise it’s worth this treatment.\n\nOK, let’s get concrete.\n\n","type":"content","url":"/interpreting-indicator-vars#the-one-thing-that-you-must-understand-when-using-indicator-variables","position":5},{"hierarchy":{"lvl1":"Using and Interpreting Indicator (Dummy) Variables","lvl2":"Indicator Variables with Two Category Variable"},"type":"lvl2","url":"/interpreting-indicator-vars#indicator-variables-with-two-category-variable","position":6},{"hierarchy":{"lvl1":"Using and Interpreting Indicator (Dummy) Variables","lvl2":"Indicator Variables with Two Category Variable"},"content":"Let’s start with a simple model in which we wish to predict voter turnout using data from North Carolina. Suppose we’re interested in looking at how turnout varies by gender, which is dichotomous in the North Carolina voter file (obviously this is somewhat problematic given what we’ve come to know about gender, but in most datasets you’ll find a dichotomous coding).\n\n# Load data we'll use. Should work for anyone.\nimport pandas as pd\nimport numpy as np\n\npd.set_option(\"mode.copy_on_write\", True)\n\nvoters = pd.read_csv(\n    \"https://raw.githubusercontent.com/nickeubank/\"\n    \"css_tutorials/master/exercise_data/voter_turnout.csv\"\n)\nvoters.head()\n\n# Create a 0/1 variable for female.\nvoters[\"female\"] = voters.gender == \"FEMALE\"\nvoters.head()\n\nimport statsmodels.formula.api as smf\n\nmodel = smf.ols(\"voted ~ female\", voters).fit()\nmodel.get_robustcov_results(\"HC3\").summary()\n\nOK, so how do we interpret this coefficient of 0.0075 on female? As we said before, it is the average DIFFERENCE in the dependent variable (Whether the person votes) with respect to a REFERENCE GROUP. The reference group is the group for whom the indicator is always equal to zero, which in this case is the set of male voters.\n\nSo this says that women are 0.7% more likely to vote (in North Carolina) then men.\n\nNow let’s try a more interesting example: Democrats.\n\nvoters.party.value_counts()  # OK, note here that there are THREE party registrations in this data.\n\n# So let's do the same thing as before for Democrats\nvoters[\"democrat\"] = voters.party == \"DEMOCRATIC\"\nvoters.head()\n\n# Note that because we're estimating a linear probability\n# model we need to use heteroskedastic robust\n# standard errors.\n\nmodel = smf.ols(\"voted ~ democrat\", voters).fit()\nmodel.get_robustcov_results(\"HC3\").summary()\n\nSo now how do we interpret this coefficient on Democrats (-0.056)? As before it’s the average DIFFERENCE in the dependent variable between the indicated group (Democrats) and the reference group. But what’s the reference group? Republicans?\n\nNo -- the reference group or omitted category is anyone for whom the indicator variable is always zero -- in this case, all non-Democrats, whether they’re Republicans or Unaffiliated.\n\nSo this result says that Democrats are less likely to vote than non-Democrats, but NOT that they’re less likely to vote than Republicans per se.\n\nSo how do we deal with multiple categories? With multiple indicator variables!\n\n","type":"content","url":"/interpreting-indicator-vars#indicator-variables-with-two-category-variable","position":7},{"hierarchy":{"lvl1":"Using and Interpreting Indicator (Dummy) Variables","lvl2":"Indicator Variables for variables with more than 2 categories"},"type":"lvl2","url":"/interpreting-indicator-vars#indicator-variables-for-variables-with-more-than-2-categories","position":8},{"hierarchy":{"lvl1":"Using and Interpreting Indicator (Dummy) Variables","lvl2":"Indicator Variables for variables with more than 2 categories"},"content":"To deal with categorical variables with more than 2 categories, we create indicator variables for all values of the variable except one. The one group for which we do not create an indicator variable will become the reference group for the regression. The choice of which value to make the reference category won’t substantively change the results of the regression -- for example, if you also have a control for age, the coefficient on age will always be the same regardless of the reference group used -- but it does influence how easily you can interpret the results of the regression.\n\nThis practice of creating a collection of indicator variables to encode a single categorical variable is what’s called “one-hot encoding” by computer scientists / machine learning people.\n\nSince we’re interested in the difference in turnout between Democrats and Republicans, let’s make Republicans the reference category, and make indicators for Democrats and Unaffiliated voters.\n\nvoters[\"unaffiliated\"] = voters.party == \"UNAFFILIATED\"\nvoters.head()\n\nmodel = smf.ols(\"voted ~ democrat + unaffiliated\", voters).fit()\nmodel.get_robustcov_results(\"HC3\").summary()\n\n(Note that we also could have used the syntax smf.ols('voted ~ C(party)', voters), which will automatically convert your data into one-hot encodings, but then you don’t get to pick the omitted category, and sometimes it’s nice to be explicit.)\n\nHow do we interpret these results?\n\nFirst, we see that the coefficient on democrat is -0.08. That means that the DIFFERENCE in turnout between Democrats and the reference group (here, Republicans) is 8%. So Democrats have 8 percentage point lower turnout on average in this data than Republicans.\n\nSecond, we see that the coefficient on unaffiliated is -0.06. That means that the DIFFERENCE in turnout between Unaffiliated voters and the reference group (here, Republicans) is 6%. So Unaffiliated voters have 6 percent point lower turnout on average in this data than Republicans.\n\nMoreover, the p-value on these indicator variables tells us if these differences are significant. And indeed, they show clearly that the difference between Democrats and Republicans, and the difference between Unaffiliated voters and Republicans are both significant.\n\nBut what about the difference between Democrats and Unaffiliated voters? Well, turns out the regression doesn’t give us that directly. To get that, we have to do some additional math.\n\nFirst, it’s easy to estimate the difference in coefficients:dem - unaffiliated = (dem - republican) - (unaffiliated - republican)\n                   = -0.08 - -0.06\n                   = -0.02\n\nSo in other words, Democrats have 2 percentage point lower turnout than Unaffiliated voters.\n\nBut is this difference statistically significant? For that we have to run a post-regression test. (In R, you can do these with the car library using the LinearHypothesis function)\n\nmodel = smf.ols(\"voted ~ democrat + unaffiliated\", voters).fit()\nmodel = model.get_robustcov_results(\"HC3\")\n\nhypothesis = \"democrat[T.True] = unaffiliated[T.True]\"\nmodel.t_test(hypothesis)\n\nVoila -- p-value of 0.1.\n\nWanna confirm it? let’s change our reference group to unaffiliated. Then when we look at the coefficient on democrat, that will be the difference between Democrats and the new reference group (Unaffiliated voters)\n\nvoters[\"republican\"] = voters.party == \"REPUBLICAN\"\nmodel = smf.ols(\"voted ~ democrat + republican\", voters).fit()\nmodel.get_robustcov_results(\"HC3\").summary()\n\nAs we can now see, the coefficient on democrat (now the difference between Democrats and Unaffiliated voters) is exactly what we’d calculated above (-0.019) and has the same p-value we calculated previously (0.1).\n\nThis just goes to show that the choice of reference group doesn’t change what’s actually being estimated, it just changes the interpretation of coefficients and what statistics pop right out of the regression output, and which values require a little extra work to get.\n\n","type":"content","url":"/interpreting-indicator-vars#indicator-variables-for-variables-with-more-than-2-categories","position":9},{"hierarchy":{"lvl1":"Using and Interpreting Indicator (Dummy) Variables","lvl2":"Interactions with Constant Variables"},"type":"lvl2","url":"/interpreting-indicator-vars#interactions-with-constant-variables","position":10},{"hierarchy":{"lvl1":"Using and Interpreting Indicator (Dummy) Variables","lvl2":"Interactions with Constant Variables"},"content":"Like regular Indicators, but for differences in SLOPE rather than differences in LEVELS!\n\nCongratulations! You’re a pro at indicator variables. Now we can turn to INTERACTIONS!\n\nInteractions (at least when you interact an indicator variable with a continuous variable), just like a regular indicator variables, report differences between a group and the reference group. The difference is that instead of reporting the difference in average value of the dependent variable between the indicated group and the reference group, the coefficient on an interaction term is the average DIFFERENCE in the SLOPE associated with the continuous variable between the indicated group and the reference group.\n\nLet’s be concrete: let’s suppose we think that turnout among men increases as they get older by a larger amount than for women. In other words, we think that turnout increases with age for both groups, but that there’s a DIFFERENCE in the amount it increases with age.\n\nTo test this, we need to create some interaction terms. But first, a quick note: when doing interactions, it’s critical to not only include all the interaction terms that interest you, but also all the variables in the interaction as stand-alone variables. So for this we want age interacted with female. But while the coefficient on that estimate is what we’re interested in, to get the right results we also need to include just age and just female.\n\nvoters[\"age_x_female\"] = voters.age * voters.female\nmodel = smf.ols(\"voted ~ age + female + age_x_female\", voters).fit()\nmodel.get_robustcov_results(\"HC3\").summary()\n\nThe coefficient on our interaction is -0.0015. Does that mean that as women get older, their turnout rate declines by -0.15 percentage points per year? NO!\n\nIt says that however turnout varies with age for men, turnout will vary with age by 0.0015 less for women. It is the DIFFERENCE in slopes between the two groups.\n\nThe coefficient on age tells us how turnout varies with age for the reference group. So it says that for men, turnout increases by 0.09 percentage points per year.\n\nBut if you want to know how women’s turnout varies with age, you have to ADD the coefficient on age (the rate of change for me) plus the coefficient on age_x_female (the difference between the rate of men and women).\n\nSo going through all these coefficients, we have:\n\nfemale (0.09): Controlling for age, women are 9 percentage points more likely to vote than men.\n\nage (0.0009): As men get one year older, they become 0.09 percentage points more likely to vote.\n\nage_x_female (-0.0015): As women get one year older, the likelihood they vote increases by 0.1 percentage point per year less than men’s likelihood of voting increases per year.\n\nSo how much does women’s turnout increase if they age one year? 0.0009 + -0.0015 = -0.0006. So female turnout actually declines by 0.06 percentage points a year.\n\nNow let’s talk statistical significance. The p-value on age shows us that there’s a statistically significant relationship between age and turnout for men. The p-value for age_x_female tells us that there’s a statistically significant difference between men and women in how turnout varies with age. But is there a statistically significant relationship between age and turnout for women?\n\nAgain, we don’t actually get an answer from our regression. To see, we have to run the following:\n\nmodel = smf.ols(\"voted ~ age + female + age_x_female\", voters).fit()\nmodel = model.get_robustcov_results(\"HC3\")\nhypothesis = \"age + age_x_female = 0\"\nmodel.t_test(hypothesis)\n\nSo the p-value is 0.17 for the relationship between female and age (and the coefficient of -0.0006, just like we calculated above!)","type":"content","url":"/interpreting-indicator-vars#interactions-with-constant-variables","position":11},{"hierarchy":{"lvl1":"Using and Interpreting Indicator (Dummy) Variables","lvl3":"Keeping Things Straight","lvl2":"Interactions with Constant Variables"},"type":"lvl3","url":"/interpreting-indicator-vars#keeping-things-straight","position":12},{"hierarchy":{"lvl1":"Using and Interpreting Indicator (Dummy) Variables","lvl3":"Keeping Things Straight","lvl2":"Interactions with Constant Variables"},"content":"When you want to know a quantity, how can you figure out what coefficients to look at if you don’t remember these rules?\n\nThe simplest way to make sure you’re interpreting indicators correctly is to think about what our model looks like for different kinds of people. So suppose we wanted to figure out how men’s turnout varies with age. Let’s look at our model:voted = \\beta_0 + \\beta_1 * age + \\beta_2 * female + \\beta_3 * (age * female) + \\epsilon\n\nWell, for men female and age_x_female will always be zero, so the model for men is actually just:voted_{men} = \\beta_0 + \\beta_1 * age + \\epsilon\n\nAnd how does this vary with age? Linearly by \\beta_1 per year.\n\nWhat about for women? For women all those indicators will be 1s, so the equation will effectively be:voted_{women} = \\beta_0 + \\beta_1 * age + \\beta_2 + \\beta_3 * age + \\epsilonvoted_{women} = \\beta_0 + (\\beta_1 + \\beta_3)* age + \\beta_2 + \\epsilon\n\n(\\beta_2 is on its own because the female is just an indicator that takes on a value of 1 in this case. You can think of it as having an implicit 1 next to it if that’s helpful.)\n\nAnd how does that vary with age? Linearly by \\beta_1 + \\beta_3 per year.\n\nFinally, if we want the difference between how men and women respond to age, we can write this out:voted_{women} - voted_{men} == (\\beta_0 + \\beta_1 * age + \\beta_2 + \\beta_3 * age + \\epsilon) - (\\beta_0 + \\beta_1 * age + \\epsilon)=\\beta_2 + \\beta_3 * age\n\nSo the difference in who men and women respond to age in particular \\beta_3.\n\n","type":"content","url":"/interpreting-indicator-vars#keeping-things-straight","position":13},{"hierarchy":{"lvl1":"Using and Interpreting Indicator (Dummy) Variables","lvl3":"The * operator","lvl2":"Interactions with Constant Variables"},"type":"lvl3","url":"/interpreting-indicator-vars#the-operator","position":14},{"hierarchy":{"lvl1":"Using and Interpreting Indicator (Dummy) Variables","lvl3":"The * operator","lvl2":"Interactions with Constant Variables"},"content":"Finally, as with using C() to convert categoricals to indicators, you can also use the * notation in statsmodels for interactions -- it not only creates the interaction term, but also adds all the level effects:\n\nmodel = smf.ols(\"voted ~ age * female\", voters).fit()\nmodel.get_robustcov_results(\"HC3\").summary()\n\n","type":"content","url":"/interpreting-indicator-vars#the-operator","position":15},{"hierarchy":{"lvl1":"Using and Interpreting Indicator (Dummy) Variables","lvl2":"Interactions Between Multiple Indicator Variables"},"type":"lvl2","url":"/interpreting-indicator-vars#interactions-between-multiple-indicator-variables","position":16},{"hierarchy":{"lvl1":"Using and Interpreting Indicator (Dummy) Variables","lvl2":"Interactions Between Multiple Indicator Variables"},"content":"\n\nYou can also do interactions between Indicators, which have similar interpretations to interactions with constant variables.\n\nFor example, suppose instead of age, we just had a binary variable old:\n\nvoters[\"old\"] = voters.age > 50\n\n# Note the interaction has to be converted to integers first -- not booleans\nvoters[\"old_x_female\"] = voters.old.astype(\"int\") * voters.female.astype(\"int\")\nmodel = smf.ols(\"voted ~ old + female + old_x_female\", voters).fit()\nmodel.get_robustcov_results(\"HC3\").summary()\n\nNow we interpret old_x_female as the difference in how age affects men and woman. It is negative because, as we saw before, as women age, their turnout rate does not increase as much as men’s. Here we find that men’s turnout increases by 10 percentage points moving from under 50 to over 50. By contrast, when moving from under 50 to over 50, a women’s turnout increases by -0.01 less (in total, it changes by 0.10 + -0.01 = 0.09).\n\n(This may seem inconsistent with the results above, but that’s because above we were modeling age linearly; in reality, the relationship between age and turnout is quadratic -- it increases initially, peaks in middle-age, then declines, so neither of these models fit the data perfectly)\n\nimport seaborn.objects as so\nfrom matplotlib import style\nimport matplotlib.pyplot as plt\nimport warnings\n\nwarnings.simplefilter(action=\"ignore\", category=FutureWarning)\n\n(\n    so.Plot(voters, x=\"age\", y=\"voted\")\n    .add(so.Line(), so.PolyFit(order=2))\n    .label(title=\"Age and Turnout\")\n    .theme({**style.library[\"seaborn-v0_8-whitegrid\"]})\n)","type":"content","url":"/interpreting-indicator-vars#interactions-between-multiple-indicator-variables","position":17},{"hierarchy":{"lvl1":"Beyond The Experiment"},"type":"lvl1","url":"/causal-inference-beyond-ab-testing","position":0},{"hierarchy":{"lvl1":"Beyond The Experiment"},"content":"The Role for Causal Inference with Observational Data in Industry\n\nI don’t think there’s anyone who would question the importance of A/B testing in the tech sector today. It is used constantly to help companies refine their products, better target their ads, and incrementally innovate.\n\nBut while A/B testing is definitely a skill a good data scientist should have in their toolbox, it’s important to understand that it is not the be-all and end-all of causal inference in industry. In this reading, we’ll discuss why it’s important to learn how to think critically about causality when working with observational data (“observational data” is data that we gather by passively observing the world -- or that somebody else collected by passively observing the world -- rather than data that we get by directly manipulating subjects in an experiment).\n\n","type":"content","url":"/causal-inference-beyond-ab-testing","position":1},{"hierarchy":{"lvl1":"Beyond The Experiment","lvl2":"A/B Testing Isn’t Always Feasible"},"type":"lvl2","url":"/causal-inference-beyond-ab-testing#a-b-testing-isnt-always-feasible","position":2},{"hierarchy":{"lvl1":"Beyond The Experiment","lvl2":"A/B Testing Isn’t Always Feasible"},"content":"The first reason it’s important to know about tools that go beyond A/B testing is that A/B testing isn’t always feasible. A/B testing only works when you can efficiently randomize people into different treatment arms, and where you can do it at low cost (if running a test is expensive, then even if you want to run the test, you should be doing some analysis first to make sure it’s worth while!). But this isn’t possible for every decision, even in big tech companies. Here’s just a handful of situations where you can’t run an A/B test:\n\nYou Don’t Control The Relevant User Behavior: Suppose you want to know the effect of, say, following a specific person on facebook or twitter on user satisfaction, or choosing to use a certain function in your product. The “ideal experiment” would be to randomly assign some users to follow the person in question / use your new function, and block others from doing so. But of course you can’t do that! So you have to find other ways to compare followers and non-followers that accounts for ways they may be different in terms of user satisfaction or behavior.\n\nIt’s a One-Shot Deal: Suppose you’re trying to decide whether to run a Super Bowl ad, or open a second store. You can’t A/B test these small-N events. When dealing with these types of “big strategic” decisions, the best you can do is look to your companies past experiences / the experiences of other companies that you think are comparable using the best available tools for observational causal inference.\n\nRandomization is Bad Business: It’s one thing to randomize someone’s landing page color scheme; it’s another thing entirely to randomly show people different prices for your products -- customers wouldn’t stand for it! Similarly, sometimes you want a big rollout -- like the launch of a new title on Netflix, or the premier of a new movie -- and an A/B test would interfere with that. (Not an abstract example: here’s \n\nNetflix talking about this constraint).\n\nTime Horizons are Too Long: A/B testing is popular in tech because you get so much data from users so quickly that they’re easy to run on short time horizons. But if you’re thinking about opening more stores across the country, you can’t put your business on hold, pick a few locations, setup new shops, and wait for sales data; you need to get a sense of what’s going to happen now. As we read in \n\nKohavi, Tang and Xu, A/B tests work best when we have an Overall Evaluation Criterion (OEC) that is “measurable in the short term (the duration of an experiment) yet believed to causally drive long-term strategic objectives.” But when that is not available / the shortest experiment available that would allow you to measure a meaningful OEC would take too long, you need other options!\n\n","type":"content","url":"/causal-inference-beyond-ab-testing#a-b-testing-isnt-always-feasible","position":3},{"hierarchy":{"lvl1":"Beyond The Experiment","lvl2":"A/B Testing Isn’t Always Legal or Ethical"},"type":"lvl2","url":"/causal-inference-beyond-ab-testing#a-b-testing-isnt-always-legal-or-ethical","position":4},{"hierarchy":{"lvl1":"Beyond The Experiment","lvl2":"A/B Testing Isn’t Always Legal or Ethical"},"content":"Those are all practical business constraints, but there are also ethical and legal constraints many people face.\n\nFor example, if you’re at a social media company and want to study the effects of harassment on customer retention, you can’t randomly assign people to be harassed!\n\nAnd even if you think certain experiments are ok, you also have to be mindful of what the public will say. In 2012, Facebook ran an experiment in which they manipulated the emotional valence of posts they saw in their feeds, showing them either more happy posts or more sad posts. The goal was to see how moods spilled over from one user to another on the network.\n\nThe experiment was legal, but when people found out they were having the moods toyed with at random, they \n\nwere furious.  Now some tech people would say that \"everything we do is to try and manipulate consumer happiness, how is this any different? And maybe you even believe that (though I think that, at the very least, deliberately showing people sad things means you’re doing harm, which is a huge no-no in human experimentation). But it doesn’t really matter, because it cost Facebook a lot of good will.\n\nSimilar issues happened with OKCupid when they published research on how they \n\nmanipulated people’s dating profiles. That, honestly, was a pretty standard experiment, but when it comes to messing with people’s hearts... you have to be careful.\n\nFinally, A/B randomizations aren’t always legal. For example, suppose you’re working in Human Resources for a company that wants to improve retention of younger tech wokers, and you want to offer childcare subsidies to employees. If that workforce is unionized, you can’t offer a benefit to only some people within a specific class of employees due to union contracts.\n\n","type":"content","url":"/causal-inference-beyond-ab-testing#a-b-testing-isnt-always-legal-or-ethical","position":5},{"hierarchy":{"lvl1":"Beyond The Experiment","lvl2":"Going Beyond Testing for the Future"},"type":"lvl2","url":"/causal-inference-beyond-ab-testing#going-beyond-testing-for-the-future","position":6},{"hierarchy":{"lvl1":"Beyond The Experiment","lvl2":"Going Beyond Testing for the Future"},"content":"Another limitation of A/B tests is that we usually use them to do small scale tests to motivate larger, future rollouts. But sometimes we want to just measure the effect of a single, large intervention.\n\nIn many areas of business, it’s increasingly common to hire outside companies to do very complicated projects, like administering government programs or providing a service to employees. In these situations, companies have increasingly found that paying vendors based on inputs (hours worked, money spent) doesn’t actually encourage vendors to do a very good job, or to try to be efficient -- if you’re being paid on the basis of what you spend, you will obviously you will not have an incentive to cut costs!\n\nIn these situations, companies are increasingly turning to something called “at-risk contracting.” In these arrangements, the company doing the hiring offers to pay the vendor if they achieve a specific outcome. For example, a hospital might hire a company to reduce in-hospital infections and pay them based on reductions in infections, or a company may hire a vendor to minimize the downtime of their internal network, and pay them based on downtime. By tying compensation to the outcome that the hiring party actually cares about, the vendors well incentivized to do precisely what the hiring company wants them to do!\n\nBut in these arrangements, it’s critical to both parties that there’s a good way to measure the effect of the vendor’s efforts or someone will get over or under paid. That’s not an average effect, that’s a specific effect, and something for which experiments are not well-suited.\n\nIn these circumstances, it’s unfortunately the case that people often just measure outcomes before the vendor starts and compare them to outcomes when the vendor finishes. But if the outcome in question is subject to natural variation -- such as seasonality -- then we expect the outcome to vary whether the vendor does anything or not, and so you need a better causal design (e.g. difference-in-difference) to take those types of confounders into account.\n\n","type":"content","url":"/causal-inference-beyond-ab-testing#going-beyond-testing-for-the-future","position":7},{"hierarchy":{"lvl1":"Beyond The Experiment","lvl2":"Don’t want to be limited"},"type":"lvl2","url":"/causal-inference-beyond-ab-testing#dont-want-to-be-limited","position":8},{"hierarchy":{"lvl1":"Beyond The Experiment","lvl2":"Don’t want to be limited"},"content":"Here’s another important thought: professionally, if you only know how to do A/B testing, you risk limiting your opportunities for upward advancement. Big companies are getting better and better at providing analysts with extremely user friendly A/B testing tools, which means doing A/B tests is getting easier and easier. Twitter, for example, has an \n\ninternal tool called Duck, Duck, Goose that makes running an A/B test a relatively low-difficulty task. And while running a good A/B test is never easy (as we have discussed at length, even with A/B testing, the internal and external validity of our causal estimates will always be dependent on a wide range of assumptions), it is something that more and more people are learning to do well and which companies are learning to make easier. Thus, if all you know how to do are A/B tests, you may find it increasingly hard to differentiate yourself in the data science market.\n\nAgain, this isn’t to say you shouldn’t learn to do A/B testing, just don’t only learn A/B testing.\n\n","type":"content","url":"/causal-inference-beyond-ab-testing#dont-want-to-be-limited","position":9},{"hierarchy":{"lvl1":"Beyond The Experiment","lvl2":"Not enough to be able to do it; you must be able to explain it"},"type":"lvl2","url":"/causal-inference-beyond-ab-testing#not-enough-to-be-able-to-do-it-you-must-be-able-to-explain-it","position":10},{"hierarchy":{"lvl1":"Beyond The Experiment","lvl2":"Not enough to be able to do it; you must be able to explain it"},"content":"\n\nOne final reason it’s important to understand how to apply the logic of causal inference to observational data is that even if you only work with A/B data, it is almost inevitable that you will interact with other people in your company who want to use observational data. In these situations, it’s not enough that you understand the considerations that go into making causal inferences from observational data; you also need to be able to explain those to colleagues.","type":"content","url":"/causal-inference-beyond-ab-testing#not-enough-to-be-able-to-do-it-you-must-be-able-to-explain-it","position":11},{"hierarchy":{"lvl1":"Fixed Effects and Causal Inference"},"type":"lvl1","url":"/fixed-effects-and-causal-inference","position":0},{"hierarchy":{"lvl1":"Fixed Effects and Causal Inference"},"content":"So, you’re working with panel data. You have either multiple observations per entity (usually data over time), or you have nested data (data on individuals, each of whom belongs to a larger group, like kids in a school). And you want to add fixed effects for the entities or groups. But what does that mean from the perspective of causal inference?\n\nThe simple answer is that a fixed effect is a tool for controlling for a specific source of baseline differences (namely, baseline differences across entities). In that sense, fixed effects are no different from any other type of control variable we put in a regression.\n\nBut there is an important difference: with most variables we put in a regression, those variables are only controlling for a specific thing, the thing they measure. If you add age, you’re controlling for age; add income, you’re controlling for income. But fixed effects are a little more powerful: they control for any stable source of baseline differences between entities!\n\nUh, what?\n\nSuppose you have weekly sales data for all your stores over several years, and you’re interested in better understanding the effect of each store’s local unemployment rate on sales. For simplicity, we’ll assume that in any week, a given store is said to experience high unemployment (D_i=1) or low unemployment (D_i=0), though this extends to using thinking of unemployment as a continuous variable.\n\nIf you just ran a regression of local unemployment rates on sales, you might find that sales are extremely sensitive to the local unemployment rate. But when you dig in, that’s because your New York City store in Times Square makes tons of sales, and NYC tends to always have low unemployment.\n\nIn our usual causal framework, we’d say that our NYC store had important baseline differences in our outcome (sales per week) that happened to be correlated with treatment assignment (NY tends to have low unemployment), though we don’t think it’s because of NYC has low unemployment (we think it’s because the store is in Times Square!). As a result, E(Y_i^0|D_i=0) \\neq E(Y_i^0|D_i=1). We have a problem with baseline differences.\n\nBut what if you add store fixed effects to the model? You can think of those fixed effects as demeaning all sales for each store. In other words, you’re removing level differences across scores from the relationship you’re trying to estimate. As a result, instead of estimating how differences in unemployment are correlated with sales, you’re instead estimating how changes in unemployment relate to changes in sales.\n\nThat’s because after fixed effects effectively demean your dependent variable (for each store), the only variation in the data you’re left with are the deviations in your dependent variable above or below its mean value for a given store. We’re no longer estimating the relationship between unemployment and store sales, but rather how changes in unemployment are correlated with changes in sales.\n\nFrom a causal perspective, now that our focus is on how changes in unemployment affect changes in sales, any differences between stores that don’t vary over time -- no matter what caused those differences -- have been accounted for.\n\nMathematically, we can think of this as a change in our Y: instead of Y_i being absolute sales, it’s now deviations in sales above or below the average sales for a given store i. Thus, baseline differences (E(Y_i^0|D_i=0) = E(Y_i^0|D_i=1)) has become a question about whether, in a world where unemployment is below the local average, sales for all groups tend to be the same amount above (or below) store average sales. And the fact that we have a store in Times Square is no longer an obvious threat to that condition!\n\nThe limit to this magic is that we’re only controlling for non-time-varying differences between stores. If store sales in NYC are always high because of their location, that’s something controlled for by the fixed effects. However, if in the middle of your data NYC experiences a hurricane, and so sales dip, that isn’t taken into account by your fixed effects (since it was “time-varying,” it only affected the store for a fixed period-of-time). As a result, you’d want a separate control for those kinds of disruptions in your regression.\n\nOne way you can see this is that if you try and stick a variable into your regression that is not time-varying (it has the same value for each store throughout the data), you’ll find that you don’t get back a regression coefficient. That’s because anything non-time varying is actually co-linear (in terms of the underlying linear algebra) with the fixed effects, meaning you literally can’t estimate a coefficient. It’d be like trying to include the variable “age” twice in the same regression.","type":"content","url":"/fixed-effects-and-causal-inference","position":1},{"hierarchy":{"lvl1":"Fixed Effects: Indicator Variables for Groups"},"type":"lvl1","url":"/fixed-effects","position":0},{"hierarchy":{"lvl1":"Fixed Effects: Indicator Variables for Groups"},"content":"One common use of indicator variables are as fixed effects. Fixed effects are used when our data as a “nested” structure (we think individual observations belong to groups), and we suspect different things may be happening in each group.\n\nFor example, suppose we have a dataset of student test scores, and students are all grouped into different schools; or perhaps we have data on earnings and gender across US cities. In these examples, individual observations can be thought of as being grouped into schools or cities.\n\nOne option with this kind of data is to just ignore the groups. For example, if we want to know about differences in the academic performance of minority children across the school system, then we might not want to add controls for students’ schools because we think that part of way race impacts performance is though sorting of minority students into worse schools. If we added school fixed effects, we’d lose that variation.\n\nBut suppose we were interested in understanding whether school administrators treat minority children differently, and whether this affects academic performance. Principles, for example, may be more likely to suspect Black children than White children. If that were our interest, then what we really want to know about is how race impacts academic performance among students in the same school. And that’s where fixed effects are useful -- they let us control for group-level effects (like the fact all children in one school might tend to get lower grades) so we can focus on explaining intra-group variation (differences among children at the same school).\n\nIn this regard, fixed effects are analogous in purpose to hierarchical models, though they are slightly different in implementation (differences between fixed effects and hierarchical models are \n\ndiscussed here).","type":"content","url":"/fixed-effects","position":1},{"hierarchy":{"lvl1":"Fixed Effects: Indicator Variables for Groups","lvl2":"Implementing Fixed Effects"},"type":"lvl2","url":"/fixed-effects#implementing-fixed-effects","position":2},{"hierarchy":{"lvl1":"Fixed Effects: Indicator Variables for Groups","lvl2":"Implementing Fixed Effects"},"content":"To illustrate, let’s try and estimate how gender impacts earnings in the US using data from the US Current Population Survey (CPS) on US wages in 2019. We’ll begin with a simple model of earnings:\n\nimport pandas as pd\n\n# Load survey\ncps = pd.read_stata(\n    \"https://github.com/nickeubank/MIDS_Data/blob/\"\n    \"master/Current_Population_Survey/morg18.dta?raw=true\"\n)\n\n# Limit to people currently employed and working full time.\ncps = cps[cps.lfsr94 == \"Employed-At Work\"]\ncps = cps[cps.uhourse >= 35]\n\n# Annual earnings from weekly\ncps[\"annual_earnings\"] = cps[\"earnwke\"] * 48\n\n# And create gender and college educ variable\ncps[\"female\"] = (cps.sex == 2).astype(\"int\")\ncps[\"has_college_educ\"] = (cps.grade92 > 43).astype(\"int\")\n\nimport statsmodels.formula.api as smf\n\nsmf.ols(\"annual_earnings ~ female + age + has_college_educ\", cps).fit().summary()\n\nIn this model, we’re getting estimates of how education and gender explain variation across all Americans.\n\nBut in this dataset, we also have a variable that tells us the industry in which each respondent is employed. If we want to understand the relationship between gender and income through both workplace bias and sectoral sorting, we can use the model above. But suppose we want to estimate wage discrimination in the workplace after controlling for the industry into which someone chooses to work. In other words, we want to know about the impact of gender on wages within industries.\n\nTo do so, we can add an indicator for each respondent’s industry (in the ind02 variable):\n\nThen we can run the following regression:\n\nsmf.ols(\n    \"annual_earnings ~ female + age + has_college_educ + C(ind02)\", cps\n).fit().summary()\n\nwhich will generate output that will look approximately like this (note your output will be VERY long—I’m omitting all the industry coefficients for space. We’ll talk later about how to suppress those in your output):               .\n               .\n               .\n\nVoilà! What you’ve just estimated is no longer the relationship between gender and income across all Americans, but rather the relationship between gender and income within each industry.\n\nTo be clear, fixed effects aren’t mathematically different from adding a normal control variable. One could say that adding has_college_educ means that we’re now estimating the relationship between gender and income among college educated and among non-college educated. Mechanically, fixed effects are just additional indicator variables. But because we often use them for groups, thinking about the fact that, when added, one is effectively estimating variation within the groups specified by the fixed effects is a powerful idea.\n\nPerhaps no place is this more clear than in full panel data, where you have data on the same entities over time. In a panel regression, the addition of entity fixed effects allow you to difference out any constant differences between entities, and focus only on changes within each entity over time. This even works for people! In a panel with individuals observed over time, adding individual fixed effects means you’re effectively controlling for anything constant about each individual (things that don’t change over time), and now you’re just studying changes over time for each individual.\n\n","type":"content","url":"/fixed-effects#implementing-fixed-effects","position":3},{"hierarchy":{"lvl1":"Fixed Effects: Indicator Variables for Groups","lvl2":"Clustering"},"type":"lvl2","url":"/fixed-effects#clustering","position":4},{"hierarchy":{"lvl1":"Fixed Effects: Indicator Variables for Groups","lvl2":"Clustering"},"content":"When working with fixed effects, however, it’s also often a good idea to cluster your standard errors by your fixed effect variable. Clustering is a method for taking into account some of the variation in your data isn’t coming from the individual level (where you have lots of observations), but rather from the group level. Since you have fewer groups than observations, clustering corrects your standard errors to reflect the smaller effective sample size being used to estimate those fixed effects (clustering only affects standard errors -- it has no impact on coefficients themselves. This is just about adjustments to our confidence in our inferences).\n\nClustering is thankfully easy to do—just use the get_robustcov_results method from statsmodels, and use the groups keyword to pass the group assignments for each observation.\n\n(R users: as we’ll discuss below, I think the easiest way to do this is to use the \n\nplm package.)\n\nTWO IMPORTANT IMPLEMENTATION NOTES:\n\nFirst, if you’re using formulas in statsmodels, the regression is automatically dropping observations that can’t be estimated because of missing data, so you have to do the same before passing your group assignments to-get_robustcov_results—otherwise you’ll get the error:ValueError: The weights and list don't have the same length.\n\nbecause the number of observations in the model doesn’t match the number of observations in the group assignment vector you pass!\n\nWhatever you pass to groups has to be a numeric array of group identifiers. If you don’t, you’ll get an error like:TypeError: '<' not supported between instances of 'float' and 'str'\n\nmodel = smf.ols(\n    \"annual_earnings ~ female + age + has_college_educ + C(ind02)\", cps\n).fit()\n\n# Drop any entries with missing data from the model\nfe_groups = cps.copy()\nfor i in [\"annual_earnings\", \"female\", \"age\", \"ind02\", \"has_college_educ\"]:\n    fe_groups = fe_groups[pd.notnull(fe_groups[i])]\n\n# Convert `ind02` categorical into group codes by\n# pulling codes used in its categorical encoding.\n\n# If you have a string instead of a categorical,\n# just make it a categorical first with `pd.Categorical()`\ngroup_codes = fe_groups.ind02.cat.codes\ngroup_codes.head(5)\n\nmodel.get_robustcov_results(cov_type=\"cluster\", groups=group_codes).summary()\n\n               .\n               .\n               .\n\nAs you can see, while our point estimates haven’t changed at all (the coefficient on female, for example, is still \\sim-10,650), we have increased the size of our standard errors. The SE on female, for example, has gone from 182 without clustering to 583 with clustering.\n\n","type":"content","url":"/fixed-effects#clustering","position":5},{"hierarchy":{"lvl1":"Fixed Effects: Indicator Variables for Groups","lvl2":"Computationally Efficient Fixed Effects"},"type":"lvl2","url":"/fixed-effects#computationally-efficient-fixed-effects","position":6},{"hierarchy":{"lvl1":"Fixed Effects: Indicator Variables for Groups","lvl2":"Computationally Efficient Fixed Effects"},"content":"OK, so everything we’ve describe up till here is a reasonable approach to fixed effects, but it has two limitations: our regression output looks terrible, and computing all those intercepts was slow.\n\nThis brings us to some of the specialized methods for calculating fixed effects. It turns out that if you aren’t interested in the coefficient on each fixed effect, there are much more computationally efficient methods of calculating fixed effects. But to use them, we’ll have to use a different library: \n\nlinearmodels (installable using conda install linearmodels or pip install linearmodels).\n\n(R users: see note at bottom on doing this in R)\n\nIn particular, we’ll be using the PanelOLS function from linearmodels. As the name implies, PanelOLS is designed for linear regression (social scientists call linear regression Ordinary Least Squares, or OLS) with panel data, which is really any form of data organized along two dimensions. Normally a panel has data on many entities observed several times, so the first dimension is the entity dimension, and the second is the time dimension.\n\nIn this case, we don’t really have a panel—just nested data—but because fixed effects are commonly used in panels, we’ll use this tool.\n\nThe only catch is: you have to use multiindexes in pandas. I know, I hate them too. But the multi-index is required by the library for it to understand what variable constitutes the “group” for which you want to add fixed effects. Basically PanelOLS calls the first level of the multi-index the entity and the second level time. In this case, though, we’ll just make the first level our counties, and the second level individual identifiers, then use entity fixed effects (and clustering).\n\ncps.head()\n\n# Move county groups into highest level of multi-index,\n# with old index in second level.\n# PanelOLS will then see the first level as the `entity`\n# identifier.\ncps_w_multiindex = cps.set_index([\"ind02\", cps.index])\ncps_w_multiindex.head()\n\nfrom linearmodels import PanelOLS\n\nmod = PanelOLS.from_formula(\n    \"annual_earnings ~ 1 + female + age + has_college_educ + EntityEffects\",\n    data=cps_w_multiindex,\n)\nmod.fit(cov_type=\"clustered\", cluster_entity=True)","type":"content","url":"/fixed-effects#computationally-efficient-fixed-effects","position":7},{"hierarchy":{"lvl1":"Fixed Effects and Hierarchical Models"},"type":"lvl1","url":"/fixed-effects-v-hierarchical","position":0},{"hierarchy":{"lvl1":"Fixed Effects and Hierarchical Models"},"content":"It is often the case that the data you will work with as a data scientist will have a nested structure, meaning our individual observations can also be divided into groups. In a dataset on student test scores, for example, individual students can be grouped by classroom, or by school. In data on store revenues, it may be possible to group stores by the city in which they are located.\n\nWhen this happens, we often want to take this group structure into account. For students, for example, we might want to take into account that all the students in a good school may do better than average (because the school is good), or that all the stores in a poor city may be likely to under-perform (not because of anything the store has done, but because the city is poor).\n\nThere are several strategies for making these adjustments. The one the is most popular among statisticians (and which is most familiar to MIDS students) are hierarchical models. Hierarchical models accomplish two things: (a) they allow for different intercepts (or different slopes) for all observations within a group, and (b) they adjust our standard errors to account for the possibility of group-level shocks (if the 300 kids in a single school are all over-performing, hierarchical models don’t think of that as 300 observations when calculating standard errors for group effects (which would generally result in small standard errors since we have a sample size of 300 kids); it sees it as a single observation of a good school (with larger standard errors due to the fact we only have a sample size of one school).\n\nHierarchical models are popular in many settings, and for good reason -- they are statistically efficient (meaning they generate estimates that tend to standard errors that are smaller than what you get from other models designed to accomplish the same things). But they also have limitations.\n\nThe chief limitation of hierarchical models is that they assume that the magnitudes of group difference (i.e. the group intercepts or differences in slope) are uncorrelated with the other explanatory variables in the model. Indeed, it the fact that they can leverage this assumption to make precise estimates that makes them statistically efficient if that assumption is true.\n\nBut there are many settings where this assumption breaks down. For example, suppose we’re estimating the test scores of children, and we’re controlling for whether children are low-income. If we estimate a hierarchical model to allow for different schools to have different average test scores, then those estimates of school-level differences will be biased if low-income students tend to go to under-performing school (because our explanatory variable -- a child’s income -- is correlated with the school’s average performance).\n\nWith that in mind, social scientists (who work with data where almost everything is extremely correlated) often prefer a different strategy: fixed effects with clustered standard errors.\n\nHowever, it’s worth noting that the question of whether to use Fixed Effects or Hierarchical Models is one of htose situations where we can statistically evaluate which strategy is the right answer! Because we know that the fixed effects estimates are always right (even if they have larger standard errors than we might want), we can run our models using both a higherarchical model strategy and a fixed effect strategy. If they answers are statistically similar, then we’re probably OK using the hierarhcical models. If they’re substantially different, then we know we can’t trust the hierarchical model, and should use the Fixed Effects. The test for this difference is called a “Hausman Test”.","type":"content","url":"/fixed-effects-v-hierarchical","position":1},{"hierarchy":{"lvl1":"Fixed Effects and Hierarchical Models","lvl2":"Fixed Effects & Clustered Standard Errors"},"type":"lvl2","url":"/fixed-effects-v-hierarchical#fixed-effects-clustered-standard-errors","position":2},{"hierarchy":{"lvl1":"Fixed Effects and Hierarchical Models","lvl2":"Fixed Effects & Clustered Standard Errors"},"content":"Fixed effects are just like hierarchical group estimates, except they don’t require that the level (or slope) differences of groups be uncorrelated with other explanatory variables. This does make them less statistically efficient when these differences are uncorrelated with other explanatory variables (you tend to get larger standard errors than in hierarchical models), but it also makes them more robust (they give you unbiased estimates whether a correlation with explanatory variables exists or not).\n\nBut fixed effects don’t address the second purpose of hierarchical models -- correcting your standard errors. For that, we use clustered standard errors. The idea of clustered standard errors is to account for the fact that if everyone in a given group has a high (or low) error, we want our standard errors to reflect the fact we shouldn’t treat that like lots of individual high (or low) errors (which would generate small standard errors because of the implied large sample size), but rather a single high (or low) error for the group (with an accompanyingly large standard error since really, there’s only one observation of a group error common to all observations). As a result, we generally get larger standard errors when we cluster.\n\n(Fixed effects are also often used to allow for different group intercepts, not it is less common to use them to allow for differential group slopes. This actually can be done, but less frequently).\n\nI recognize this all feels hand-wavy. If you’re interested in the math, you can find a more \n\ndetailed mathematical discussion, but I’ll confess that this is an area I’ve found found that math to offer much intuition. Technically, what we’re doing is allowing for off-the-diagonal terms in our variance-covariance matrix for members of each group to allow for correlated shocks. But if that explanation helps you understand in principle what we’re doing, you’re smarter than me. :)\n\nSo if you’re using fixed effects for groups that you think might be subject to common “shocks” (things you aren’t directly measuring that affect the outcomes of the observations -- like how all students in a school may see test scores change because of an especially good principal, or how all stores in a city may have low sales because the city is unusually poor) -- you should cluster all the observations for that group (we’ll discuss how to cluster in Python in the next execises).\n\nLast note: hierarchical models are equivalent to what social scientists often call “random effects models with clustered standard errors.” So just think “hierarchical models” when you hear “random effects.”","type":"content","url":"/fixed-effects-v-hierarchical#fixed-effects-clustered-standard-errors","position":3},{"hierarchy":{"lvl1":"Fixed Effects and Hierarchical Models","lvl2":"Things To Remember:"},"type":"lvl2","url":"/fixed-effects-v-hierarchical#things-to-remember","position":4},{"hierarchy":{"lvl1":"Fixed Effects and Hierarchical Models","lvl2":"Things To Remember:"},"content":"Everything you learned about when and how you can use hierarchical models applies to fixed effects + clustered standard errors, except that fixed effects + clustered standard errors are even more robust.\n\nIf you’re using fixed effects for groups that might be subject to common shocks, you should probably also be using clustered standard errors.\n\nRandom effects + clustered standard errors is just a different term for hierarchical models, and often you’ll just hear them called “random effects models” or “mixed effects models”.","type":"content","url":"/fixed-effects-v-hierarchical#things-to-remember","position":5},{"hierarchy":{"lvl1":"What Is Matching?"},"type":"lvl1","url":"/matching-why","position":0},{"hierarchy":{"lvl1":"What Is Matching?"},"content":"This week we’ll be exploring matching: an approach to analyzing observational data that is primarily designed to do the same types of analyses as regression, but with less sensitivity to the functional form assumptions implicit to regression.\n\nAs we move forward, I’ll be drawing a lot (including most figures) from \n\nHo, Imai, King and Stuart (2007) and two of Gary King’s public lectures on youtube (\n\ntheory, \n\nimplementation). I’ve streamlined his argument and tried to adapt it for the concepual framworks, language, and level of technical depth we’re targeting in this class, but if you’re really into this topic, that source material may be extremely valuable to explore.\n\n","type":"content","url":"/matching-why","position":1},{"hierarchy":{"lvl1":"What Is Matching?","lvl2":"Model Dependency"},"type":"lvl2","url":"/matching-why#model-dependency","position":2},{"hierarchy":{"lvl1":"What Is Matching?","lvl2":"Model Dependency"},"content":"To understand matching, it helps to start with the problem matching is designed to solved: model dependence.\n\nThe term model dependence refers to a situation in which the results of an analysis are highly sensitive to apparently small decisions made by the researcher in how they specify a regression -- for example, whether they include X in their regression, or X + X^2, or whether they use X or log(X) as an independent variable.\n\n“But wait!” you may say: we have all sorts of test statistics for evaluating what fits our data best, so shouldn’t we be able to just pick the specification with the best [insert test statistic of choice here]?\n\nYes... most of the time. But where you get into trouble is when you want to use a model fit on data that covers a certain range of values to make predictions about outcomes outside that range. For example, consider the following example:\n\nHere we have a model where either a quadratic functional form or a linear functional form fits our data extremely well. Maybe there’s a third decimal place distinction in some test statistic, but really, they’re the same in the area we have our actual data.\n\nBut now suppose you’re asked to make predictions about outcomes at , say, x=5. Out there, the functional form you choose has a tremendous impact! So this is what’s called “model dependence”.\n\nNote that “model dependence” is a condition that depends on the application. If you fit this model to predict Y at x=1.02315, there’s probably very little model dependence here. But if you want to predict a value at x=5, there is. Something we’ll come back to.\n\n","type":"content","url":"/matching-why#model-dependency","position":3},{"hierarchy":{"lvl1":"What Is Matching?","lvl2":"Model Dependency, Causal Inference, and Imbalance"},"type":"lvl2","url":"/matching-why#model-dependency-causal-inference-and-imbalance","position":4},{"hierarchy":{"lvl1":"What Is Matching?","lvl2":"Model Dependency, Causal Inference, and Imbalance"},"content":"OK, fine, but I know I’m never supposed to extrapolate that far from my data, so who cares?\n\nWell... funny story: turns out we do this in causal inference all the time. That’s because if our treatment group and our control groups look very different (something called “imbalanced”), then we are sometimes actually extrapolating a relationship we estimate from the control group data to estimate what the treatment group would look like in areas where have no actual data from the treatment group.\n\nOK, let’s illustrate that. Suppose we have the following observational data (i.e. this is data from the world, not a randomized experiment). It’s made up, but let’s assume it’s from a consumer survey, where Treatment is whether the customer came to the store with a coupon, and “Outcome” is spending. Read T’s are consumer we’ve been treated (got promotion), blue Cs are consumers who weren’t treated (controls).\n\nAs you can see, this data is badly imbalanced, meaning that the range of values of Education are very different for our control population and our treatment population. For the control group, Education ranges ranges all the way from 12-28 years, while our treated group only has observations between 16 and 24.\n\nWhy does this matter? Suppose we now fit the following regression:Y = \\alpha + \\beta_1 treat + \\beta_2 educ + \\epsilon\n\nThat fit would look something like this:\n\n\n\nAs you can see, Treatment is above Control, so we have a large positive treatment effect!\n\nOK, but that clearly seems weird. It’s not fitting those control observations, so instead let’s try this:Y = \\alpha + \\beta_1 treat + \\beta_2 educ + \\beta_3 educ^2 + \\epsilon\n\nThat looks like this:\n\n\n\nWell, now the treatment effect is negative! Red below blue!\n\nSo which is right? Well... the thing that should probably make us uncomfortable is that the way we drew that red parabola is that we estimated a relationship for our full data, but really we were just fitting our control data, then applying that fit to treatment. As you can see, no treatment observations are really contributing to us fitting a big inverted U, since all the T observations are in the middle of the distribution.\n\nNow, if you want to take a strong theoretical position and say “I’m really confident education plays the same role for people who brought in coupons as those who did not”, then you can stop here. But...\n\nThe idea of matching is that maybe that should make us nervous, and that maybe there’s a way to avoid that\n\n","type":"content","url":"/matching-why#model-dependency-causal-inference-and-imbalance","position":5},{"hierarchy":{"lvl1":"What Is Matching?","lvl2":"Matching: Better thought of as pruning"},"type":"lvl2","url":"/matching-why#matching-better-thought-of-as-pruning","position":6},{"hierarchy":{"lvl1":"What Is Matching?","lvl2":"Matching: Better thought of as pruning"},"content":"\n\nWhen you hear the term “matching”, your first thought is probably that the focus of the method is finding pairs of observations that are similar, and... you’re not wrong. But a better way to think of matching is as a method for pruning observations that don’t have any close matches.\n\nIn other words, at its core, matching is about pruning back your dataset until you’re left with control and treatment observations that look relatively similar. Any control observations that are completely unlike any treatment observation (in terms of our explanatory variables) you drop, and any treatment observations that are completely unlike any controls you drop.\n\nSo if we ran matching here, we’d end up with the following dataset (dropped observations greyed out) (matching isn’t deterministic, there are choices, but a reasonably matching algorithm would likely do something like this):\n\n\n\nAs you can see, we’ve now dropped all the control observations that are completely unlike our treatment variables. And now the range of Education for control variables and treatment variables is about the same -- we have a “balanced” dataset.\n\nAnd now it doesn’t matter if we do a simple linear fit or if we include a quadratic term -- the results look exactly the same (i.e. no model dependence):\n\n\n\nAnd if we limit our focus to these observations, we see that regardless of the functional form we put in our regression, we get no treatment effect.\n\n","type":"content","url":"/matching-why#matching-better-thought-of-as-pruning","position":7},{"hierarchy":{"lvl1":"What Is Matching?","lvl2":"The Cost of Matching"},"type":"lvl2","url":"/matching-why#the-cost-of-matching","position":8},{"hierarchy":{"lvl1":"What Is Matching?","lvl2":"The Cost of Matching"},"content":"So what do we lose when we do matching? The main answer is that the group of people for whom our treatment effect is being estimated is changing dramatically. We aren’t estimating an effect for the whole population we started with, we’re estimating the effect for this small group where T and C overlap, which may or may not be useful in later applications.\n\nIn these kinds of studies, we often have far more control observations than treatment observations, and the control variables will often cover a much bigger range of values of your explanatory values (if not many people get treated, then it makes sense that the people who get treated may all look similar, and so may fall into a smaller range of, say, education than the general populous).\n\nIn these situtations -- where during matching you get to keep all your treated observations because they all have close controls, but you drop some controls, then what you’re estimating is the Average Treated on the Treated, which isn’t half bad (it’s often all we get with observational data).\n\nBut if you have Treated observations that don’t look like any control observations and so you have to drop them, well now you’re estimating an effect on... the sample of people in the range of explanatory variables for which there are both treated and untreated observations? And who really knows what that is.\n\n","type":"content","url":"/matching-why#the-cost-of-matching","position":9},{"hierarchy":{"lvl1":"What Is Matching?","lvl2":"Causal Inference Assumptions"},"type":"lvl2","url":"/matching-why#causal-inference-assumptions","position":10},{"hierarchy":{"lvl1":"What Is Matching?","lvl2":"Causal Inference Assumptions"},"content":"Before closing our discussion of the high level pros and cons of matching, it’s worth emphasizing one important point: both matching and good old fashion linear regression rest on the same basic assumption when it comes to causal inference: there are no baseline differences between the treatment and control groups after conditioning on observable variables.\n\nMatching, in other words, is a way to address possible modelling errors, not to fundamentally change what assumptions we’re making about the differences between treatment and control groups in terms of potential outcomes.\n\n","type":"content","url":"/matching-why#causal-inference-assumptions","position":11},{"hierarchy":{"lvl1":"What Is Matching?","lvl2":"In Summary"},"type":"lvl2","url":"/matching-why#in-summary","position":12},{"hierarchy":{"lvl1":"What Is Matching?","lvl2":"In Summary"},"content":"Matching is really best thought of a way of pruning your data to a sample where C and T observations look similar (impoves balance)\n\nWhere the original data has observations of C and T that don’t look similar (it’s imbalanced), matching helps reduce the sensitivity of results to the functional form assumptions you make in your regression.\n\nBut by changing the data on which you’re making an estimate, you are also changing the actually population for which you’re estimating your effect, which may be important to understand.\n\nTo use matching for causal inference, you have to make the same basic assumption you use for regular linear regression: controlling for observable differences is enough to eliminate baseline differences in terms of potential outcomes for our treated and untreated observations.","type":"content","url":"/matching-why#in-summary","position":13},{"hierarchy":{"lvl1":"How to Match"},"type":"lvl1","url":"/matching-how","position":0},{"hierarchy":{"lvl1":"How to Match"},"content":"In this reading, I’ll give a high level summary of how matching works before referring to a youtube lesson a the nitty gritty of a few specific implementations.\n\n","type":"content","url":"/matching-how","position":1},{"hierarchy":{"lvl1":"How to Match","lvl2":"Pruning Your Data"},"type":"lvl2","url":"/matching-how#pruning-your-data","position":2},{"hierarchy":{"lvl1":"How to Match","lvl2":"Pruning Your Data"},"content":"As noted in our last reading (this reading is a follow-on to \n\nThe Why of Matching, so if you haven’t read that start there), matching could be more appropriately called “pruning”, as the goal is to winnow down your dataset until you have a set of observations for which your control and treatment variables look very similar in terms of observable characteristics. So how do we do that?\n\nA simple matching algorithm would proceed like this:\n\nLoop over all your treated observations.\n\nFor each treated observation, look for the most similar untreated observation (not already in a pair) in terms of your control variables.\n\nIf that untreated observation is too dissimilar to the treated observation, throw away the treated observation. (As the user you have to pick a threshold for how dissimilar is ok.)\n\nIf not, call them a pair and keep both.\n\nWhen you’ve finished looping over your treated observations, throw away any unpaired untreated observations.\n\nWhen you’re done, you’ll have a collected of pairs of observations (one treated, one untreated), where both members of each pair are very similar in terms of their observable control variables. All other data has been thrown away.\n\nTo illustrate with the example from the last reading, if we started with this data:\n\n\nA simple matching algorithm would probably prune it down to something like this:\n\nThen, and here’s the cool part, you take this dataset and analyze just the way you would otherwise! Just run your regression on this dataset!\n\n","type":"content","url":"/matching-how#pruning-your-data","position":3},{"hierarchy":{"lvl1":"How to Match","lvl3":"Measuring Similarity","lvl2":"Pruning Your Data"},"type":"lvl3","url":"/matching-how#measuring-similarity","position":4},{"hierarchy":{"lvl1":"How to Match","lvl3":"Measuring Similarity","lvl2":"Pruning Your Data"},"content":"The biggest decision you have to make when doing matching is deciding how you want to measure whether two observations are “similar”. The most simple, commonly used strategy is to measure the dissimilarity of two observations in a pair by:\n\nFor each control variable, calculate the difference between the two observations in the pair (so if one has Education of 20 and one of 14, you’d get 6). Note the example above just has Education, but in reality you likely have dozens of these variables, so you do this for each variable.\n\nNormalize those differences by the standard deviation of the variable (so divide 6 by the standard deviation of Education)\n\nSquare all those differences, add them up, and take the square root. That’s your “similarity” score.\n\nBasically, this is like taking the euclidean distance between the points in some really high dimensional space, except you also normalize distances by their standard deviation, a strategy called “Mahalanobis Distance Matching”.\n\nOf course it’s not the only strategy -- the video linked at the bottom of this reading will direct you to a talk on three very good strategies, as well as their strengths and weaknesses -- but that’s generally the idea.\n\n","type":"content","url":"/matching-how#measuring-similarity","position":5},{"hierarchy":{"lvl1":"How to Match","lvl2":"When Can / Should I Use Matching?"},"type":"lvl2","url":"/matching-how#when-can-should-i-use-matching","position":6},{"hierarchy":{"lvl1":"How to Match","lvl2":"When Can / Should I Use Matching?"},"content":"Matching is best used in a somewhat odd situation: a place where you have some overlap in what your treated and untreated observations look like (called having “common support”),  but where you also have some areas where they don’t overlap (imbalance).\n\nThe first is necessary because when you prune your data, the goal is to keep only observations that look similar, so you need some area of overlap, or you won’t have anything to match!\n\nAt the same time, however, if there’s no imbalance, then you don’t really need to do matching.\n\nSo when should you use it? When your distributions have both areas of overlap and areas of imbalance.\n\n","type":"content","url":"/matching-how#when-can-should-i-use-matching","position":7},{"hierarchy":{"lvl1":"How to Match","lvl2":"Checking Balance"},"type":"lvl2","url":"/matching-how#checking-balance","position":8},{"hierarchy":{"lvl1":"How to Match","lvl2":"Checking Balance"},"content":"There’s a balance you have to strike when matching: the more strict you are about the maximium dissimilarity you’re willing to include before you throw out a pair of observations, the more balanced your final dataset will be, but the smaller your dataset will be do.\n\nRight? If you reject any pairs that aren’t almost exactly identical, you’ll end up with less data, but what’s left will be more balanced.\n\nSo for your application, you have to decide on whether it’s better to have the statistical power of more observations, or the better balance from fewer.\n\n","type":"content","url":"/matching-how#checking-balance","position":9},{"hierarchy":{"lvl1":"How to Match","lvl2":"Analyze!"},"type":"lvl2","url":"/matching-how#analyze","position":10},{"hierarchy":{"lvl1":"How to Match","lvl2":"Analyze!"},"content":"Now the best part of matching: now you just do do what you would have done normally.\n\nIn other words, you can think of this as a kind of “pre-processing step”, and now you can carry forward by feeding this into a regression just the way you would with the original data.\n\n","type":"content","url":"/matching-how#analyze","position":11},{"hierarchy":{"lvl1":"How to Match","lvl2":"Specific Models"},"type":"lvl2","url":"/matching-how#specific-models","position":12},{"hierarchy":{"lvl1":"How to Match","lvl2":"Specific Models"},"content":"OK, for the details of a few common models, please go watch this great video by Gary King -- you can probably start 15 minuntes in, and should watch till at least 45 minutes, though what follows is also really interesting!\n\nGary King on Matching","type":"content","url":"/matching-how#specific-models","position":13},{"hierarchy":{"lvl1":"Interpretable Models"},"type":"lvl1","url":"/interpretability","position":0},{"hierarchy":{"lvl1":"Interpretable Models"},"content":"For most applications, perform just as well as fancy pants models. \n\nhttps://​arxiv​.org​/abs​/1811​.10154\nAllow for non-specialists to see what goes into a model to debate ethics (after all, we data scientists have specialized knowledge when it comes to statistical methods, but not ethics)","type":"content","url":"/interpretability","position":1},{"hierarchy":{"lvl1":"How to Read (Academic Edition)"},"type":"lvl1","url":"/how-to-read-this-book","position":0},{"hierarchy":{"lvl1":"How to Read (Academic Edition)"},"content":"In this class, you will be asked to do significantly more reading than many of you — especially those of you from engineering backgrounds — are used to. Moreover, many of our reading may feel different from a lot of the reading that you’ve done in the past, and so I want to take a moment to discuss how you should approach reading in this — and indeed in any — reading intensive course.\n\nKnowing that many students in this class speak English is a second language (and so may find reading more time-consuming), and many of you also don’t have experience with more reading intensive courses, I have worked very hard to ensure that the readings I assign communicate key concepts as efficiently as possible. But as we will see, learning to answer causal questions well requires wrestling with the complexities that arise when apparently simple math meets the real world, and that unavoidably requires thoughtful exposition.","type":"content","url":"/how-to-read-this-book","position":1},{"hierarchy":{"lvl1":"How to Read (Academic Edition)","lvl2":"Read Actively"},"type":"lvl2","url":"/how-to-read-this-book#read-actively","position":2},{"hierarchy":{"lvl1":"How to Read (Academic Edition)","lvl2":"Read Actively"},"content":"The first major piece of advice I can offer is that you should always be active when reading for this course. That may mean taking notes on a separate piece of paper as you go, or highlighting passages that stand out and adding comments in the margins. But reading of the type you will encounter in this course should never be a passive process.\n\nThis is especially true any time you encounter mathematical notation. A key skill in answering causal questions is the ability to map concepts represented in mathematical notation onto facets of real world examples. With that in mind, any time you are reading something written in mathematical notation, it is good practice to think of a specific example and see if you can relate each term you encounter to the real world example.","type":"content","url":"/how-to-read-this-book#read-actively","position":3},{"hierarchy":{"lvl1":"How to Read (Academic Edition)","lvl2":"Be Patient with Examples From Different Domains"},"type":"lvl2","url":"/how-to-read-this-book#be-patient-with-examples-from-different-domains","position":4},{"hierarchy":{"lvl1":"How to Read (Academic Edition)","lvl2":"Be Patient with Examples From Different Domains"},"content":"Data science is an extremely diverse field. This course does its best to embrace that diversity though the use of examples from a wide range of substantive domains. This, at times, causes frustration among students as many examples will necessarily come from domains that don’t feel relevant to your particular interests. Try and resist this urge — while this may seem like a problem, it’s actually emblematic of a huge opportunity for intellectual arbitrage (the porting of insights that have been richly developed in one domain to a different domain where they are unfamiliar)!\n\nThis will be particularly relevant when we get to the study of causal inference (the study of how to answer Causal Questions), as there are lots of concepts that have been well-developed in the social sciences that people are only now starting to apply in industry, meaning many of the best texts and examples will be public policy or social science oriented.\n\nAnd while the downside of that is that there aren’t as many great books written about causal inference in industry as you may wish, the upside is that there are lots of opportunities to for young data scientists to innovate by applying these concepts in new ways!\n\nSo please bear with these examples, and practice trying to apply the concepts you read to an industry example that matters to you.","type":"content","url":"/how-to-read-this-book#be-patient-with-examples-from-different-domains","position":5},{"hierarchy":{"lvl1":"How to Read (Academic Edition)","lvl2":"Do NOT Summarize with LLMs"},"type":"lvl2","url":"/how-to-read-this-book#do-not-summarize-with-llms","position":6},{"hierarchy":{"lvl1":"How to Read (Academic Edition)","lvl2":"Do NOT Summarize with LLMs"},"content":"I fully recognize that there is a strong temptation when faced with a long reading to stuff it into a Large Language Model and ask for a summary. Don’t.\n\nThere are a few reasons for this. The first is that while an LLM can provide you with a broad summary of what you’re reading, it will necessarily have to exclude all the nuance in the original reading. If you just want to figure out if a reading is generally relevant to your interests, that’s fine; but you’re here to learn a subject — one that can can be infuriatingly subtle — and cutting out all those nuances will limit what you can learn and prevent you from being able to test your understanding of concepts by wrestling to understand how each new sentence relates to what you’ve read previously. So just as the goal of the readings isn’t to allow you to answer our reading reflection questions (those are just there to draw your attention to especially salient points), nor is the goal of the readings to understanding it at the level of a summary.\n\nThe second big reason is that the process of summarizing material yourself is critical to consolidating your learning. This insight comes, in part, from research on whether students taking notes on computers learn more effectively than students taking notes on paper. This research has found that students taking notes on computers can write much more quickly than students taking notes by hand, but that counter-intuitively this seems to result in worse learning outcomes (based on subsequent learning assessments). Why? It appears that students taking notes on computers are effectively able to transcribe everything happening in class, while students taking notes on paper have to think about the material in real time in order to summarize it enough that they can keep up taking notes.\n\nLetting LLMs summarize material for you seems likely to cause a similar issue — by allowing an algorithm to organize the information in a more concise manner, it deprives you of the opportunity to engage with the material to create your own summary, a process that forces you to actively think about the connections between concepts. The importance of this type of active learning is one of the biggest bedrock findings of research on learning in recent years — students who have material given to them (e.g., through a passive lecture) often think they understand material, but it is the students who learn material actively — through class or group exercises, problem sets, or other activities — who perform better on learning assessments.\n\nFinally, learning to focus on a reading for a prolonged period of time is an important skill, and one we practice less and less in the modern age. Sometimes letting our attention flitting from thing to thing is fine, but being able to focus for prolonged periods when required is an important skill to cultivate! (If you’re interested, you can find a really interesting discussion of \n\nthis idea here.)","type":"content","url":"/how-to-read-this-book#do-not-summarize-with-llms","position":7},{"hierarchy":{"lvl1":"Backwards Design"},"type":"lvl1","url":"/backwards-design","position":0},{"hierarchy":{"lvl1":"Backwards Design"},"content":"Backwards Design is a way of developing an efficient strategy for completing a new data science project, and in my view it is one of the most important skills of a professional data scientist.\n\nIf you don’t have a lot of professional data science experience, it may not be obvious why this is an important skill, or even why I call it a “skill.” That’s because most data science students’ experience with project development comes from classroom exercises or sites like kaggle. These types of projects are excellent opportunities for learning, but it is usually the case that -- unbeknownst to the student -- these projects have been carefully tailored to have clearly defined goals, and they come with data sets that have been cleaned and filter to provide only relevant variables. This is usually done for good reasons -- the instructors design these exercises in a way that focuses student attention on the skills that they are trying to develop (like model selection or model interpretation). But as a result, students often come away with the impression that most of what data scientists do is work with statistical models.\n\nIn reality, however, often the most important thing that a data scientist does is (a) develop and articulate a concrete, feasible objective of a data science project, and (b) develop a strategy for achieving that objective efficiently. And Backwards Design is one of the best ways to go about accomplishing both of these goals.\n\n","type":"content","url":"/backwards-design","position":1},{"hierarchy":{"lvl1":"Backwards Design","lvl2":"Overview"},"type":"lvl2","url":"/backwards-design#overview","position":2},{"hierarchy":{"lvl1":"Backwards Design","lvl2":"Overview"},"content":"As the name implies, the idea Backwards Design is to start by clearly defining where you want to end up at the end of the project, and then working backwards to figure out exactly what you need to do to get there. Backwards Design is actually a common project management strategy and a range of different domains, and so you may already be familiar with the strategy and broad terms. In this class, however, we will focus on a five-step strategy for doing Backwards Design in data science:\n\nDefine the problem you want to solve.\n\nDefine a question that you wish to answer to help you solve this problem.\n\nArticulate exactly what an answer to your question would look like.\n\nDetermine the variables you would need in order to generate that answer.\n\nIdentify data sets with those variables, and develop a strategy for bringing them together.","type":"content","url":"/backwards-design#overview","position":3},{"hierarchy":{"lvl1":"Backwards Design","lvl2":"1) Define Your Problem"},"type":"lvl2","url":"/backwards-design#id-1-define-your-problem","position":4},{"hierarchy":{"lvl1":"Backwards Design","lvl2":"1) Define Your Problem"},"content":"This first step should be the most straightforward, and yet you will be surprised at how often it is never actually explicitly addressed. People get so excited about the idea of data science that they will often come to you (the data scientist) with the data set and say “do some data science with this!” So the first thing you should always do when starting a data science project is make sure that you can clearly articulate the objective of the project. In addition, you should always make sure that your stakeholder agrees with that articulation of the problem you are trying to address! There’s nothing worse than spending weeks on a project and then discovering that it’s not actually a value to your stakeholder.\n\nHere are a few examples of defined problems:\n\nWe don’t know how to reduce mass incarceration.\n\nMy business can’t identify potential new customers.\n\nWe don’t know who is going to develop Alzheimers, so we can’t test early interventions.","type":"content","url":"/backwards-design#id-1-define-your-problem","position":5},{"hierarchy":{"lvl1":"Backwards Design","lvl2":"2) Define the Question You Wish to Answer"},"type":"lvl2","url":"/backwards-design#id-2-define-the-question-you-wish-to-answer","position":6},{"hierarchy":{"lvl1":"Backwards Design","lvl2":"2) Define the Question You Wish to Answer"},"content":"Although not everyone will agree with us, it is my view the data science is fundamentally the practice of using data to quantifiably answer questions about the world.\n\nFor example, when we ran our regressions of birth weight on various demographic variables and whether the mother smoked during pregnancy, those models were answering the question “is maternal smoking associated with lower birth weight (at a statistically significant level after controlling for other confounds)?”\n\nIf someone who runs a commerce website runs an A/B test where users visiting the site are randomly assigned to see two versions of a new landing page, and we then track their purchasing behavior, then when we analyze that data statistically what we’re doing is answering the question “Which of these designs is more effective at getting customers to buy things?”\n\nAnd finally we can think of supervised machine learning algorithms as answering two types of question: there’s the broad question that you answer by building a model and evaluating it (“can we identify cancer from patient x-rays, and if so, how well?”), and then the narrow question the is answered each time the model is run (“given this x-ray, how likely is this patient to have cancer?”). (There’s a small digression on supervised machine learning and this “data science is about answering questions” conceptual framework at the end of this if you’re interested).\n\nSo the next step in backwards design is to ask yourself: what question, if answered, would help you solve the problem that motivates you?","type":"content","url":"/backwards-design#id-2-define-the-question-you-wish-to-answer","position":7},{"hierarchy":{"lvl1":"Backwards Design","lvl3":"Defining a Good Question","lvl2":"2) Define the Question You Wish to Answer"},"type":"lvl3","url":"/backwards-design#defining-a-good-question","position":8},{"hierarchy":{"lvl1":"Backwards Design","lvl3":"Defining a Good Question","lvl2":"2) Define the Question You Wish to Answer"},"content":"A key feature of a good question is one that it is concrete, tractable and answerable by a data science project. Your question meets these criteria if it directly implies how you should approach the data science project, and that approach seems feasible. If your question is so vague that you don’t immediately start thinking about the data you want to collect, it’s not a good motivating question.\n\nTo illustrate, here are a set of bad questions to the three problems described above:\n\nWhat policies reduce mass incarceration?\n\nCan machine learning help me identify potential customers.\n\nWhat indicates Alzheimers?\n\nBy contrast, here’s a set of concrete, tractable, and answerable questions:\n\nDoes the availability of grand juries result in longer sentences? (Grand juries are a pool of citizens prosecutors can ask for guidance on sentencing. In theory they’re supposed to hold prosecutors accountable, but in reality its often said that prosectors can shape the information grand juries get so they reach the recommendations that prosecutors wanted to begin with).\n\nWhat attributes are common to the customers who buy the most from my business?\n\nAre there lab results common in patients who later develop Alzheimers (diagnosed post-mortem) that we don’t see in patients who don’t go on to develop Alzheimers?\n\nFor the first set, we’ve asked questions, but they’re so vague that it’s not clear how you should approach answering the question. In the second set, by contrast, likely first steps are very clear. For example, the first good question clearly implies we need to find data on sentencing from places with and without grand juries. For the second question, its clear we need data on our current customers, and data from the general population for comparison. And for the last question we clearly want lab data from patients with and without diagnosed Alzheimers!\n\nMoreover, for these answerable questions, you can imagine what the answer to the question will look like: for the first, you could have a regression that regresses sentences on grand jury availability controlling for crime committed; and for the second, you could imagine a table that compares various demographic characteristics of customers to non-customers.","type":"content","url":"/backwards-design#defining-a-good-question","position":9},{"hierarchy":{"lvl1":"Backwards Design","lvl3":"Why is Having a Good Question Important?","lvl2":"2) Define the Question You Wish to Answer"},"type":"lvl3","url":"/backwards-design#why-is-having-a-good-question-important","position":10},{"hierarchy":{"lvl1":"Backwards Design","lvl3":"Why is Having a Good Question Important?","lvl2":"2) Define the Question You Wish to Answer"},"content":"It will save you from getting lost in your data, since it helps you focus you energy.\n\nBeing able to articulate the question you wish to answer allows you to make sure that answering that question will actually help address your motivating problem (/make sure that your stateholder agrees that answering your question will help them). There’s nothing worse than getting excited, diving into your data, doing lots of work, and then getting a result that doesn’t actually help address the problem that motivated you (but it happens all the time).\n\n","type":"content","url":"/backwards-design#why-is-having-a-good-question-important","position":11},{"hierarchy":{"lvl1":"Backwards Design","lvl2":"3) Write Down What An Answer Would Look Like"},"type":"lvl2","url":"/backwards-design#id-3-write-down-what-an-answer-would-look-like","position":12},{"hierarchy":{"lvl1":"Backwards Design","lvl2":"3) Write Down What An Answer Would Look Like"},"content":"Seriously. Do it. Not abstractly: I mean draw the graph, figure, table, dataset with columns of predicted values and predictors, or set of model diagnostics you want to generate as a way of answering your question. Literally draw the graph, label the axes, etc.\n\nWhy?\n\nIf you can’t, then it turns out your question wasn’t sufficiently concrete.\n\nYou can then show this to your stakeholder to ensure they think this constitutes an answer that would help them solve their problem (and avoid later being told your work doesn’t actually help them)\n\nIt makes it even clearer what steps you need to do next to generate this result.\n\n","type":"content","url":"/backwards-design#id-3-write-down-what-an-answer-would-look-like","position":13},{"hierarchy":{"lvl1":"Backwards Design","lvl3":"Falsifiability","lvl2":"3) Write Down What An Answer Would Look Like"},"type":"lvl3","url":"/backwards-design#falsifiability","position":14},{"hierarchy":{"lvl1":"Backwards Design","lvl3":"Falsifiability","lvl2":"3) Write Down What An Answer Would Look Like"},"content":"OK. So now you’re written down what an answer to your question looks like. But there’s one other key feature of a good question that we didn’t get into above: it should be falsifiable, which means that (a) you should be able to articulate a hypothesis about the answer to your question and (b) know what a result to your question would look like.\n\nSo when writing down what your answer should look like, do the following:\n\nState a hypothesis about what you think the answer to your question is likely to be.\n\nDraw what an answer to your question would look like if your hypothesis is true.\n\nDraw what an answer to your question would look like if your hypothesis is false.\n\nFor example, consider our question about grand juries and sentecing. My hypothesis might be that grand juries result in longer sentences because they insulate prosectors from accountability.\n\nMy result, as described above, could be a regression table where I regress sentences on whether a county has a grand jury along with controls for crime committed.\n\nThe answer if my hypothesis is true is that we’d have a positive coefficient on the presence of grand juries.\n\nThe answer if my hypothesis is false is that we’d have a zero or negative coefficient on the presence of grand juries.\n\nWhy do all this? Because it helps ensure that the way we’re planning to answer our question will actually answer it by generating different results in different states of the world.\n\n","type":"content","url":"/backwards-design#falsifiability","position":15},{"hierarchy":{"lvl1":"Backwards Design","lvl2":"4) What Data Do You Need?"},"type":"lvl2","url":"/backwards-design#id-4-what-data-do-you-need","position":16},{"hierarchy":{"lvl1":"Backwards Design","lvl2":"4) What Data Do You Need?"},"content":"Congratulations! You’ve now completed the really hard part of a data science project: defining your goals. Now we turn to the easy stuff.\n\nFirst, now you know your goal -- the result described above -- we turn to how we will actually answer our question. So ask yourself:\n\nWhat variables do I need to make the result I described above,\n\nWhat population do I need represented in that data\n\nSo let’s think about our business trying to find new customers. Clearly, we need data on (a) customer spending, and (b) the demographics of those same customers.\n\nWe also need data on both people who spend a lot, and people who don’t spend a lot so we can compare these two populations. We could do this either by getting data on all our customers and comparing big spenders from people who don’t buy much (if there’s a lot of variation in the data on level of spending), or we could compare current customers to the general public (most of whom aren’t customers).\n\n","type":"content","url":"/backwards-design#id-4-what-data-do-you-need","position":17},{"hierarchy":{"lvl1":"Backwards Design","lvl2":"5) Where Can You Get That Data?"},"type":"lvl2","url":"/backwards-design#id-5-where-can-you-get-that-data","position":18},{"hierarchy":{"lvl1":"Backwards Design","lvl2":"5) Where Can You Get That Data?"},"content":"OK, now you know the variables you need measured and the populations for whom you need those variables. Now let’s figure out:\n\nWhere can I get that data, and\n\nIf the data will come from different datasets, how will I combine them?\n\nIn the customer example above, for example, we can start by looking for the data the company already has on its current customers. What’s in that data?\n\nWe can also look for similar demographic data for non-customers using a resource like the American Community Survey (the annual survey run by the US Census bureau).\n\nIf we use government data for our comparison group, we’ll then have to make sure we get comparable samples, so we’ll want to make sure we can match our observations on things like age, gender, and where people live, so we’ll need to make sure we have those variables in both datasets.\n\n","type":"content","url":"/backwards-design#id-5-where-can-you-get-that-data","position":19},{"hierarchy":{"lvl1":"Backwards Design","lvl2":"Wrapping Up"},"type":"lvl2","url":"/backwards-design#wrapping-up","position":20},{"hierarchy":{"lvl1":"Backwards Design","lvl2":"Wrapping Up"},"content":"Congratulations!\n\nBy the time you’ve done these 5 steps, you’ve managed to develop a concrete plan for exactly where you’ll focus your time, and you’ve nearly guaranteed that the result you’re working to generate will actually be useful in solving the problem that motivates you or your stakeholder. There’s still a lot of data wrangling, model selection, etc. ahead, but at least you won’t get lost in your data, or do lots of work that ends up no helping anyone!\n\nWant a template for this? Great news! \n\nYou can download one here!\n\n","type":"content","url":"/backwards-design#wrapping-up","position":21},{"hierarchy":{"lvl1":"Backwards Design","lvl2":"A Digression on Supervised Machine Learning"},"type":"lvl2","url":"/backwards-design#a-digression-on-supervised-machine-learning","position":22},{"hierarchy":{"lvl1":"Backwards Design","lvl2":"A Digression on Supervised Machine Learning"},"content":"As noted above, we can think of superived machine learning as a tool that answers two types of questions: the first is the broad question of “can we predict [outcome of interest] using [variables we have] and the training set we have access to?”, and the second is the more narrow prediction question “for a given set of predictors, what value of [outcome of interest] would the model predict for a given observation”?\n\nThe first, I think, is pretty straightforward. But there’s a nuance to the second question that’s super important to understand: when we ask a supervised machine learning it’s prediction for a given observation, what we’re fundamentally asking your model is: “how do you think the entity who labeled the data in your training data set would label this new observation?”\n\nBecause that’s all that supervised machine learning does: it develops models that are designed to replicate the behavior that gave rise to the data set due used for training your model. For example, if you train a supervised machine learning algorithm to label pictures with the name of the animal in the picture by feeding it a bunch of pictures that have been labeled by undergraduates at an American university, than what you are training that machine learning algorithm to do is answer the question “how would an American undergraduate label this photo” every time it sees an unlabeled photograph.\n\nObviously different supervised machine learning algorithms go about trying to answer this question in different ways, and some will be more successful than others depending on the context (which is why we spend so much time studying model selection in machine learning courses), but answering this question is always the goal to which they aspire.\n\nThis is a bit of a digression, but I think it’s an important one: recognizing that this is all supervised machine learning algorithms do is important because it helps you, the data scientist, understand the limitations of supervised machine learning algorithms. For a surprisingly long time, people thought that machine learning algorithms were incapable of harboring racial or sexist prejudices. They are, after all, just built of math, and math can’t be racist, can it? And so companies like amazon tried to build supervised machine learning algorithms to help them decide who to hire. The problem, though, is that they trained them using data on which people human employees had decided to hire in the past, and data from subjective employee evaluations that had been made by human supervisors. And because this gave rise to an algorithm that looked at people’s resumes and asked itself “what would Amazon’s (very human) hiring staff and supervisors have thought of this person?,” the algorithm of course inherited all the biases of those humans. And so, OOPS!, when Amazon suddenly realized that “their new recruiting engine didn’t like women,” \n\nthey had to abandon the project.\n\nOK, digression on bias in data science complete. For now. :)","type":"content","url":"/backwards-design#a-digression-on-supervised-machine-learning","position":23},{"hierarchy":{"lvl1":"Ethics in Data Science"},"type":"lvl1","url":"/ethics-and-bias","position":0},{"hierarchy":{"lvl1":"Ethics in Data Science"},"content":"In recent years, for example, we’ve seen near endless examples of data science systems not just failing to solve societal inequities, but instead reinforcing them. A hiring algorithm at Amazon was recently scrapped after it was discovered that it systematically \n\ndiscriminated against female job candidates. An algorithm for prioritizing kidney transplants was found to make it less likely that \n\nBlack patients would receive kidney transplants than White patients. Another medical algorithm recommended less preventative care for \n\nsick Black patients than White patients. And a popular “risk assessment” algorithm used by judges around the country to make decisions about whether defendants should be released pending trial, held on bond, or held without bonds—as well as how convicted criminals should be sentenced—\n\nwas found to make more mistakes for Black defendants than White defendants, systematically reporting to judges that they were more likely to re-offend than they actually were according to subsequent analyses.\n\nSimilarly, in the political sphere \n\nFacebook’s own research has shown that its algorithms polarize users and drive division, a fact that internal documents show its own executives chose to largely ignore. Facebook’s internal research also found that “64% of all extremist group joins are due to our recommendation tools” like “Groups You Should Join” and the Discover tools.\n\nWhile much of these problems are the result of a lack of carelessness or a lack of critical thought on the part of the data scientists developing these algorithms, in other cases problems have arisen because of a lack of critical evaluation of data science tools by their users. In 2020, for example, it was discovered that company that provided doctors with (suspiciously free) software designed to provide “clinical decision support” (advice on tests that might be advisable or drugs that might be prescribed for patients based on their medical records) was taking kickbacks from an opioid producing pharmaceutical company to ensure opioids remained a suggested treatment for patients, despite the strong recommendation of groups like the American Medical Association to reduce opioid use in light of the opioid overdose epidemic the US.\n\nMotivation: piles of case studies. See list under “Prediction: ML Bias” (March 29 at the moment) here\nTwo types of “unethical algorithms: biased performance and biased predictions.\n\nBiased Performance:\n\nSuper ethically straightforward—works for one group (e.g., White people) but not another (e.g., Black people). “Works” can be defined in terms of whatever performance metrics we care about (accuracy, recall, etc.), but the point is that the error rate is different across groups (e.g., the zoom background blurring algorithm that can’t see Black faces, so just blurs their screens).\n\nBiased Predictions:\n\nNow the much more complicated one: suppose that your model gives different predictions for people from different group (Black/White), but that’s because that’s what is in the data. Is that ok?\n\nIf the data is biased: probably not! E.g. Amazon (I think this is what happened) tried to make algorithm that would look at a resume and predict how good an employee that person would be if hired. So it used resumes to train a dataset using managerial employee ratings as labels. But… managers were biased. That was the problem. So algorithm just learned to recapitulate the misogynistic rating of managers. Gotta make sure you know what question is being answered by your algorithm…\n\nIf the data is NOT biased: depends! Suppose that a model to predict success of a kidney transplant designed to maximize the efficiency of kidney transplant allocations systematically scores black recipients as being less likely to still have their transplanted kidneys and be healthy after ten years… but it’s not an anomaly of the model, it’s a real fact in the world. Is it OK to down-rank Black recipients? (not a contrived example). In that context, providing black recipients with less access to kidneys seems deeply problematic, even if rating them higher will result in less “years of healthy kidneys” after transplant. Here it seems like racially disparate outcomes are unethical. But what if we want to allocate HIV preventative interventions? Black Americans have a much higher incidence of HIV than any other ethnic group in the US—a model that suggests targeting their communities with more interventions would seem appropriate, on a model that doesn’t recognize that HIV rates in the Black community are more than 2x the next closest group seems like it wouldn’t be very helpful.\n\nChicago crime example: \n\nhttps://​www​.theverge​.com​/c​/22444020​/chicago​-pd​-predictive​-policing​-heat​-list\n\nhttps://​filtermag​.org​/chicago​-crime​-prediction​/\n\nhttps://​medium​.com​/analytics​-vidhya​/predicting​-arrests​-looking​-into​-chicagos​-crime​-through​-machine​-learning​-78697cc930b9\n\nOpacity\n\nCan’t audit normatively\n\nCan’t audit for accuracy: \n\nhttps://​www​.nytimes​.com​/2017​/06​/13​/opinion​/how​-computers​-are​-harming​-criminal​-justice​.html\n\nBut… it’s data? How do our values come into play!\nLike… checking performance of algorithms for different racial/ethnic groups.\nOr looking for racial/gender heterogeneity during descriptive analyses.\n\nThis research found the key driver of polarization was Facebook’s decision to design recommendations algorithms that prioritized “user engagement” (clicks, shares, comments) which resulted in promoting partisan, polarizing, sensationalist, or extreme content.","type":"content","url":"/ethics-and-bias","position":1},{"hierarchy":{"lvl1":"Making Decisions Using Data"},"type":"lvl1","url":"/from-data-to-decisions","position":0},{"hierarchy":{"lvl1":"Making Decisions Using Data"},"content":"(This is something that I know I need to add to my classes but I haven’t really managed integrated yet. I talk to my students about that fact that they should just pray at the altar of p<0.05, but instead weigh the relative costs and benefits of Type 1 and Type 2 errors in the context in which they are trying to make a decision. But where I really struggled is the fact that you can’t directly map P values onto decision theory very easily because of all of the weirdnesses of frequentist P values—e.g. A p-value of 0.05 means that under the null, the odds of a Type 2 is 5%... but that means the ACTUAL odds of a Type 2 error if you have a p-value of 0.05% is pr(null is true) * 0.05. 🤦‍♂️. )","type":"content","url":"/from-data-to-decisions","position":1},{"hierarchy":{"lvl1":"Writing to Stakeholders"},"type":"lvl1","url":"/writing-to-stakeholders","position":0},{"hierarchy":{"lvl1":"Writing to Stakeholders"},"content":"In the spirit of what is to follow, I will begin with the most important idea in this reading:\n\nThe key to effective writing to stakeholders is to continually ask yourself — where ever you are in your document, whatever your thinking of writing, and whatever you’re debating including — if my stakeholder stopped reading my report right at this spot, have I told them everything I want them to have learned.","type":"content","url":"/writing-to-stakeholders","position":1},{"hierarchy":{"lvl1":"Writing to Stakeholders","lvl2":"Why Learning to Write to Stakeholders is Hard"},"type":"lvl2","url":"/writing-to-stakeholders#why-learning-to-write-to-stakeholders-is-hard","position":2},{"hierarchy":{"lvl1":"Writing to Stakeholders","lvl2":"Why Learning to Write to Stakeholders is Hard"},"content":"As students (especially data science students), the way most of us were taught to write reports is to:\n\nstart with an introduction that helps explain the broader context in which the report is being positioned,\n\ndescribes the data that we intend to use,\n\ndescribe that how we have wrangled and cleaned that data,\n\ndescribe how we plan to model that data,\n\nreport the results,\n\nand discuss limitations and tack on a boilerplate conclusion.\n\nThis structure makes a lot of sense in the context of a class because the order of presentation mirrors the objectives of the assignment: demonstrate that you understand the substantive topics that are being taught, demonstrate that you are being thoughtful about the data that you are collecting and that you have internalized the emphasis your instructors have placed on the importance of data cleaning, and that you understand the principles of data modeling. Results come last because in the context of a class, your results don’t actually matter. No professor is going to make a major business decision on the basis of a student report, and no government is going set policy on the basis of what you say.\n\nThis structure — which almost entirely front loads material that is not particularly interesting to the instructor — is also viable because it is basically the job of the reader (your instructor or teaching assistant) to read everything you wrote.","type":"content","url":"/writing-to-stakeholders#why-learning-to-write-to-stakeholders-is-hard","position":3},{"hierarchy":{"lvl1":"Writing to Stakeholders","lvl2":"Putting Yourself in the Stakeholder Shoes"},"type":"lvl2","url":"/writing-to-stakeholders#putting-yourself-in-the-stakeholder-shoes","position":4},{"hierarchy":{"lvl1":"Writing to Stakeholders","lvl2":"Putting Yourself in the Stakeholder Shoes"},"content":"None of that is true in the real world. In fact, I would argue that being taught to write reports in this manner is about the worst possible preparation one could give students for learning to communicate to real-world stakeholders for two key reasons:\n\nIn the real world, the only thing that your stakeholder actually cares about are the conclusions you have reached about how to solve their problem (i.e. your results and how they relate to the stakeholder’s problem).\n\nThere is nothing more scarce in any organization than a decision makers time, and so the moment it stops being obvious to the decision maker why the material their reading is directly relevant to solving their problem, there is a very high probability that they will let their attention shift to one of the other hundred critical issues vying for their attention.\n\nBecause of these two facts, when writing to a stakeholder you should always — always — be asking yourself two questions:\n\nIf my stakeholder stopped reading right now, have I already told them the things that I think it is most important they walk away knowing? and\n\nAt every transition — between sections, between topics, and even between paragraphs — is it explicitly clear to the reader that what follows is relevant to solving the stakeholder’s problem so they have and affirmative reason to not get distracted?\n\nWhat does this look like in practice? It depends a little bit on how much of your stakeholder’s attention you think you can get in the best of circumstances (intelligence briefings were written very differently for Donald Trump than for Barack Obama), but the structure I am going to advocate for is roughly the following:\n\nExecutive Summary: A full summary of absolutely everything you want your stakeholder to walk away knowing if they were to read nothing else in about two to four paragraphs. State the problem that you are setting out to address, state the question that you’re going to answer in order to help solve that problem, and at a very high level state how you are going to answer that question, state the answer you have found, reiterate how that result helps solve the problem.\n\nContext: With the Executive Summary out of the way, you have hopefully piqued your stakeholder’s interest just enough to double back and provide a little more context about the problem you are trying to address and the context and which it is situated. But don’t get complacent — even here, it is important to very clearly and explicitly motivate why all of the information you are providing is relevant to solving the stakeholder’s problem effectively.\n\nThis is where the answers you generated to your Exploratory Questions fit — they provide information to your stakeholder about why you have chosen to prioritize certain facets of the problem, and why those choices are correct.\n\nYour Strategy: Now you get to explain how you are going to answer the question that will help solve the stakeholder’s problem in more detail. But don’t get lost in the weeds — the stakeholder only needs to understand enough about your strategy (including your data) to be able to evaluate how much confidence they should have in our results and conclusions.\n\nThis is perhaps the hardest section for data science students to write, not because they can’t think of what to put here, but because they want to include way, way too much. There is a very natural and very human tendency when you finish a project that you have put a tremendous amount of work into to talk about all of the work you did. And most of that work will involve wrestling with data, dealing with merging issues, tuning models, etc. But almost nothing you have done in this domain is something that your stakeholder needs to know about. You can write it all up — there may very well be some people on the stakeholder’s staff who will want to read it — but it belongs at the back of the report in an appendix, not in the body of the report.\n\nThe only exceptions to this rule are places where you exercised substantial discretion in how you handled the data or constructed your sample. If you exercised discretion in a substantial way that may impact how one interprets the conclusions of the report — for example, you had to choose which states to include in an analysis as control states — you can/should include a brief explanation for your reasoning along with a link to an appendix were you discuss those choices in detail.\n\nYour Results: Now you get to present your results in greater detail. Note that nothing here should come as a surprise to the reader — don’t try and “hide the ball” to build suspense by not revealing your findings till now because while you may think what you’ve done is so interesting that the suspense will draw the reader in, in reality, it just means that when your stakeholder doesn’t make it past the Executive Summary, they will not have learned the thing you spent so much time trying to learn.\n\nAlso, note that while this structure still has a results section towards the end, because you have kept your Context and Strategy sections very short, it should actually be coming up much sooner than your results would come up in a normal class report (in terms of the page number on which it appears).\n\nRelating It Back To The Problem: And now we bring things full circle — now that you presented your results, you have to make sure that your reader hasn’t lost the thread by relating your results back to the problem that motivated your analysis to begin with.","type":"content","url":"/writing-to-stakeholders#putting-yourself-in-the-stakeholder-shoes","position":5},{"hierarchy":{"lvl1":"Writing to Stakeholders","lvl3":"Wow! What a Great Way of Thinking About This? Did You Invent This Yourself?","lvl2":"Putting Yourself in the Stakeholder Shoes"},"type":"lvl3","url":"/writing-to-stakeholders#wow-what-a-great-way-of-thinking-about-this-did-you-invent-this-yourself","position":6},{"hierarchy":{"lvl1":"Writing to Stakeholders","lvl3":"Wow! What a Great Way of Thinking About This? Did You Invent This Yourself?","lvl2":"Putting Yourself in the Stakeholder Shoes"},"content":"Obviously not. And now that you are primed to think about how writing can be organized in a manner that reflects the likelihood that most people who pick up a document won’t actually read it all the way to the end, you will start to see how people front load the things they think matter most everywhere.\n\nJournalism is the quintessential example of this style of writing. No one reads entire news articles, so they are always nearly organized with the most critical information up front, after which they double back to fill in additional details for anyone still reading. There are a number of different ways this can be accomplished — for example the \n\ninverted pyramid — start with “who? what? when? where? how?”, then add important details, then add context — is one of the first article formats journalists are introduced to.\n\nBut the structure I think you’re likely to see most if you start looking for it is that in the first two or three paragraphs of a well-written news story, you will notice that there is a single paragraph that is designed to summarize everything that the journalist wants you to know about the story — the “\n\nnut graph”.\n\nAcademic publications also usually follow this structure. They start with an abstract (essentially an Executive Summary of the Executive Summary), an “introduction” (which is, in effect, an Executive Summary), a literature review (to establish why what they’re doing is novel and provide some broader context), a not too long discussion of their methodology, their results, and a short conclusion that ties the results back to the motivating question. All the sensitivity analyses, detailed discussion of the data, etc.? Those go into an “Online Only Appendix,” a document that is often easily twice as long as the article itself.","type":"content","url":"/writing-to-stakeholders#wow-what-a-great-way-of-thinking-about-this-did-you-invent-this-yourself","position":7},{"hierarchy":{"lvl1":"Writing to Stakeholders","lvl2":"Other Points To Bear In Mind"},"type":"lvl2","url":"/writing-to-stakeholders#other-points-to-bear-in-mind","position":8},{"hierarchy":{"lvl1":"Writing to Stakeholders","lvl2":"Other Points To Bear In Mind"},"content":"","type":"content","url":"/writing-to-stakeholders#other-points-to-bear-in-mind","position":9},{"hierarchy":{"lvl1":"Writing to Stakeholders","lvl3":"Putting The Pieces Together","lvl2":"Other Points To Bear In Mind"},"type":"lvl3","url":"/writing-to-stakeholders#putting-the-pieces-together","position":10},{"hierarchy":{"lvl1":"Writing to Stakeholders","lvl3":"Putting The Pieces Together","lvl2":"Other Points To Bear In Mind"},"content":"In this course, we’ve spent a lot of time establishing taxonomies — ways of organizing and recognizing the many distinct things that we do as data scientists. The assignments we have done for this class have often been structured in a manner to emphasize these distinctions. But when writing to a stakeholder, you don’t want to hold too rigidly to those distinctions. A good report to a stakeholder will not consist of stapling together all of the assignments we’ve done in this class one after the other. The goal of a good report is to construct a narrative that consistently and effectively communicates a key idea to the reader.\n\nMany of you will be familiar with the idea of the “five-paragraph essay.” The five-paragraph essay is a structure that is often used to introduce students to essay writing — you start with an introductory paragraph, you write three paragraphs, each of which starts with a topic sentence and then includes evidence in support of that topic sentence, and then you write a conclusion paragraph. It is a useful framework for introducing students to essay writing, but it is also a framework that is best left behind as soon as it is understood.\n\nThe emphasis the assignments we have done in this class puts on different types of questions is similar — the goal is to make sure you can recognize the different types of questions and the purposes to which we put them. But your stakeholder report should not include a section called Exploratory Questions — rather the answers you generated in answering your Exploratory Questions should be reflected in how you’ve refined your problem statement, and the results of some of those analyses will likely make an appearance as tools for motivating the focus of your final analysis.","type":"content","url":"/writing-to-stakeholders#putting-the-pieces-together","position":11},{"hierarchy":{"lvl1":"Writing to Stakeholders","lvl3":"Justify Your Methods With Concrete Examples","lvl2":"Other Points To Bear In Mind"},"type":"lvl3","url":"/writing-to-stakeholders#justify-your-methods-with-concrete-examples","position":12},{"hierarchy":{"lvl1":"Writing to Stakeholders","lvl3":"Justify Your Methods With Concrete Examples","lvl2":"Other Points To Bear In Mind"},"content":"In discussing the methods you choose to use — such as a difference-in-difference design or matching — be sure to explain why you’re using the method in concrete terms that are relevant to the context in question, and without using technical language your stakeholder may not understand.\n\nIf you’re doing a difference-in-difference design (and not just a pre-post comparison), give examples of specific events that would cause problems for a simple pre-post analysis but that aren’t a problem for the difference-in-difference design you are using. Consider the opioid project from IDS 720. In that project, we estimated the effect of state-level changes in opioid prescription regulations in states like Florida and Texas on opioid shipments and overdoses. For that project, it was important to give an example — like the US federal government creating a national limit on the amount of opioids manufacturers were allowed to ship to individual clinics around the same time — that would cause incorrect inferences to be drawn from a simple pre-post comparison, but not from our design of choice (a difference-in-difference).\n\nIf you don’t include an example like this, it won’t be clear to the stakeholder why you feel fancy techniques are necessary. And if you can’t think of an example like this, then maybe you don’t need the fancy technique at all!","type":"content","url":"/writing-to-stakeholders#justify-your-methods-with-concrete-examples","position":13},{"hierarchy":{"lvl1":"Writing to Stakeholders","lvl3":"Data Cleaning","lvl2":"Other Points To Bear In Mind"},"type":"lvl3","url":"/writing-to-stakeholders#data-cleaning","position":14},{"hierarchy":{"lvl1":"Writing to Stakeholders","lvl3":"Data Cleaning","lvl2":"Other Points To Bear In Mind"},"content":"As noted above, a discussion of data cleaning and data wrangling does not belong in the body of your report. Data cleaning is where you probably spent most of your actual time, so it’s natural to want to demonstrate how much effort you put into a project by detailing all of the painstaking merging, string cleaning, harmonizing, etc. work you put into your project. All of that can go into an appendix, but including it in a report only makes it more likely that all of that effort will go to waste because reading about it will bore your stakeholder into setting down your report before you want them to.\n\nThere’s a famous saying in writing \n\nthat appears to have first appeared in a 1913 Cambridge Lecture by Arthur Quiller-Couch:\n\nIf you here require a practical rule of me, I will present you with this: ‘Whenever you feel an impulse to perpetrate a piece of exceptionally fine writing, obey it — whole-heartedly — and delete it before sending your manuscript to press. Murder your darlings.’\n\nWell, when it comes to data science, you don’t have to murder those darling paragraphs about all the messy data you had to clean up, but you should shove them in an appendix.\n\nOh, and please never use verbatim variable names in reports — they’re fine in appendices, but in the body of a report you should explain what you’re measuring in substantive terms someone without the data documentation can understand.","type":"content","url":"/writing-to-stakeholders#data-cleaning","position":15},{"hierarchy":{"lvl1":"Writing to Stakeholders","lvl3":"Discretion","lvl2":"Other Points To Bear In Mind"},"type":"lvl3","url":"/writing-to-stakeholders#discretion","position":16},{"hierarchy":{"lvl1":"Writing to Stakeholders","lvl3":"Discretion","lvl2":"Other Points To Bear In Mind"},"content":"The exception to the “don’t talk about your data manipulations” rule is that when you were forced to exercise substantial discretion in a way that may impact the internal or external validity of the analysis in a meaningful way (for example, selection of control states, or dropping certain time periods from the analysis you feel are too anomalous).\n\nEven in these situations, however, it is usually best to explain the logic behind the decisions in the body of the report (like in choosing what entities belong in your control group). However, a full discussion of these kinds of choices belong in an appendix.\n\nWhen you do exercise substantial discretion in an analysis (for example, deciding to include certain entities as controls while excluding others), it’s best practice to include some sensitivity analyses in your report by examining how your results do (or hopefully do not) change if you exercise discretion in slightly different ways. A sensitivity analysis, as a reminder, is where you make different discretionary choices (like choosing what entities to use as controls, or what variables you include in your regression), then re-run your analysis to see if the results change. The goal is to show that while, yes, you did have to exercise discretion in your analysis and data manipulations (we always do!), the choices you were forced to make aren’t driving your results and conclusions.\n\nIdeally, you can just reference that “results are similar when [example of doing something a little differently]” in the body of the report and include the sensitivity analysis in an appendix.\n\nIf different discretionary choices do lead to substantively different results, then you need to (a) try to characterize how fragile your results are (how much do they change in response to how small of a tweak in your choices), and/or (b) defend why the choices you made were correct, and the choices that give different results are not.","type":"content","url":"/writing-to-stakeholders#discretion","position":17},{"hierarchy":{"lvl1":"Writing to Stakeholders","lvl3":"Figures","lvl2":"Other Points To Bear In Mind"},"type":"lvl3","url":"/writing-to-stakeholders#figures","position":18},{"hierarchy":{"lvl1":"Writing to Stakeholders","lvl3":"Figures","lvl2":"Other Points To Bear In Mind"},"content":"Not everyone may agree with this approach, but my philosophy with plots is that they should be more or less freestanding — if a reader were to only look at the figures in a report, the labels on the axes, the titles, and any notes associated with the figure, they should be able to get a pretty good understanding what’s going on without having to go read the text in the report.\n\nFor example, this plot (which, yes, \n\nis from a paper on which I am a co-author, but all credit for the figure quality goes to my coauthor):","type":"content","url":"/writing-to-stakeholders#figures","position":19},{"hierarchy":{"lvl1":"Writing to Stakeholders","lvl3":"Limitations","lvl2":"Other Points To Bear In Mind"},"type":"lvl3","url":"/writing-to-stakeholders#limitations","position":20},{"hierarchy":{"lvl1":"Writing to Stakeholders","lvl3":"Limitations","lvl2":"Other Points To Bear In Mind"},"content":"There is a tendency for students to use their “Limitations” sections to, well... just try and cover their butts by throwing out anything they can think of about the paper that is imperfect. That’s ok in the classroom, but it’s not useful in the real world.\n\nThe point of a Limitations section isn’t to demonstrate your ability to identify any imperfections in the study; the point of a limitation section is to give your stakeholder a sense of how much confidence they should have in the results presented in the report from your professional perspective. Just because you had to make an assumption does not mean that the assumption constitutes a “limitation” of the study unless you have reason to think that the assumption is unlikely to be true (or is sufficiently untrue as to impact the results). Please only include things in your limitation section that you think really are substantive limitations! ## A Few Final Thoughts on Writing\n\nThis is not a class on writing, but communication is a central part of data science, and writing is one of our best tools we have for effective communication.    The earliest recorded use of the quote \"If I Had More Time, I Would Have Written a Shorter Letter\" comes from French mathematician and philosopher Blaise Pascal's work \"Lettres Provinciales\" in 1657.[1] Written in French the quote says, \"Je n’ai fait celle-ci plus longue que parce que je n’ai pas eu le loisir de la faire plus courte.\" This translates to \"I have made this longer than usual because I have not had time to make it shorter.\" ","type":"content","url":"/writing-to-stakeholders#limitations","position":21},{"hierarchy":{"lvl1":"Welcome to DS4Humans"},"type":"lvl1","url":"/landing-page","position":0},{"hierarchy":{"lvl1":"Welcome to DS4Humans"},"content":"This website is both the course site for the Duke Interdisciplinary Data Science Course Solving Problems with Data (IDS 701), as well as the beginning of what I hope will eventually become a stand-alone textbook by \n\nNick Eubank.\n\nIf you aren’t a Duke IDS 701 student and wish to explore the content of the course, I’d suggest starting with the \n\nIntroduction chapter here. You’re also welcome to browse the class schedule of topics covered in the class in the \n\nclass schedule link.\n\nIf you are a MIDS student, here’s a little more about the course.","type":"content","url":"/landing-page","position":1},{"hierarchy":{"lvl1":"Welcome to DS4Humans","lvl2":"Solving Problems with Data (IDS 701)"},"type":"lvl2","url":"/landing-page#solving-problems-with-data-ids-701","position":2},{"hierarchy":{"lvl1":"Welcome to DS4Humans","lvl2":"Solving Problems with Data (IDS 701)"},"content":"Few fields have shown as much promise to address the world’s problems as data science. At the same time, however, recent years have also made clear that today’s global challenges will not be met by simply “throwing data science at the problem” and hoping things will work out. Even in business, where many assume that Artificial Intelligence is a sure ticket to profits, \n\na major recent study found only > 11% of businesses that had piloted or employed Artificial Intelligence had reaped a sizeable return on their AI investments.\n\nHow, then, should a burgeoning data scientist approach this field full of such promise but also so many pitfalls? And why have so many data science endeavors failed to deliver on their promise?\n\nThe answer lies — at least in significant part — in a failure to provide students with a systematic approach to bringing the techniques learned in statistical modeling and machine learning courses to bear on real-world problems. Data science curricula usually begin with coding, statistics, and model evaluation techniques. All too often, however, that’s where they stop. But while the hardest part of data science classes is often fitting a model well or getting a good AUC score, the hardest part of being an effective professional data scientist is ensuring that the models being fit and the results being interpreted actually solve the problem that motivated you (or your stakeholder) in the first place.\n\nThis class is designed to fill this gap. Through exercises, case studies, and projects, students will develop a systematic understanding of how to approach and manage data science projects from conception through delivery and adoption. It will provide a unified perspective on how the perspectives and tools learned in other courses complement one another, and when different approaches to data science are most appropriate.\n\nIn addition, this course will also provide an in-depth introduction into causal inference — the practice of answering causal questions. Given the interests of MIDS students, this introduction will focus heavily on experiments and A/B testing, but will also cover the use of observational data (data that did not come from an experiment that employed random assignment to treatment) for answering causal questions.","type":"content","url":"/landing-page#solving-problems-with-data-ids-701","position":3},{"hierarchy":{"lvl1":"Welcome to DS4Humans","lvl3":"How to Succeed in this Class","lvl2":"Solving Problems with Data (IDS 701)"},"type":"lvl3","url":"/landing-page#how-to-succeed-in-this-class","position":4},{"hierarchy":{"lvl1":"Welcome to DS4Humans","lvl3":"How to Succeed in this Class","lvl2":"Solving Problems with Data (IDS 701)"},"content":"In Duke course reviews, students are asked, “What would you like to say about this course to a student who is considering taking this course in the future?”\n\nBy far the most consistent thing past students say they would like to tell a student considering taking it in the future is to do the readings and take them seriously.\n\nThere is a tendency among data science students — especially those from a STEM background — to assume that readings that don’t have a lot of math aren’t “serious,” and consequently don’t require substantial focus. That’s a mistake. This course is about the critical reasoning required to make the leap from the relatively clean math of statistics and machine learning to the messiness of real world problems. To help you learn how to do so, the readings are full of examples, ways to think about problems, and problem-solving frameworks to help you cross that wobbly bridge from the clean world of problem sets to the real, under- or mis-defined problems you will face when you enter the work force. But with this type of material, what you get out of it depends on what you put into it, and unlike with a theorem — which you either follow or you don’t — thinking critically happens on many levels. So while it’s easy to skim a reading and — because you weren’t confused by any greek notation — assume you internalized it, succeeding in this class requires actively wrestling with the material, not just letting your eyes glide over it.\n\nIn other words, take the readings for this course just as seriously as the exercises. There is as much learning to be done by thinking deeply about the readings as there is to be gained from doing the exercises, a fact that is also reflected in how the course is graded (individual or two-person exercises make up 20% of your grade, while reading comprehension quizzes and the midterm count for 20% each).","type":"content","url":"/landing-page#how-to-succeed-in-this-class","position":5},{"hierarchy":{"lvl1":"Welcome to DS4Humans","lvl3":"Big Ideas","lvl2":"Solving Problems with Data (IDS 701)"},"type":"lvl3","url":"/landing-page#big-ideas","position":6},{"hierarchy":{"lvl1":"Welcome to DS4Humans","lvl3":"Big Ideas","lvl2":"Solving Problems with Data (IDS 701)"},"content":"This course is organized around three big ideas:\n\nData science is about solving problems. All too often, data scientists get lost in the technical details of models and lose sight of the bigger picture. Data science is not about maximizing accuracy or AUC scores — it’s about using data and quantitative methods to solve problems, and at the end of the day the only “metric” that matters is whether your work has solved the problem you set out to address.\n\nData scientists solve problems by answering questions, and the question you are asking determines what tool is appropriate. At their core, all data science tools are tools for answering questions, whether you realize it or not. Learning to recognize how data scientists use questions to solve problems — and exactly what questions are being answered by the tools you use every day — is key to navigating the ambiguity of real-world problem solving.\n\nReasoning rigorously about uncertainty and errors is what differentiates good data scientists from great data scientists. Data science isn’t just about minimizing classification errors and uncertainty — it’s also about deciding how unavoidable errors should be distributed, and how to weigh the risks and trade-offs inherent in probabilistic decision-making rigorously and in a manner that takes into account the problem you are trying to solve.","type":"content","url":"/landing-page#big-ideas","position":7},{"hierarchy":{"lvl1":"Welcome to DS4Humans","lvl3":"Pre-Requisites for Non-MIDS Students","lvl2":"Solving Problems with Data (IDS 701)"},"type":"lvl3","url":"/landing-page#pre-requisites-for-non-mids-students","position":8},{"hierarchy":{"lvl1":"Welcome to DS4Humans","lvl3":"Pre-Requisites for Non-MIDS Students","lvl2":"Solving Problems with Data (IDS 701)"},"content":"This course is primarily designed for students in the Duke Masters in Interdisciplinary Data Science (MIDS) program, but students from other programs are more than welcome if they have the appropriate pre-requisite training. Data Science is a fundamentally interdisciplinary field, so the more perspectives we have represented in the classroom the better!\n\nThis course will assume that enrolled students have a good grasp of inferential statistics and statistical modeling (e.g. a course in linear models), though no prior experience with causal inference is expected. In addition, MIDS students will be taking a concurrent course in applied machine learning, so incoming students will also be expected to have some basic experience with machine learning or be concurrently enrolled in an applied machine learning course.\n\nThis course will also assume students are comfortable manipulating real-world data in Python. The substantive content of this course is language-independent, but because students will be required to work on their projects in teams, comfort with Python will be required to facilitate collaboration (MIDS students are, generally, “bilingual” in R and Python, but have a strong preference for Python, and it’s hard to write problem sets to accommodate multiple languages).\n\nFinally, students will also be expected to be comfortable collaborating using git and github. If you meet the other requirements for this course but are not familiar with git and github, this is a skill you should be able to pick up on your own in advance of the course without too much difficulty. You can read more about \n\ngit and github here. The \n\nDuke Center for Data and Visualization Science also hosts git and github workshops if you are a Duke student.","type":"content","url":"/landing-page#pre-requisites-for-non-mids-students","position":9},{"hierarchy":{"lvl1":"Welcome to DS4Humans","lvl3":"Course Schedule","lvl2":"Solving Problems with Data (IDS 701)"},"type":"lvl3","url":"/landing-page#course-schedule","position":10},{"hierarchy":{"lvl1":"Welcome to DS4Humans","lvl3":"Course Schedule","lvl2":"Solving Problems with Data (IDS 701)"},"content":"You can find the \n\ncourse schedule here. Note that our schedule is subject to change, but this should give you a good sense of the material we will cover.","type":"content","url":"/landing-page#course-schedule","position":11},{"hierarchy":{"lvl1":"Welcome to DS4Humans","lvl3":"Syllabus","lvl2":"Solving Problems with Data (IDS 701)"},"type":"lvl3","url":"/landing-page#syllabus","position":12},{"hierarchy":{"lvl1":"Welcome to DS4Humans","lvl3":"Syllabus","lvl2":"Solving Problems with Data (IDS 701)"},"content":"To learn more about the course, please \n\nread the course syllabus here..","type":"content","url":"/landing-page#syllabus","position":13}]}