# Interpretability and Passive Prediction

It is my aim, at some point soon, to have my own chapter here. But for now, two external readings that are hard to beat! 

- ["Stop Using Black Boxes"](https://arxiv.org/abs/1811.10154) by Cynthia Rudin. Who is Cynthia Rudin? [A truly amazing scholar.](https://biostat.duke.edu/news/faculty-cynthia-rudin-wins-1-million-artificial-intelligence-prize-new-nobel) You can skip the last section on "Algorithmic Challenges in Interpretable ML" if you want.
- Using Black Boxes requires [trusting the data too](https://www.nytimes.com/2017/06/13/opinion/how-computers-are-harming-criminal-justice.html?unlocked_article_code=1.pk4.d6Ix.JKuN5_dxK_sS&smid=url-share).

<!-- ## Performance Differential Is (Often) A Myth

There's just only so much signal in the data.

## Regulatory Compliance

## Trusting Model == Trusting Data

## Ethical Transparency

## Ease of Adoption

(Cite study)

## No Magic, Not Undue Deference

- Most models internal, where IP-black-box doesn't matter
- Handoff and implementation easier
- Ethical review. -->
