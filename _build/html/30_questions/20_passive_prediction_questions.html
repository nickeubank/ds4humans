
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Passive-Prediction Questions &#8212; Data Science for Humans</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="../_static/logo.jpg"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Causal Questions: The Theory" href="30_causal_questions_theory.html" />
    <link rel="prev" title="Exploratory Questions" href="10_exploratory_questions.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.jpg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Data Science for Humans</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../landing_page.html">
                    Welcome to Data Science for Humans
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../10_introduction/10_our_approach.html">
   Solving Problems with Data Science
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../10_introduction/20_data_science_in_historical_context.html">
   What
   <em>
    is
   </em>
   Data Science: An Historical Perspective
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Types of Questions
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="00_solving_the_right_problem.html">
   Solving the Right Problem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="05_descriptive_v_proscriptive.html">
   Descriptive versus Proscriptive Questions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="10_exploratory_questions.html">
   Exploratory Questions
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Passive-Prediction Questions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="30_causal_questions_theory.html">
   Causal Questions: The Theory
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="40_causal_questions_application.html">
   Causal Questions in Practice
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Data Science in Practice
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../40_in_practice/00_backwards_design.html">
   Backwards Design
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../40_in_practice/20_from_data_to_decisions.html">
   Making Decisions Using Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../40_in_practice/25_writing_to_stakeholders.html">
   Writing Data Science Report for Non-Technical Audiences
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Advanced Topics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../40_advanced_topics/30_interpretability.html">
   Interpretable Models
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/nickeubank/ds4humans"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/nickeubank/ds4humans/issues/new?title=Issue%20on%20page%20%2F30_questions/20_passive_prediction_questions.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/30_questions/20_passive_prediction_questions.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#flavors-of-passive-prediction-questions">
   Flavors of Passive-Prediction Questions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#differentiating-between-exploratory-and-passive-prediction-questions">
   Differentiating Between Exploratory and Passive-Prediction Questions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#when-are-our-predictions-valid">
   When Are Our Predictions Valid?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#internal-validity">
     Internal Validity
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#external-validity">
     External Validity
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Passive-Prediction Questions</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#flavors-of-passive-prediction-questions">
   Flavors of Passive-Prediction Questions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#differentiating-between-exploratory-and-passive-prediction-questions">
   Differentiating Between Exploratory and Passive-Prediction Questions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#when-are-our-predictions-valid">
   When Are Our Predictions Valid?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#internal-validity">
     Internal Validity
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#external-validity">
     External Validity
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="passive-prediction-questions">
<h1>Passive-Prediction Questions<a class="headerlink" href="#passive-prediction-questions" title="Permalink to this headline">#</a></h1>
<p>When most people hear the term “machine learning,” what they think of is the ability of computers to answer Passive-Prediction Questions: “which patients are likely to experience complications from surgery if we don’t do anything?”, “which people applying for life insurance are healthy enough we should issue them a policy?”, or “which job applicants would make good employees (and thus, which job applicants should we interview)?” And indeed, the ability of data scientists to answer Passive-Prediction Questions is one of our most useful skills.</p>
<p>However, answering this type of question is also one of the easiest ways to get in trouble as a data scientist. Why? Just as you can always calculate a summary statistic or get a result from an unsupervised machine learning model when trying to answer an Exploratory Question, you can also always get predicted values from a statistical model. But with Passive-Prediction Questions—<em>unlike</em> with Exploratory Questions—you can’t fully check the validity of your answer to a Passive-Prediction Question with data you currently have. That’s because, <em>by definition</em>, the reason you are trying to answer a Passive-Prediction Question is that you want to predict something that you don’t currently know!</p>
<section id="flavors-of-passive-prediction-questions">
<h2>Flavors of Passive-Prediction Questions<a class="headerlink" href="#flavors-of-passive-prediction-questions" title="Permalink to this headline">#</a></h2>
<p>There are two flavors of Passive-Prediction Questions:</p>
<ul class="simple">
<li><p>predicting something that has yet to occur (“which patients going in for surgery are likely, in the future, to experience complications?”), and</p></li>
<li><p>predicting something that <em>could</em> occur but actually won’t (“if a radiologist had looked at this mammogram, would they conclude the patient had cancer?”).</p></li>
</ul>
<p>The first category of passive prediction—predicting something that has yet to occur—is the most intuitive, and is the type of passive prediction that accords best with the normal meaning of the term “predict.” But the second favor of passive prediction—in which we try and predict what someone <em>would</em> do—is also very important, as it underlies efforts at automation. Spam detection, image classification, autocomplete, and self-driving cars are all examples of situations where we train a model by showing it examples of how a person <em>would</em> do something, so the model can predict what a person would do when faced with new data and emulate that behavior itself.</p>
<p>And just as there are two flavors of passive-prediction, so too are there two corresponding use cases for answering Passive-Prediction Questions:</p>
<ul class="simple">
<li><p>Identifying individual entities for follow-up, and</p></li>
<li><p>Automating data classification to make hard-to-work-with data (images, medical scans, text) simpler</p></li>
</ul>
</section>
<section id="differentiating-between-exploratory-and-passive-prediction-questions">
<h2>Differentiating Between Exploratory and Passive-Prediction Questions<a class="headerlink" href="#differentiating-between-exploratory-and-passive-prediction-questions" title="Permalink to this headline">#</a></h2>
<p>If you have not felt a little confused about the distinction between Exploratory and Passive-Prediction Questions previously, there’s a good chance you find yourself struggling with that issue here, and for understandable reasons.</p>
<p>In many cases, one can easily imagine how the same analysis might constitute an answer to <em>either</em> an Exploratory or Passive-Prediction Question. For example, predicting which patients are likely to experience complications from surgery using a logistic regression could constitute the answer a Passive-Prediction Question, but it could also answer Exploratory Questions like “what hospitals have the highest surgery complication rates?” or “what type of surgeries have the highest complication rates?”</p>
<p>The confusion lies in the fact that the distinction between these types of questions isn’t related to the statistical machinery you might use to answer the question, but rather what we are trying to accomplish, and thus how we might evaluate the success of a given statistical or machine learning model.</p>
<p>With Passive-Prediction Questions, our interest is in the values that get spit out of a model for each entity in the data. When answering a Passive-Prediction Question, the <em>only</em> thing we care about is the quality of those predictions, and so we evaluate the success of a model that aims to answer a Passive-Prediction Question by the quality of those predictions (using metrics like AIC, AUC, R-Squared, Accuracy, Precision, Recall, etc.). Thus, when using a logistic regression to answer a Passive-Prediction Question, we don’t actually care about what factors are being used to make our predictions, just that they improve the predictions. Our interest is only the quality of our predicted values, and a good model is one that explains a substantial portion of the variation in our outcome.</p>
<p>With Exploratory Questions, our interest is in improving our understanding of the problem space, not in making precise predictions for each entity in our data. Thus, in the example of a logistic regression, our interest is in the factors on the “right-hand side” of our logistic regression and how they help us understand what shapes outcomes, not the exact accuracy of our predictions. A good model, in other words, doesn’t actually have to explain a large share of variation at the level of individual entities, but it does have to help us understand our problem space.</p>
<p>For example, a model that looked at the relationship between individuals’ salaries and their age, education, and where they live might tell us a <em>lot</em> about the importance of a college degree to earnings (which we could see by the large and statistically significant coefficient on having a college degree), even if it only explains a small amount of overall variation in salaries (e.g., the R-Squared might only be 0.2).</p>
<p>This distinction also has important implications when working with more opaque supervised machine learning techniques, like deep learning, random forests, or SVMs. These techniques are often referred to as “black boxes” because exactly how different impute factors relate to the predictions that the model makes is impossible to understand (in other words, it’s like the input data is going into a dark box we can’t see into, and then predictions are magically popping out the other side). These models can be very useful for answering Passive-Prediction Questions, as they can accommodate very unusual, non-linear relationships between input factors and predicted values, but because these relationships are opaque to us, the data scientist, they don’t really help us understand the problem space.</p>
</section>
<section id="when-are-our-predictions-valid">
<h2>When Are Our Predictions Valid?<a class="headerlink" href="#when-are-our-predictions-valid" title="Permalink to this headline">#</a></h2>
<p>Because passive-prediction is fundamentally about making predictions about things that are not-yet-seen, making predictions is one of the more precarious things a data scientist can do. But that doesn’t mean that we are helpless when it comes to determining how confident we should be in our predictions, and when and where we think our predictions will be reliable. In particular, as data scientists, we have a great many tools for evaluating how well our model fits the data we <em>already have</em> (a concept known as <em>internal validity</em>), and ways of thinking critically about the contexts in which using a given model to make predictions are appropriate (a concept known as <em>external validity</em>).</p>
<section id="internal-validity">
<h3>Internal Validity<a class="headerlink" href="#internal-validity" title="Permalink to this headline">#</a></h3>
<p>Of all the places where data science is fragmented, none is more evident than in how data scientists evaluate how effectively we think a model is representing our data.</p>
<p>The first data science perspective on evaluating the internal validity of a model comes from the field of statistics. Statisticians have approached evaluating model fit with, unsurprisingly, methods based on the idea of random sampling and the properties of statistical distributions. They make assumptions about the distributions underlying data and use those to derive theoretically-motivated metrics. That’s the origin of statistics like Akaike Information Criterion (AIC), Bayesian Information Criterion (BIC), as well as the emphasis on the validity of the standard errors assigned to factors on the right-hand side of the regression.</p>
<p>When computer scientists were first developing their own machine learning techniques… I’m editorializing a little here, but I think it’s safe to say that initially they either didn’t <em>know about</em> a lot about these metrics, or they thought that they could do a better job investing their own. So they developed the “split-train-test” approach to model evaluation: they split their data into two parts, train their model on part of the data, then test how well the model is able to predict the (known) outcomes in the test dataset.</p>
<p>Of course, over time these two fields have largely converged in adopting one another’s methods, and some—like cross-validation—live comfortably in the middle. But if you’re ever wondering why, when you get to a machine learning class, it seems like everything you learned in stats has been abandoned (or end up in a stats class and have the opposite experience), it’s largely an artifact of parallel development of methods of model evaluation in computer science and statistics departments.</p>
</section>
<section id="external-validity">
<h3>External Validity<a class="headerlink" href="#external-validity" title="Permalink to this headline">#</a></h3>
<p>Where <em>internal validity</em> is a measure of how well a model captures the meaningful variation in the data we already have, <em>external validity</em> is a measure of how well we think that our model is likely to perform when faced with new data.</p>
<p>The external validity of a model, it is important to emphasize, is specific to the context in which a model is being used. A model will generally have very <em>high</em> external validity when used to answer Passive-Prediction Questions in a setting that is very similar to the setting from which the data used to train the model was collected, but <em>low</em> external validity when applied in a very different setting.</p>
<p>There are a range of factors that can determine external validity, such as whether a model is being used to answer Passive-Prediction Questions about:</p>
<ul class="simple">
<li><p>the <em>same population</em> from which the training data was drawn. The patterns in data from one country will often differ from patterns in data from another country, for example.</p></li>
<li><p>the <em>same time period</em> from which the training data was drawn. Consumer behavior may vary across seasons, and many patterns in data change over longer timespans.</p></li>
<li><p>the <em>same parameter ranges</em> as those in the training data. Statistical and machine learning models are designed to fit the data they can see as well as possible. However, while nearly all models will generate predictions about outcomes when given inputs that weren’t in the data used to fit a model because they weren’t trained with access to data of this type, their guesses are unlikely to be particularly meaningful.</p></li>
</ul>
<!-- Need a figure we make ourselves -->
<p>To illustrate, consider the two models in the figure below (<a class="reference external" href="https://ece.uwaterloo.ca/~dwharder/NumericalAnalysis/06LeastSquares/extrapolation/complete.html">source</a>)—one a linear fit, and one a higher-order polynomial. Both model the data similarly <em>in the range for which data is available</em> but make very different predictions at values of <code class="docutils literal notranslate"><span class="pre">x</span></code> below 0 or above 2.</p>
<p><img alt="example of two models that look similar over ranges with data but extrapolate very differently outside that range" src="../_images/extrapolation.gif" /></p>
<!-- ## Manipulation and External Validity

Models may exhibit low external validity when applied in contexts that are obviously very different from the data on which it was trained: in a different country, in a different industry, in a different climate, or during a different time of year. But they can sometimes also fail to perform well in situations where everything *looks* similar, but the processes generating the data have changed.

Suppose, for example, we wanted to go back to our example of wanting to reduce complications from surgery. So we build a model that allows us to predict, for each patient going into surgery, the likelihood they will eventually experience complications. -->
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./30_questions"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="10_exploratory_questions.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Exploratory Questions</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="30_causal_questions_theory.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Causal Questions: The Theory</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Josh Clinton and Nick Eubank<br/>
  
      &copy; Copyright 2023.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>