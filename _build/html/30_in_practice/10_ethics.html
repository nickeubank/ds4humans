
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Ethics in Data Science &#8212; Data Science for Humans</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Making Decisions Using Data" href="20_from_data_to_decisions.html" />
    <link rel="prev" title="Causal Questions" href="../20_questions/30_causal_questions.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Data Science for Humans</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../landing_page.html">
   Welcome to Data Science for Humans
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../00_introduction.html">
   Introduction to Data Science for Humans
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Working with Data
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../10_programming/welcome_to_r.html">
   We’re gonna learn R!
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Types of Questions
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../20_questions/00_from_problems_to_questions.html">
   From Problems to Questions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../20_questions/10_exploratory_questions.html">
   Exploratory Questions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../20_questions/20_passive_prediction_questions.html">
   Classification Questions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../20_questions/30_causal_questions.html">
   Causal Questions
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Data Science in Practice
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Ethics in Data Science
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="20_from_data_to_decisions.html">
   Making Decisions Using Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="30_interpretability.html">
   Interpretable Models
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/30_in_practice/10_ethics.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/nickeubank/ds4humans"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/nickeubank/ds4humans/issues/new?title=Issue%20on%20page%20%2F30_in_practice/10_ethics.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Ethics in Data Science</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="ethics-in-data-science">
<h1>Ethics in Data Science<a class="headerlink" href="#ethics-in-data-science" title="Permalink to this headline">¶</a></h1>
<p>In recent years, for example, we’ve seen near endless examples of data science systems not just failing to solve societal inequities, but instead reinforcing them. A hiring algorithm at Amazon was recently scrapped after it was discovered that it systematically <a class="reference external" href="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G">discriminated against female job candidates</a>. An algorithm for prioritizing kidney transplants was found to make it less likely that <a class="reference external" href="https://www.wired.com/story/how-algorithm-blocked-kidney-transplants-black-patients/">Black patients would receive kidney transplants than White patients</a>. Another medical algorithm recommended less preventative care for <a class="reference external" href="https://www.washingtonpost.com/health/2019/10/24/racial-bias-medical-algorithm-favors-white-patients-over-sicker-black-patients/">sick Black patients than White patients</a>. And a popular “risk assessment” algorithm used by judges around the country to make decisions about whether defendants should be released pending trial, held on bond, or held without bonds—as well as how convicted criminals should be sentenced—<a class="reference external" href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">was found to make more mistakes for Black defendants than White defendants, systematically reporting to judges that they were more likely to re-offend than they actually were according to subsequent analyses.</a></p>
<p>Similarly, in the political sphere <a class="reference external" href="https://www.wsj.com/articles/facebook-knows-it-encourages-division-top-executives-nixed-solutions-11590507499">Facebook’s own research</a> has shown that its algorithms polarize users and drive division, a fact that internal documents show its own executives chose to largely ignore.<a class="footnote-reference brackets" href="#facebook-engagement" id="id1">1</a> Facebook’s internal research also found that “64% of all extremist group joins are due to our recommendation tools” like “Groups You Should Join” and the Discover tools.</p>
<p>While much of these problems are the result of a lack of carelessness or a lack of critical thought on the part of the data scientists developing these algorithms, in other cases problems have arisen because of a lack of critical evaluation of data science tools by their <em>users</em>. In 2020, for example, it was discovered that company that provided doctors with (suspiciously free) software designed to provide “clinical decision support” (advice on tests that might be advisable or drugs that might be prescribed for patients based on their medical records) was taking kickbacks from an opioid producing pharmaceutical company to ensure opioids remained a suggested treatment for patients, despite the strong recommendation of groups like the American Medical Association to reduce opioid use in light of the opioid overdose epidemic the US.</p>
<ul class="simple">
<li><p>Motivation: piles of case studies. See list under “Prediction: ML Bias” (March 29 at the moment) here
Two types of “unethical algorithms: biased performance and biased predictions.</p></li>
<li><p>Biased Performance:</p>
<ul>
<li><p>Super ethically straightforward—works for one group (e.g., White people) but not another (e.g., Black people). “Works” can be defined in terms of whatever performance metrics we care about (accuracy, recall, etc.), but the point is that the error rate is different across groups (e.g., the zoom background blurring algorithm that can’t see Black faces, so just blurs their screens).</p></li>
</ul>
</li>
<li><p>Biased Predictions:</p>
<ul>
<li><p>Now the much more complicated one: suppose that your model gives different predictions for people from different group (Black/White), but that’s because that’s what is in the data. Is that ok?</p></li>
<li><p>If the data is biased: probably not! E.g. Amazon (I think this is what happened) tried to make algorithm that would look at a resume and predict how good an employee that person would be if hired. So it used resumes to train a dataset using managerial employee ratings as labels. But… managers were biased. That was the problem. So algorithm just learned to recapitulate the misogynistic rating of managers. Gotta make sure you know what question is being answered by your algorithm…</p></li>
<li><p>If the data is NOT biased: depends! Suppose that a model to predict success of a kidney transplant designed to maximize the efficiency of kidney transplant allocations systematically scores black recipients as being less likely to still have their transplanted kidneys and be healthy after ten years… but it’s not an anomaly of the model, it’s a real fact in the world. Is it OK to down-rank Black recipients? (not a contrived example). In that context, providing black recipients with less access to kidneys seems deeply problematic, even if rating them higher will result in less “years of healthy kidneys” after transplant. Here it seems like racially disparate outcomes are unethical. But what if we want to allocate HIV preventative interventions? Black Americans have a much higher incidence of HIV than any other ethnic group in the US—a model that suggests targeting their communities with more interventions would seem appropriate, on a model that doesn’t recognize that HIV rates in the Black community are more than 2x the next closest group seems like it wouldn’t be very helpful.</p></li>
<li><p>Chicago crime example: <a class="reference external" href="https://www.theverge.com/c/22444020/chicago-pd-predictive-policing-heat-list">https://www.theverge.com/c/22444020/chicago-pd-predictive-policing-heat-list</a></p></li>
<li><p><a class="reference external" href="https://filtermag.org/chicago-crime-prediction/">https://filtermag.org/chicago-crime-prediction/</a></p></li>
<li><p><a class="reference external" href="https://medium.com/analytics-vidhya/predicting-arrests-looking-into-chicagos-crime-through-machine-learning-78697cc930b9">https://medium.com/analytics-vidhya/predicting-arrests-looking-into-chicagos-crime-through-machine-learning-78697cc930b9</a></p></li>
</ul>
</li>
</ul>
<p>But… it’s data? How do our values come into play!
Like… checking performance of algorithms for different racial/ethnic groups.
Or looking for racial/gender heterogeneity during descriptive analyses.</p>
<hr class="footnotes docutils" />
<dl class="footnote brackets">
<dt class="label" id="facebook-engagement"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>This research found the key driver of polarization was Facebook’s decision to design recommendations algorithms that prioritized “user engagement” (clicks, shares, comments) which resulted in promoting partisan, polarizing, sensationalist, or extreme content.</p>
</dd>
</dl>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./30_in_practice"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="../20_questions/30_causal_questions.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Causal Questions</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="20_from_data_to_decisions.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Making Decisions Using Data</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Josh Clinton and Nick Eubank<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>