%% Generated by Sphinx.
\def\sphinxdocclass{jupyterBook}
\documentclass[letterpaper,10pt,english]{jupyterBook}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
\ifdefined\pdfimageresolution
    \pdfimageresolution= \numexpr \dimexpr1in\relax/\sphinxpxdimen\relax
\fi
%% let collapsible pdf bookmarks panel have high depth per default
\PassOptionsToPackage{bookmarksdepth=5}{hyperref}
%% turn off hyperref patch of \index as sphinx.xdy xindy module takes care of
%% suitable \hyperpage mark-up, working around hyperref-xindy incompatibility
\PassOptionsToPackage{hyperindex=false}{hyperref}
%% memoir class requires extra handling
\makeatletter\@ifclassloaded{memoir}
{\ifdefined\memhyperindexfalse\memhyperindexfalse\fi}{}\makeatother

\PassOptionsToPackage{warn}{textcomp}

\catcode`^^^^00a0\active\protected\def^^^^00a0{\leavevmode\nobreak\ }
\usepackage{cmap}
\usepackage{fontspec}
\defaultfontfeatures[\rmfamily,\sffamily,\ttfamily]{}
\usepackage{amsmath,amssymb,amstext}
\usepackage{polyglossia}
\setmainlanguage{english}



\setmainfont{FreeSerif}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Italic,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldItalic
]
\setsansfont{FreeSans}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Oblique,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldOblique,
]
\setmonofont{FreeMono}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Oblique,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldOblique,
]



\usepackage[Bjarne]{fncychap}
\usepackage[,numfigreset=1,mathnumfig]{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}


\usepackage{sphinxmessages}



        % Start of preamble defined in sphinx-jupyterbook-latex %
         \usepackage[Latin,Greek]{ucharclasses}
        \usepackage{unicode-math}
        % fixing title of the toc
        \addto\captionsenglish{\renewcommand{\contentsname}{Contents}}
        \hypersetup{
            pdfencoding=auto,
            psdextra
        }
        % End of preamble defined in sphinx-jupyterbook-latex %
        

\title{Solving Problems With Data}
\date{Jan 22, 2024}
\release{}
\author{Nick Eubank}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{landing_page::doc}}


\sphinxAtStartPar
\sphinxstyleemphasis{This is the beginning of a textbook by \sphinxhref{https://www.nickeubank.com}{Nick Eubank}.}

\sphinxAtStartPar
Few fields have shown as much promise to address the world’s problems as data science. At the same time, however, recent years have also made clear that today’s global challenges will not be met by simply “throwing data science at the problem” and hoping things will work out. Even in business, where many assume that Artificial Intelligence is a sure ticket to profits, \sphinxhref{https://www.wired.com/story/companies-rushing-use-ai-few-see-payoff/}{a major recent study found only > 11\%} of businesses that had piloted or employed Artificial Intelligence had reaped a sizeable return on their AI investments.

\sphinxAtStartPar
How, then, should a burgeoning data scientist approach this field full of such promise but also so many pitfalls? And why have so many data science endeavors failed to deliver on their promise?

\sphinxAtStartPar
The answer lies — at least in significant part — in a failure to provide students with a systematic approach to bringing the techniques learned in statistical modeling and machine learning courses to bear on real\sphinxhyphen{}world problems. Data science curricula usually begin with coding, statistics, and model evaluation techniques. All too often, however, that’s where they stop. But while the hardest part of data science \sphinxstyleemphasis{classes} is often fitting a model well or getting a good AUC score, the hardest part of being an effective \sphinxstyleemphasis{professional} data scientist is ensuring that the models being fit and the results being interpreted actually solve the problem that motivated you (or your stakeholder) in the first place.

\sphinxAtStartPar
This book is designed to fill this gap between neatly curated classroom exercises and the messiness of the real world.  It will provide a unified perspective on how the perspectives and statistical tools learned in other courses complement one another, and \sphinxstyleemphasis{when} different approaches to data science are most appropriate to use. More importantly, though, it provides a framework for understanding your goals as a data scientist, and how to achieve them.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Is this book for me?

\sphinxAtStartPar
You’d be forgiven, serious data scientist, for flipping through this book and finding yourself thinking “Hmmm… I don’t see many equations in this book. Is this really for me, the serious data scientist?” But worry not.

\sphinxAtStartPar
This book may not be the \sphinxstyleemphasis{most} helpful resource when it comes to preparing for technical interviews (though the detailed discussion of Causal Questions in later chapters likely would be). And your impression is correct — this book contains more case studies than proofs. But don’t be fooled — this is not a “light and fuffy” book that waves vaguely in the direction of statistical concepts so you can discuss them at cocktail parties.

\sphinxAtStartPar
This book \sphinxstyleemphasis{takes as given} that you’ve already been introduced to statistical inference and machine learning, and you feel comfortable with the core concepts of implementing and evaluating stats and ML models (evaluating a model’s AUC, cross\sphinxhyphen{}validation, hypothesis testing, train\sphinxhyphen{}test sample splits, etc.). Those concepts will be treated as “assumed knowledge.”

\sphinxAtStartPar
This book is about what comes \sphinxstyleemphasis{before} and \sphinxstyleemphasis{after} you faithfully fit a model to a dataset in a robust manner. By \sphinxstyleemphasis{before}, I mean that it covers how you decide what questions to answer, what data to collect, and what models to consider using. And by \sphinxstyleemphasis{after}, I mean we will discuss how one evaluates whether a result is likely to generalize, whether a model is safe to deploy, and where to go from there.

\sphinxAtStartPar
It is, in other words, about everything you need to know \sphinxstyleemphasis{beyond} the purely technical. And while that may be the part of data science that doesn’t feel as exciting, the ability to reason about problems and think critically about the appropriate use of data science tools is what will get you promoted after you ace that technical interview. And that same ability to think critically is also what will prevent you from being replaced by the next generation of auto\sphinxhyphen{}ML tools or Large Language Models.
\end{sphinxadmonition}

\sphinxstepscope


\part{Part}

\sphinxstepscope


\chapter{Solving Problems with Data}
\label{\detokenize{10_introduction/10_our_approach:solving-problems-with-data}}\label{\detokenize{10_introduction/10_our_approach::doc}}

\section{Introduction}
\label{\detokenize{10_introduction/10_our_approach:introduction}}
\sphinxAtStartPar
Few fields have shown as much promise to address the world’s problems as data science. Today, data science is being used to develop climate models to improve our understanding of global climate change and mitigate its effects. It is being used in medicine to speed drug discovery, improve the quality of x\sphinxhyphen{}rays and MRIs, and to ensure that patients receive appropriate medical care. Data science is used in courtrooms to fight for fair elections and electoral maps, and by data journalists to document and communicate to readers the injustices prevalent in our criminal justice system and issues in policing. Data science also enables new technologies that have huge potential to improve our lives. Autonomous drones are delivering blood and medical supplies to rural health clinics from Rwanda to \sphinxhref{https://www.theverge.com/2020/5/27/21270351/zipline-drones-novant-health-medical-center-hospital-supplies-ppe/}{North Carolina}, and driver\sphinxhyphen{}aid features continue to make progress in reducing the over 30,000 traffic deaths and millions of injuries that occur in the US alone every year. Nearly no facet of business has gone untouched by the recent revolution in data analytics, from song and movie recommendation engines on Netflix, Spotify, and Apple’s App Store to the use of personalized, targeted advertisements used to ensure businesses can make the most of their advertising revenue.

\sphinxAtStartPar
At the same time, however, recent years have also made clear that today’s global challenges will not be met by simply “throwing data science at the problem” and hoping things will work out. Even in business, where many assume that Artificial Intelligence is a sure ticket to profits, a major recent study found \sphinxhref{https://www.wired.com/story/companies-rushing-use-ai-few-see-payoff/}{only 11\% of businesses that had piloted or employed Artificial Intelligence had reaped a sizeable return on their AI investments.} In recent years we’ve also seen near endless examples of data science tools reinforcing racial and gender inequities, like algorithms \sphinxhref{https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G}{discriminating against female job candidates at Amazon}, prioritizing White patients over Black patients \sphinxhref{https://www.wired.com/story/how-algorithm-blocked-kidney-transplants-black-patients/}{for kidney transplants} and \sphinxhref{https://www.washingtonpost.com/health/2019/10/24/racial-bias-medical-algorithm-favors-white-patients-over-sicker-black-patients/}{preventative care}, and being more likely to \sphinxhref{https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing}{incorrectly identify Black defendants than White defendants as being a “danger to society” when providing risk assessments to judges deciding on pre\sphinxhyphen{}trial release, bail and sentencing}. And even companies like Meta’s own research have shown its algorithms drive political polarization and division among users, and push users into extremist groups.%
\begin{footnote}[1]\sphinxAtStartFootnote
\sphinxhref{https://www.wsj.com/articles/facebook-knows-it-encourages-division-top-executives-nixed-solutions-11590507499}{Recent reporting by the Wall Street Journal} has shown that Facebook’s own research has confirmed what many outside experts have long argued: the way its recommendation engines prioritize content that results in “user engagement” (clicks, shares, comments) ends up promoting partisan, polarizing, sensationalist, or extreme content. In addition, their own research has also shown that group recommendations are contributing to extremism. According to one internal presentation, “64\% of all extremist group joins are due to our recommendation tools” like \sphinxstyleemphasis{Groups You Should Join} and other discovery tools.
%
\end{footnote}

\sphinxAtStartPar
How, then, should a burgeoning data scientist approach this field full of such promise but also so many pitfalls? And why have so many data science endeavors failed to deliver on their promise?

\sphinxAtStartPar
The answer lies — in significant part — in a failure to provide students with a systematic approach to bringing the techniques learned in statistical modeling and machine learning courses to bear on real\sphinxhyphen{}world problems. Data science curricula usually begin with coding, statistics, and model evaluation techniques. All too often, however, that’s where they stop. But while the hardest part of data science \sphinxstyleemphasis{classes} is often fitting a model well or getting a good AUC score, the hardest part of being an effective \sphinxstyleemphasis{professional} data scientist is ensuring that the models being fit and the results being interpreted actually solve the problem that motivated you (or your stakeholder) in the first place.

\sphinxAtStartPar
This book is designed to fill this gap between neatly curated classroom exercises and the messiness of the real world.  It will provide a unified perspective on how the perspectives and statistical tools learned in other courses complement one another, and \sphinxstyleemphasis{when} different approaches to data science are most appropriate to use. More importantly, though, it provides a framework for understanding your goals as a data scientist, and how to achieve them.



\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Is this book for me?

\sphinxAtStartPar
You’d be forgiven, serious data scientist, for flipping through this book and finding yourself thinking “Hmmm… I don’t see many equations in this book. Is this really for me, the serious data scientist?” But worry not.

\sphinxAtStartPar
This book may not be the \sphinxstyleemphasis{most} helpful resource when it comes to preparing for technical interviews (though the detailed discussion of Causal Questions in later chapters likely would be). And your impression is correct — this book contains more case studies than proofs. But don’t be fooled — this is not a “light and fuffy” book that waves vaguely in the direction of statistical concepts so you can discuss them at cocktail parties.

\sphinxAtStartPar
This book \sphinxstyleemphasis{takes as given} that you’ve already been introduced to statistical inference and machine learning, and you feel comfortable with the core concepts of implementing and evaluating stats and ML models (evaluating a model’s AUC, cross\sphinxhyphen{}validation, hypothesis testing, train\sphinxhyphen{}test sample splits, etc.). Those concepts will be treated as “assumed knowledge.”

\sphinxAtStartPar
This book is about what comes \sphinxstyleemphasis{before} and \sphinxstyleemphasis{after} you faithfully fit a model to a dataset in a robust manner. By \sphinxstyleemphasis{before}, I mean that it covers how you decide what questions to answer, what data to collect, and what models to consider using. And by \sphinxstyleemphasis{after}, I mean we will discuss how one evaluates whether a result is likely to generalize, whether a model is safe to deploy, and where to go from there.

\sphinxAtStartPar
It is, in other words, about everything you need to know \sphinxstyleemphasis{beyond} the purely technical. And while that may be the part of data science that doesn’t feel as exciting, the ability to reason about problems and think critically about the appropriate use of data science tools is what will get you promoted after you ace that technical interview. And that same ability to think critically is also what will prevent you from being replaced by the next generation of auto\sphinxhyphen{}ML tools or Large Language Models.
\end{sphinxadmonition}


\section{Solving Problems with Data: An Overview}
\label{\detokenize{10_introduction/10_our_approach:solving-problems-with-data-an-overview}}
\sphinxAtStartPar
The remainder of this chapter provides an overview of the key concepts of this book. All concepts discussed here will also be covered in greater detail in future readings. To help readers understand those more detailed readings in their proper context, however, it is important you first get an overall sense of the approach to data science being advocated in this book.


\subsection{Specifying the Problem}
\label{\detokenize{10_introduction/10_our_approach:specifying-the-problem}}
\sphinxAtStartPar
The first step in solving any problem is \sphinxstyleemphasis{always} to carefully specify the problem. While this may seem trivial, properly articulating the core problem one seeks to address can be remarkably difficult. Moreover, because everything you will do \sphinxstyleemphasis{after} articulating your problem is premised on having correctly specified your objective, it is \sphinxstyleemphasis{the} greatest determinant of the success of your project. The most sophisticated, efficiently executed, high precision, high recall model in the world isn’t worth a lick of good if the results it generates don’t solve the problem you or your stakeholder need solved.

\sphinxAtStartPar
Specifying your problem not only ensures that your subsequent efforts are properly directed, but it can also radically simplify your task. Many times problems only \sphinxstyleemphasis{appear} difficult because of how they are presented. As Charles Kettering, Head of Research at General Motors from 1920 to 1947 once said, “A problem well stated is a problem half solved.”

\sphinxAtStartPar
How do you know if you’ve “clearly articulated the problem,” and how should you go about refining your problem statement with your stakeholder? Those are topics we will discuss in detail in the coming chapters, as well as strategies for using data to help inform this process through iterative refinement of your understanding of the contours of the problem space.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Throughout this book, I will frequently use the term “stakeholder” to refer to the person whose problem that you, the data scientist, is seeking to address. I use this term because, as a young data scientist, you will often be in the position of having to use your data science skills to help someone else. Thus your stakeholder may be your manager, your CEO, or someone at another company you are advising.

\sphinxAtStartPar
However, if you’re lucky enough to \sphinxstyleemphasis{not} be directly answerable to someone else, either because you work for yourself or because you’re in a field that gives you substantial autonomy like academia, you can simply think of your “stakeholder” as yourself.

\sphinxAtStartPar
If you’re interested in developing a consumer\sphinxhyphen{}facing product (e.g., you’re an independing developer whose thinking of creating a new data\sphinxhyphen{}science\sphinxhyphen{}based web app), you may also find it useful to think of your customer of the stakeholder, since very few products are successful if they don’t solve a problem customers face.
\end{sphinxadmonition}


\subsection{Solving Problems Through Answering Questions}
\label{\detokenize{10_introduction/10_our_approach:solving-problems-through-answering-questions}}
\sphinxAtStartPar
Once we have successfully articulated our problem, we must then figure out how to solve it. As data scientists, we are somewhat restricted in the types of solutions to which we have access; nobody hires a data scientist to call donors to raise funds for cancer research, for example, or invent a new semiconductor manufacturing technique. Rather, as we will explore in detail in this book, all data science models and algorithms can be fundamentally understood as instruments for \sphinxstylestrong{answering questions} about the world using quantitative methods.

\begin{sphinxShadowBox}
\sphinxstylesidebartitle{Answering Questions}

\sphinxAtStartPar
All data science models and algorithms can be fundamentally understood as instruments for \sphinxstylestrong{answering questions} about the world using quantitative methods.
\end{sphinxShadowBox}

\sphinxAtStartPar
In light of that fact, we can reframe the challenge of a data scientist from the more amorphous task of just “figuring out how to solve the problem” to the more concrete “figure out what question, if answered, would make it easier to solve this problem.”



\sphinxAtStartPar
Once we’ve articulated a question to answer we can turn to choosing the best tool for generating an answer. But it is worth emphasizing this point — it is only at this stage of our project—not at the beginning!—that we start thinking about what statistical method, algorithm, or model to use.

\sphinxAtStartPar
Our job as data scientists is never to just grab the trendiest tool for a given type of question. Rather, we must recognize and evaluate the strengths and weaknesses of different tools available to us \sphinxstyleemphasis{in the context of the specific problem we are seeking to address}.


\subsection{Types of Questions}
\label{\detokenize{10_introduction/10_our_approach:types-of-questions}}
\sphinxAtStartPar
While this may seem an impossible task given the sheer multiplicity of data science methods available today, nearly all data science questions we may wish to answer fall into one of three categories:%
\begin{footnote}[2]\sphinxAtStartFootnote
Careful readers may notice that these categories do not include \sphinxstyleemphasis{should questions}, which are sometimes referred to as “proscriptive” or “normative” questions. As we will discuss in detail in an upcoming reading, that is because while data science is an amazing tool for characterizing the world around us, it cannot, on its own, answer questions about how the world \sphinxstyleemphasis{should} be. Answering “should questions” requires evaluating the desirability of different possible states of the world, and that can only be done with reference to a system of values, making them inherently subjective. Data science can help us predict the \sphinxstyleemphasis{consequences} of different courses of action, but it cannot tell us whether those consequences make a given course of action \sphinxstyleemphasis{preferable}.
%
\end{footnote}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Exploratory Questions: Questions about large\sphinxhyphen{}scale patterns in the data.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Useful for understanding the problem space better and prioritizing subsequent efforts.

\end{itemize}

\item {} 
\sphinxAtStartPar
Passive Prediction Questions: Questions about likely outcomes for individual observations or entities.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Useful for targeting individuals for additional attention or automating certain tasks.

\end{itemize}

\item {} 
\sphinxAtStartPar
Causal Questions: Questions about the consequences of actions or interventions being considered.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Useful for deciding on appropriate courses of action.

\end{itemize}

\end{itemize}

\sphinxAtStartPar
Each of these can play a different but important role in solving problems, and any effort to answer a question of each type will raise similar issues that need to be considered. Thus, by recognizing the \sphinxstyleemphasis{class} of questions we are seeking to answer, we can significantly narrow both the set of data science tools that are appropriate to consider and provide a short list of common considerations to think through.


\section{Question Types and Their Uses}
\label{\detokenize{10_introduction/10_our_approach:question-types-and-their-uses}}
\sphinxAtStartPar
Understanding these three types of questions — both in terms of how they can be used to help solve problems, and also in terms of the challenges inherent in answering them — is a key objective of this book. Here is a brief introduction to each type of question.


\subsection{Exploratory Questions}
\label{\detokenize{10_introduction/10_our_approach:exploratory-questions}}
\sphinxAtStartPar
Once you have settled on a problem you wish to address, the next step is often to use data science to better understand the contours of the problem in order to better prioritize and strategize your efforts. As data scientists, our best strategy for this type of investigation is to ask questions about general patterns related to your problem — what I call \sphinxstyleemphasis{Exploratory Questions.}

\sphinxAtStartPar
Why is this necessary? Well, as we’ll discuss in a future reading on “stakeholder management,” you would be \sphinxstyleemphasis{shocked} at how often stakeholders have only a vague sense of the patterns surrounding their problem. This makes refinement of your problem statement (and thus prioritization of your subsequent efforts) impossible. So before you get too far into any data science project, it’s important to ask Exploratory Questions to improve your understanding of how best to get at your problem.

\sphinxAtStartPar
To illustrate, suppose a company hired you because they were having trouble recruiting enough high\sphinxhyphen{}quality employees. You \sphinxstyleemphasis{could} ask for their HR data and immediately try to train a neural network to… well, I’m not even sure what you’d want to train it to do right off that bat! And that’s a big part of the problem. Getting more high\sphinxhyphen{}quality employees is a very general problem, and you could imagine addressing it in any number of ways — you could try and get more people to apply for the job in the first place, you could try and get a \sphinxstyleemphasis{different type} of candidate to apply then is currently applying, you could try and get more high\sphinxhyphen{}quality people who are given job offers to accept those offers, or you could help try to increase the number of people who are hired who turn out to be successful hires! But which should you do first?

\sphinxAtStartPar
To help answer this question, we can start by asking a series of Exploratory Questions that, when answered, will aid in your efforts to solve your stakeholder’s problem:
\begin{itemize}
\item {} 
\sphinxAtStartPar
How many job applications are you receiving when you post a job?

\item {} 
\sphinxAtStartPar
What share of your current job applicants are of high quality?

\item {} 
\sphinxAtStartPar
If your current applicants come from different sources (online ads, services like Indeed, outreach to colleagues for recommendations, etc.), what share of job applicants from each of these sources are of high quality?

\item {} 
\sphinxAtStartPar
What share of employees you try to hire accept your offer?

\item {} 
\sphinxAtStartPar
What share of employees you do hire turn out to be successful employees?

\end{itemize}

\sphinxAtStartPar
Suppose, for example, only 10\% of applicants who receive job offers accept. Then clearly that would seem a place where intervention would be likely to substantially increase the number of high\sphinxhyphen{}quality employees being hired. If, by contrast, 95\% of applicants accept offers, then that is clearly not a place where you would want to focus.

\sphinxAtStartPar
Similarly, if most applicants are high quality and there just aren’t enough of them, then you would probably want to focus your efforts on increasing the number of people who apply in the first place. But if only 2\% of applicants seem appropriate to the company, then maybe focus should be put on changing \sphinxstyleemphasis{who} is applying for positions with an eye towards increasing the average quality of applicants.

\sphinxAtStartPar
Answering these questions will likely not, on its own, make it clear exactly where to focus your efforts. Your stakeholder may look at the fact that only 2\% of applicants are appropriate and say “That’s fine — we have so many applications that the \sphinxstyleemphasis{absolute number} of quality applicants is actually high enough, and it’s easy to filter out the bad applicants.” But these are numbers you can bring back to your stakeholder to discuss and use to zero in on the specific facet of their problem that is most amenable to an impactful solution.

\sphinxAtStartPar
Generating answers to these types of Exploratory Questions doesn’t have the same “coolness factor” as using expensive GPUs to train deep learning models. But it is precisely this type of analysis that will help ensure that when if you \sphinxstyleemphasis{do} later run up a giant bill renting GPUs, at least that money will have been spent addressing a part of your stakeholder’s problem that matters.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
The term \sphinxstyleemphasis{Exploratory Data Analysis} (EDA) is often used in statistics courses to describe the process of poking around in a new data set before fitting a more complicated statistical model. Answering Exploratory Questions will often use some of the same tools used for EDA, but “answering Exploratory Questions” is \sphinxstylestrong{not} synonymous with EDA.

\sphinxAtStartPar
As it is commonly used, EDA (as the name implies) is often focused on getting to know a piece of \sphinxstyleemphasis{data}. It entails learning what variables are in a dataset, how they are coded, and \sphinxstyleemphasis{sometimes} also looking at general patterns in a given dataset ({\hyperref[\detokenize{30_questions/07_eda::doc}]{\sphinxcrossref{\DUrole{doc,std,std-doc}{we will discuss the conceptual issues surrounding EDA in more detail in a later reading}}}}.).

\sphinxAtStartPar
Answering Exploratory Questions, by contrast, will often be far more involved. Answering an important Exploratory Question may require you to actively seek out new datasets, merge data from different sources together, and maybe even do novel data collection.

\sphinxAtStartPar
Moreover, where EDA is often viewed as just a box to check on the road to model fitting, answering Exploratory Questions can often be an end goal in\sphinxhyphen{}and\sphinxhyphen{}of itself.
\end{sphinxadmonition}

\sphinxAtStartPar
How do we answer Exploratory Questions? As we’ll discuss in later chapters, at times Exploratory Questions can be answered with simple tools, like scatter plots, histograms, and the calculation of summary statistics like means and medians. Other times, however, it may require more sophisticated methods, like clustering or other unsupervised machine learning algorithms that can, say, identify “customer\sphinxhyphen{}types” in a large dataset of customer behavior.

\sphinxAtStartPar
Regardless of the tool used, however, the goal is always to identify patterns in the data that are salient to understanding your stakeholder’s problem.


\subsection{Passive Prediction Questions}
\label{\detokenize{10_introduction/10_our_approach:passive-prediction-questions}}
\sphinxAtStartPar
Answering Exploratory Questions helps you to prioritize your efforts and improve your understanding of your stakeholder’s problem. Often you will even bring the answers you generate to Exploratory Questions back to your stakeholder and use them to refine your problem statement in an iterative loop. But what then? As all data science tools are fundamentally tools for answering questions, we return to asking “What question, if answered, would help solve my problem?”

\sphinxAtStartPar
Many problems can be solved if we can answer questions about the future outcomes or behaviors of \sphinxstyleemphasis{individual entities} (people, stocks, stores, etc.). This type of question may take the form “Given this new customer’s behavior on my website, are they likely to spend a lot over the next year?” or “Given the symptoms of this patient and their test results, how likely are they to develop complications after surgery?” I term these questions about outcomes for individual entities \sphinxstyleemphasis{Passive Prediction Questions} as they are questions about what is likely to happen if we do not intervene in some way (i.e., if we remain passive).

\sphinxAtStartPar
Because Passive Prediction Questions are questions about individual entities, they don’t necessarily have one “big” answer. Rather, Passive Prediction Questions are answered by fitting or training a model that can take the characteristics of an individual entity as inputs (e.g., this patient is age 67, has blood pressure of 160/90, and no history of heart disease) and spitting out an answer \sphinxstyleemphasis{for that individual} (given that, her probability of surgical complications is 82\%).

\sphinxAtStartPar
This differentiates Passive Prediction Questions from Exploratory Questions. Being questions about general patterns in the world, Exploratory Questions will tend to have discrete answers. If a company gives you their hiring data, you can answer the question “What share of employees you try to hire end up accepting your offer?”

\sphinxAtStartPar
With Passive Prediction Questions, by contrast, the first question to ask is often one of feasibility: “Given data on new customer behavior on my website, \sphinxstylestrong{can I} predict how much they are likely to spend a lot over the next year?” But you then answer that question by training a model that can answer the question you really care about for any given customer: “Given this new customer’s behavior on my website, are they likely to spend a lot over the next year?”

\sphinxAtStartPar
This ability to make predictions about future outcomes is obviously of tremendous use to stakeholders as it allows them to tailor their approach at the individual level. A hospital that can predict which patients are most likely to experience complications after surgery can allocate their follow\sphinxhyphen{}up care resources accordingly. A business that knows which customers are more likely to be big spenders can be sure that those customers are given priority by customer care specialists.

\sphinxAtStartPar
But the meaning of the term “Prediction” in Passive Prediction Questions extends beyond “predicting the future”. Passive Prediction Questions also encompass efforts to predict how a third party \sphinxstyleemphasis{would} behave or interpret something about an individual if given the chance.

\sphinxAtStartPar
For example, suppose our hospital stakeholder wanted to automate the reading of mammograms, so rural hospitals without full\sphinxhyphen{}time radiologists could give patients diagnoses more quickly (or, more cynically, pay fewer radiologists).%
\begin{footnote}[3]\sphinxAtStartFootnote
Mammograms are x\sphinxhyphen{}rays of breast tissue used for the detection of breast cancer.
%
\end{footnote} We can think of this process of reading mammograms as answering the question “if a radiologist looked at this particular scan, would they conclude the patient had cancer?”

\sphinxAtStartPar
The value of this type of prediction to stakeholders is likely also self\sphinxhyphen{}evident, as it opens the door for automation and scaling of tasks that would otherwise be too costly or difficult for humans. Indeed, answering this question is the type of task for which machine learning has become most famous. Spam filtering amounts to answering the question “If the user saw this email, would they tag it as spam?” Automated content moderation amounts to answering “Would a Meta contractor conclude the content of this photo violates Facebook’s Community Guidelines?” Indeed, even Large Language Models (LLMs) like chatGPT, Bard, and LLaMA can be understood in this way, as we will discuss later.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Thinking of training an algorithm to read a mammogram as “predicting how a radiologist \sphinxstyleemphasis{would} interpret the mammogram if given the chance” may seem a little strange, but this framing is both more accurate and more conceptually useful than other ways of thinking about these models. That’s because many data science problems are solved using a practice called \sphinxstyleemphasis{supervised machine learning} in which a statistical model is “trained” using data that a human has already analyzed. Any real mammogram analyzing algorithm, for example,  is likely to be trained using examples of mammograms that human radiologists had reviewed and labeled as either containing suspicious abnormalities or not.

\sphinxAtStartPar
But a critical feature of this supervised machine learning approach is that the model is not actually being being taught to “find cancer” \sphinxstyleemphasis{per se}; it is being taught to emulate the behavior of the human radiologists who labelled the training data. Or, expressed differently, the model is being trained to answer the question “If one of the radiologist who labelled my training data looked at this scan, would they diagnose the patient with cancer?”

\sphinxAtStartPar
This distinction is subtle, but it is important because it helps us to understand why any model we train in this way will inherit all of the biases and limitations of the radiologists who created the data used to train the algorithm. If, for example, our radiologists were less likely to see cancer in denser breast tissue, that bias would also be inherited by the algorithm.

\sphinxAtStartPar
(We call the inevitable existance of some difference between between what we \sphinxstyleemphasis{want} the algorithm to do — in this case, detect cancer — and \sphinxstyleemphasis{what it is actually being trained to do} — predict how a radiologist would interpret the scan — an “alignment problem.”)
\end{sphinxadmonition}

\sphinxAtStartPar
The big differentiator between Exploratory Questions and Passive Prediction Questions is that Exploratory Questions are questions about \sphinxstyleemphasis{general patterns} in the data, while Passive Prediction Questions are questions about \sphinxstyleemphasis{individual observations or entities}.

\sphinxAtStartPar
It is worth emphasizing that this is a distinction \sphinxstyleemphasis{in purpose}, not necessarily in the statistical tools that are most appropriate to the task. A linear regression, for example, may be used for answering either type of question, but in different ways. To answer an Exploratory Question, we might look at the coefficients in a linear regression to understand the partial correlations between variables in the data. To answer a Passive Prediction Question, we might only look at the predicted values from the regression model.

\sphinxAtStartPar
But even if the same \sphinxstyleemphasis{type} of model can be used for both purposes, how one \sphinxstyleemphasis{evaluates} the model depends entirely on the purpose to which it is being put. When answering an Exploratory Question through the interpretation of regression coefficients, the size of the standard errors on the coefficients is critical. When making predictions, by contrast, one may not care about the coefficients of a model at all! So long as the R\sphinxhyphen{}squared is high enough (and other diagnostics seem good), one can simply use the predicted values the regression generates without ever looking “inside the box.”

\sphinxAtStartPar
As such, there’s no simple mapping between statistical or machine learning methods and the type of questions you aim to answer. However, \sphinxstyleemphasis{in general}, Passive Prediction Questions are most commonly the domain of methods that fall under the label “supervised machine learning,” which encompasses everything from linear regression to neural networks.


\subsection{Causal Questions}
\label{\detokenize{10_introduction/10_our_approach:causal-questions}}
\sphinxAtStartPar
The word “passive” in “Passive Prediction Questions” is there because many data science problems entail predicting what outcomes would occur absent intervention. For example, when answering the question “Given their case history, how likely is this patient to experience post\sphinxhyphen{}surgical complications?” we don’t actually want to know how likely they are to experience complications — we want to know how likely they would be to experience complications \sphinxstyleemphasis{if the status quo prevails and our behavior doesn’t change.} Our hope, after all, is that by learning that a certain patient is likely to experience complications we can act to prevent that outcome!

\sphinxAtStartPar
Causal Questions, by contrast, are questions about predicting the \sphinxstyleemphasis{effect} of actions \sphinxstyleemphasis{we may choose to take}. Causal Questions arise when stakeholders want to do something — buy a Superbowl ad, change how the recommendation engine in their app works, authorize a new prescription drug — but they fear the action they are considering may be costly and not actually work. In these situations, stakeholders will often turn to a data scientist in the hope that the scientist can “de\sphinxhyphen{}risk” the stakeholder’s decision by providing guidance on the likely effect of the action \sphinxstyleemphasis{before} the action is undertaken at full scale.

\sphinxAtStartPar
Causal Questions, therefore, take the form of “What is the effect of an action X on an outcome Y?”—or more usefully, “If I do X, how will Y change?”. Nearly anything can take the place of X and Y in this formulation: X could be something small, like changing the design of a website, or something big, like giving a patient a new drug or changing a government regulation. Y, similarly, could be anything from “how long users stay on my website” or “how likely are users to buy something at my store” to “what is the probability that the patient survives”.

\sphinxAtStartPar
In my view, Causal Questions are perhaps the hardest to answer for two reasons. The first is that when we ask a Causal Question, we are fundamentally interested in \sphinxstyleemphasis{comparing} what our outcome Y would be in two states of the world: the world where we do X, and the world where we don’t do X. But as we only get to live in one universe, we can never perfectly know what the value of our outcome Y would be in \sphinxstyleemphasis{both} a world where we do X and one where we don’t do X—a problem known as the \sphinxstylestrong{Fundamental Problem of Causal Inference} (causal inference is just what people call the study of how to answer Causal Questions).

\sphinxAtStartPar
But the second reason is Causal Questions land on the desk of data scientists when a stakeholder wants to know the likely consequences of an action \sphinxstyleemphasis{before they actually undertake the action at full scale.} This may seem obvious, but it bears repeating — not only is answering Causal Questions hard because we never get to measure outcomes in both a universe where our treatment occurs and also a universe where it does not (the Fundamental Problem of Causal Inference), but answering Causal Questions is \sphinxstyleemphasis{also} hard because stakeholders want to know about the likely consequences of an action they aren’t ready to actually undertake!

\sphinxAtStartPar
As a result, the job of a data scientist who wants to answer a Causal Question is to design a study that not only measures the effect of a treatment but also does so in a setting that is enough like the context in which the stakeholder wants to act that any measured effect will generalize to the stakeholder’s context.


\section{Bringing It All Together}
\label{\detokenize{10_introduction/10_our_approach:bringing-it-all-together}}
\sphinxAtStartPar
In this introductory chapter alone, we’ve already covered a substantial amount of material. We’ve discussed the importance of problem articulation, the idea that the way data scientists solve problems is by answering questions, and the three types of questions data scientists are likely to encounter.

\sphinxAtStartPar
It’s easy to see how this framework might result in a sequential development of a project. First, a hospital comes to you concerned about the cost of surgical complications. So you:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Work with them to more clearly define the problem (“Surgical complications are extremely costly to the hospital and harm patients. We want to reduce these complications in the most cost\sphinxhyphen{}effective manner possible.”)

\item {} 
\sphinxAtStartPar
You answer some Exploratory Questions (“Are all surgical complications equally costly, or are there some we should be most concerned about?”).

\item {} 
\sphinxAtStartPar
You develop a model to answer a Passive Prediction Question (“Given data in patient charts, can we predict which patients are most likely to experience complications?”) so the hospital can marshal its limited nursing resources more effectively.

\item {} 
\sphinxAtStartPar
The hospital then comes back to you to ask the Causal Question “Would a new program of post\sphinxhyphen{}discharge nurse home visits for patients identified as being at high risk of complications reduce complications?”

\end{enumerate}

\sphinxAtStartPar
In reality, however, while it is important that some steps come before others (if you don’t start by defining your problem, where do you even start?), real projects are never so linear. The reality is that you will constantly find yourself moving back and forth between different types of questions, using new insights gained from answering one question to refine your problem statement and articulate new questions.

\sphinxAtStartPar
Nevertheless, by using this framework as a starting point, and using this taxonomy to help you recognize (a) the type of question you are asking, and (b) the reason you are seeking to answer a given question even when iterating through a project, you will see tremendous gains in your ability to please your stakeholders by staying focused on the problems they need addressed.


\section{Reading Reflection Questions}
\label{\detokenize{10_introduction/10_our_approach:reading-reflection-questions}}
\sphinxAtStartPar
At the end of many readings in this book you will find a set of “reading reflection questions.” As the name implies, these are questions meant to help readers reflect on what they’ve read, as well as to draw attention to key points from the chapter.
\begin{itemize}
\item {} 
\sphinxAtStartPar
What is the purpose of this book? What problem in data science education does it aim to address?

\item {} 
\sphinxAtStartPar
What is \sphinxstylestrong{the} most important task for a data scientist hoping to successfully help their stakeholder?

\item {} 
\sphinxAtStartPar
In the view of this book, all data science tools are tools for doing what? Do you agree?

\item {} 
\sphinxAtStartPar
What are the three types of questions a data scientist is likely to encounter? What is the primary purpose of each type of question?

\item {} 
\sphinxAtStartPar
Does one always move through the questions presented here in the same order?

\end{itemize}


\bigskip\hrule\bigskip


\sphinxstepscope


\chapter{Stakeholder Management \& Solving the Right Problem}
\label{\detokenize{10_introduction/30_solving_the_right_problem:stakeholder-management-solving-the-right-problem}}\label{\detokenize{10_introduction/30_solving_the_right_problem::doc}}
\sphinxAtStartPar
In Douglas Adams’ comedic sci\sphinxhyphen{}fi classic \sphinxstyleemphasis{Hitchhiker’s Guide to the Galaxy}, a race of hyperintelligent pandimensional beings set out to build a massive supercomputer the size of a city to solve the mysteries of the cosmos once and for all. When they turned on the computer, named Deep Thought, they announced that:
\begin{quote}

\sphinxAtStartPar
“The task we have designed you to perform is this. We want you to tell us… the Answer!”

\sphinxAtStartPar
“The Answer?” said Deep Thought.

\sphinxAtStartPar
“The Answer to what?”

\sphinxAtStartPar
“Life!” urged one designer.

\sphinxAtStartPar
“The Universe!” said another.

\sphinxAtStartPar
“Everything!” they said in chorus.

\sphinxAtStartPar
Deep Thought paused, then answered, “Life, the Universe, and Everything. There is an answer. But,” Deep Thought added, “I’ll have to think about it.”
\end{quote}

\sphinxAtStartPar
Seven and a half million years later, when Deep Thought had \sphinxstyleemphasis{finally} finished its calculations, the descendants of those designers assembled to learn the result of their ancestors’ work.
\begin{quote}

\sphinxAtStartPar
“Er …good morning, O Deep Thought,” said Loonquawl {[}one descendants{]} nervously, “do you have … er, that is …”

\sphinxAtStartPar
“An answer for you?” interrupted Deep Thought majestically. “Yes. I have.”

\sphinxAtStartPar
The two {[}descendants{]} shivered with expectancy. Their waiting had not been in vain.

\sphinxAtStartPar
“There really is one?” breathed Phouchg {[}the other descendant{]}.

\sphinxAtStartPar
“There really is one,” confirmed Deep Thought.

\sphinxAtStartPar
“To Everything? To the great Question of Life, the Universe and Everything?”

\sphinxAtStartPar
“Yes. {[}…{]} Though I don’t think,” added Deep Thought, “that you’re going to like it.”

\sphinxAtStartPar
{[}…{]}

\sphinxAtStartPar
“All right,” said the computer, and settled into silence again.

\sphinxAtStartPar
The two fidgeted.

\sphinxAtStartPar
The tension was unbearable.

\sphinxAtStartPar
“Forty\sphinxhyphen{}two,” said Deep Thought, with infinite majesty and calm.

\sphinxAtStartPar
“Forty\sphinxhyphen{}two!” yelled Loonquawl. “Is that all you’ve got to show for seven and a half million years’ work?”

\sphinxAtStartPar
“I checked it very thoroughly,” said the computer, “and that quite definitely is the answer. I think the problem, to be quite honest with you, is that you’ve never actually known what the question is.”

\sphinxAtStartPar
“But it was the Great Question! The Ultimate Question of Life, the Universe and Everything,” howled Loonquawl.

\sphinxAtStartPar
“Yes,” said Deep Thought with the air of one who suffers fools gladly, “but what actually is it?”

\sphinxAtStartPar
A slow stupefied silence crept over the men as they stared at the computer and then at each other.

\sphinxAtStartPar
“Well, you know, it’s just Everything … everything …” offered Phouchg weakly.

\sphinxAtStartPar
“Exactly!” said Deep Thought. “So once you do know what the question actually is, you’ll know what the answer means.”%
\begin{footnote}[1]\sphinxAtStartFootnote
Yes, I recognize that it is wildly indulgent to open a chapter with such a long epigraph. But it’s my book, and if there’s anything to be indulgent about its quotes from \sphinxstyleemphasis{Hitchhiker’s Guide to the Galaxy}, damn it!
%
\end{footnote}
\end{quote}

\sphinxAtStartPar
In addition to establishing the premise for one of the greatest comedic science fiction novels in human history,%
\begin{footnote}[2]\sphinxAtStartFootnote
Not least for being the only 5\sphinxhyphen{}book trilogy of which I am aware!
%
\end{footnote} I feel this passage perfectly exemplifies the three things that cause most data science projects to fail.

\sphinxAtStartPar
The first is that we are often so enamored with technology that we have absolute faith that if we just throw our problems at it, it will solve them for us. But it won’t. Without our thoughtful, critical guidance, it can’t. It never has, and it never will.

\sphinxAtStartPar
The second is that the \sphinxstyleemphasis{reason} this doesn’t work is that if we don’t actually figure out what it is we hope the technology will do for us, and make sure that what we’re asking for will actually solve a real problem, technology couldn’t care less. It will do what it has been asked to do — no more and no less. Garbage in, garbage out.

\sphinxAtStartPar
But the third reason data science projects fail that is exemplified in this passage is the most subtle. In this passage, we can see that Deep Thought recognizes the idiocy of the request it has been given by Loonqual and Phouchg, it doesn’t do anything about it. And that, unfortunately, is the cardinal sin committed by most young data scientists — they fail to recognize that helping the stakeholder properly specify their problem is a core part of the job.

\begin{sphinxShadowBox}

\sphinxAtStartPar
And that, unfortunately, is the cardinal sin committed by most young data scientists — they fail to recognize that helping the stakeholder properly specify their problem is a core part of the job.
\end{sphinxShadowBox}

\sphinxAtStartPar
At this point, you may be thinking “well, isn’t that \sphinxstyleemphasis{their} problem? They’re the ones who asked me to do the wrong thing?” And… yes, in some sense it is. But it’s also yours. Once you leave the classroom, you will no longer be evaluated on the complexity of your model or the aesthetics of your visualizations—you’ll be evaluated on whether you’ve made your stakeholder’s life better. And even if it was the stakeholder who originally misspecified their need, if you fail to correct that error and deliver a result that doesn’t help your stakeholder, then that’s all that will be remembered.

\sphinxAtStartPar
In this chapter, we will discuss the concept of “stakeholder management:” specific ways you can work with your stakeholder to help refine and improve your mutual understanding of the problem you are seeking to solve before you—like the Deep Thought computer in \sphinxstyleemphasis{Hitchhiker’s Guide to the Galaxy}—spend weeks dutifully grinding away to solve a misspecified problem, only to deliver a result to their stakeholder that turns out to not be as helpful as expected.

\sphinxAtStartPar
Not someone who has an obvious stakeholder with whom you can have this type of conversation? Well, stick with me — many of the suggested questions and conversational strategies detailed below are ones I’ve often used in conversation with myself in my academic research, and I assure you they work almost as well when talking to the voices in your head as with another person.


\section{Problem Refinement \& Stakeholder Management}
\label{\detokenize{10_introduction/30_solving_the_right_problem:problem-refinement-stakeholder-management}}
\sphinxAtStartPar
How then should you — the young data scientist — go about ensuring your efforts are well spent?

\sphinxAtStartPar
There are (sorry) no hard and fast rules for how to work with your stakeholder to better articulate the problem you are seeking to solve. If there were, there would probably be a lot fewer problems in the world, since refining and re\sphinxhyphen{}articulating problems is often a major part of what results in them being solved. As Charles Kettering, Head of Research at General Motors from 1920 to 1947 once said, “A problem well stated is a problem half solved.”

\begin{sphinxShadowBox}

\sphinxAtStartPar
“A problem well stated is a problem half solved.”
\begin{itemize}
\item {} 
\sphinxAtStartPar
Charles Kettering, Head of Research at General Motors.

\end{itemize}
\end{sphinxShadowBox}

\sphinxAtStartPar
Nevertheless, here are some guiding principles to bear in mind. Read these, reflect on these, but most importantly, \sphinxstyleemphasis{review} them from time to time as you begin new data science engagements!


\subsection{Step 0: Recognize Your Role}
\label{\detokenize{10_introduction/30_solving_the_right_problem:step-0-recognize-your-role}}
\sphinxAtStartPar
If you remember nothing else from this chapter, please remember this: helping your stakeholder better understand their problem is a core part of the job.

\sphinxAtStartPar
Because most stakeholders are older and domain experts in their field, young data scientists tend to err on the side of deference. It is important to be respectful of your stakeholder’s experience and to use their domain expertise, but it is important to also recognize that data science is about \sphinxstyleemphasis{pairing} domain expertise with computational methods and quantitative insights, and neither you nor your stakeholder is likely to have expertise in \sphinxstyleemphasis{both} the substantive domain in question \sphinxstyleemphasis{and} cutting edge quantitative methods. Indeed, if they did, they probably wouldn’t be hiring you!%
\begin{footnote}[3]\sphinxAtStartFootnote
Obviously there are exceptions to this — if you work for a mature tech company like Google or Meta, you may very well end up working under a manager who knows sides of a problem significantly better than you. In my experience, however, is circumstance is the exception, not the rule.
%
\end{footnote} So don’t hesitate to speak up! Ask questions, raise concerns, and while you should do so with \sphinxstyleemphasis{some} humility, have confidence in your own expertise.


\subsection{Step 1: Don’t Assume Your Stakeholder Knows What They Need}
\label{\detokenize{10_introduction/30_solving_the_right_problem:step-1-don-t-assume-your-stakeholder-knows-what-they-need}}
\sphinxAtStartPar
A corollary to Step 0 is to not assume your stakeholder understands what they need. So when I say “helping your stakeholder understand their problem is a core part of the job,” I don’t only mean that it’s part of your job \sphinxstyleemphasis{if the stakeholder admits to deep uncertainty about their problem}.” Odds are your stakeholder will come to you with a strong statement of what they think they want, but you should take that as a starting point for discussion, not your mandate.

\sphinxAtStartPar
This is particularly true if your stakeholder comes to you with really specific technical suggestions. Often you will be approached by a stakeholder who, rather than laying out a problem, announces they would like you to do X using some data science tool Y. Occasionally the stakeholder doing this knows exactly what they’re talking about, and you should use Y to do X.

\sphinxAtStartPar
More often, however, you’re dealing with a stakeholder with just enough knowledge to be dangerous (and to drop buzzwords), but not enough to know how best to solve their problem.

\sphinxAtStartPar
Most people ask data scientists for help because they don’t know much about data science (or, worse, they \sphinxstyleemphasis{think} they know about data science but don’t). Again, different rules apply if you’re at Google or Apple, but in most contexts, it’s a good idea to treat implementation details provided by the client as a red herring. Focus on the stakeholder’s \sphinxstyleemphasis{needs}. Only get into implementation details once you feel you understand the problem well.

\begin{sphinxShadowBox}

\sphinxAtStartPar
Focus on the stakeholder’s \sphinxstyleemphasis{needs}. Only get into implementation details once you feel you understand the problem well.
\end{sphinxShadowBox}


\subsection{Step 2: Abstract the Problem}
\label{\detokenize{10_introduction/30_solving_the_right_problem:step-2-abstract-the-problem}}
\sphinxAtStartPar
So how do you help your stakeholder better understand \sphinxstyleemphasis{their} problem?

\sphinxAtStartPar
If I could offer only one piece of advice on how to approach a sticky problem, it would be this: rephrase the problem in a more general manner that abstracts away from the specifics. It’s difficult to overstate how often a “unique” sticky problem becomes very straightforward once you realize it’s a special case of a more general type of problem, or once you realize that your stakeholder has (often unknowingly) introduced constraints to the problem that aren’t actually constraints.

\sphinxAtStartPar
Perhaps my favorite example of this comes from a talk given by \sphinxhref{https://youtu.be/kYMfE9u-lMo?t=1281\&si=haO8mlmO5tB4OC9k}{Vincent Warmerdam at PyData 2019.}

\sphinxAtStartPar
The World Food Program (WFP) is a global leader in food aid provision. As Vincent tells the story — which he reports having heard at an Operations Research Conference — the WFP was struggling with an extremely difficult data science problem: how best to get food from the places it was being grown/stored to the people who needed it most. Essentially, the WFP would receive reports of needs from communities facing food insecurity. One community might report a need for bread and beef, while another might request lentils and meat. The WFP would compile these requests and then set about trying to determine the most efficient way to meet these needs.

\sphinxAtStartPar
This type of logistics problem is an example of a notoriously difficult problem (essentially a version of the Traveling Salesman Problem, which is NP\sphinxhyphen{}Complete, if that means anything to you) that companies like FedEx and UPS buy supercomputers to address. But this particular problem was made extra challenging by all the different types of food the WFP was trying to provide communities.

\sphinxAtStartPar
What the WFP realized was that they didn’t actually need to provide bread to the village asking for bread. See, humans don’t need \sphinxstyleemphasis{bread} to avoid starvation — they need a certain number of calories, a certain amount of protein, and a handful of other nutrients.%
\begin{footnote}[4]\sphinxAtStartFootnote
As I understand it, calcium, iron, vitamins A, B1, B2, C, and niacin.
%
\end{footnote} So when a village asks for bread, rice, or wheat, you can instead think of them asking for carbohydrates. And a village asking for beef or beans is actually asking for protein and iron. So by simply abstracting the task from “How best can we meet all these food requests?” to “How best can we meet the nutritional needs indicated by these requests?” the WFP was able to \sphinxstyleemphasis{dramatically} reduce the number of constraints being imposed on the logistical optimization problem WFP needed to solve, making its task \sphinxstyleemphasis{far} simpler.


\subsection{Step 3: Ask Questions (Especially Quantitative Ones!)}
\label{\detokenize{10_introduction/30_solving_the_right_problem:step-3-ask-questions-especially-quantitative-ones}}
\sphinxAtStartPar
Be sure to ask a lot of questions of your stakeholder. In particular, I would suggest two types: questions about what success would look like, and questions about the problem itself.


\subsubsection{Questions About Success}
\label{\detokenize{10_introduction/30_solving_the_right_problem:questions-about-success}}
\sphinxAtStartPar
Getting a sense of where the goalposts are for your stakeholder will both help you know what to target and also help you better understand your stakeholder’s understanding of the problem. Make sure to ask questions like:
\begin{itemize}
\item {} 
\sphinxAtStartPar
How are you measuring the problem? What would you measure to help you know if you were successful in solving the problem?

\item {} 
\sphinxAtStartPar
How big, in quantitative terms, is this problem?

\item {} 
\sphinxAtStartPar
How much would you need the current situation to change to call this a success?

\end{itemize}


\subsubsection{Questions About the Problem}
\label{\detokenize{10_introduction/30_solving_the_right_problem:questions-about-the-problem}}
\sphinxAtStartPar
The more you know about your client’s needs the better, so ask anything that comes to mind. If the client can answer your question, it will help you better understand the situation; if the client can’t answer your question you may find that they are suddenly really interested in knowing the answer, and you immediately have some of your first Exploratory Questions to try to resolve.

\sphinxAtStartPar
In the example of the company that wanted to improve recruitment of high\sphinxhyphen{}quality employees in the introduction of this book, I suggested that some of the first exploratory questions you might want to investigate would be things like:
\begin{itemize}
\item {} 
\sphinxAtStartPar
How many job applications are you receiving when you post a job?

\item {} 
\sphinxAtStartPar
What share of your current job applicants are of high quality?

\item {} 
\sphinxAtStartPar
What share of employees you try to hire accept your offer?

\item {} 
\sphinxAtStartPar
What share of employees you do hire turn out to be successful employees?

\end{itemize}

\sphinxAtStartPar
These are all questions that I would ask my stakeholder in one of our first meetings.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Stakeholder Meetings
It is always good to go into meetings with your stakeholder with a clear sense of your objectives — what you hope to communicate, and what information and feedback you need to get before the meeting ends. When your stakeholder is someone you don’t get to meet with regularly, it’s good practice to detail these objectives and provide them — in writing — to your stakeholder in advance of your meeting. This will not only ensure that you and your teammates are on the same page (as you will all have reviewed the document before sending it to your stakeholder), but also ensure that your stakeholder has adequete time to reflect on any questions or issues you wish to raise.

\sphinxAtStartPar
When it comes to your \sphinxstyleemphasis{first} meeting, however, this practice can feel impractical as you may feel so uncertain about the project that you only know the first few questions you want to ask.

\sphinxAtStartPar
But even in a first meeting, preparation is key. Rather than laying out the new issues you wish to raise and questions you want answered, for a first meeting it’s helpful to write out a full \sphinxstyleemphasis{tree} of lines of inquiry you may wish to propose. In other words, for every question you wish to pose to your stakeholder, try to anticipate some likely responses they make provide, then write down a few followup questions to ask if they provide one of those responses.

\sphinxAtStartPar
Time with your stakeholder is \sphinxstyleemphasis{precious}, especially early in a project, make the most of that face time through preparation.
\end{sphinxadmonition}


\subsection{Step 4: Propose Questions You Might Answer}
\label{\detokenize{10_introduction/30_solving_the_right_problem:step-4-propose-questions-you-might-answer}}
\sphinxAtStartPar
As a data scientist, answering questions about the world is the instrument you have to solve problems. So once you think you have a sense of your stakeholder’s needs, turn around and propose a handful of questions and ask them if answering those questions would help solve their problem.

\sphinxAtStartPar
This is important because many people have only a vague sense of what they are likely to get as a “deliverable” from the data scientist. They usually have a vague sense that they will get some type of magic machine (a “magic model” or “magic algorithm”) that will just make their problem go away. By concretely framing your deliverable as the answer to a question (or a model that would answer a specific question for each entity like a customer or patient that it encounters), you can get much more valuable feedback before you dive into a problem.


\subsubsection{Make Your Questions Specific and Actionable}
\label{\detokenize{10_introduction/30_solving_the_right_problem:make-your-questions-specific-and-actionable}}
\sphinxAtStartPar
In developing your questions, it is important to make them specific and actionable. A specific and actionable question makes it very clear what you need to do next. For example, suppose an international aid organization told you they were worried that urbanization in Africa, Asia, and Latin America was impacting efforts to reduce infant mortality. Some examples of specific, actionable questions are: “Is infant mortality higher among recent migrants to urban centers, controlling for income?” or “Are the causes of infant mortality among recent migrants to urban centers different from those living in rural areas?” Reading those questions, you can probably immediately think of what data you’d need to collect, and what regressions you’d want to run to generate answers to those questions.

\sphinxAtStartPar
Vague questions would be “Is urbanization impacting efforts to reduce infant mortality?”, or “Does urbanization affect infant mortality?” Note that when you read these, they don’t seem to obviously imply a way forward.

\sphinxAtStartPar
Perhaps the best way to figure out if your question is answerable is to write down what an answer to your question would look like. Seriously – try it. Can you write down, on a piece of paper, the graph, regression table, or machine learning diagnostic statistics (complete with labels on your axes, names for variables, etc.) that would constitute an answer to your question? If not, it’s probably too vague.


\subsection{Step 5: Iterate}
\label{\detokenize{10_introduction/30_solving_the_right_problem:step-5-iterate}}
\sphinxAtStartPar
And here’s the last but perhaps most important step: \sphinxstylestrong{iterate.} Bring your work back to your stakeholder as often as possible.

\sphinxAtStartPar
Many stakeholders find the idea of data science mysterious and abstract and will struggle to understand what is and is not feasible. By bringing them intermediate results, the whole process will start to become more concrete for the stakeholder, and it will help them provide you with better feedback.

\sphinxAtStartPar
The way this book is organized suggests a natural flow from problem articulation to answering Exploratory Questions to prioritize efforts, to answering Passive\sphinxhyphen{}Prediction Questions to target individuals for extra attention or automate tasks, and finally to Causal Questions to better understand the effects of that extra attention/automation. In reality, however, a good data scientist is always coming back to the stakeholder, updating their plan, and jumping back in the sequence when new questions arise.


\section{What Solving the Wrong Problem Looks Like}
\label{\detokenize{10_introduction/30_solving_the_right_problem:what-solving-the-wrong-problem-looks-like}}
\sphinxAtStartPar
Our discussion up to this point has been a little abstract, so to illustrate what it means to “mis\sphinxhyphen{}specifying a problem.” The details of this example are fictitious, but the underlying logic of this example is not; indeed, the insight illustrated by this example is central to one of the biggest pivots in how people think about online advertising.

\sphinxAtStartPar
You have been hired by the advertising division of a fictitious national pizza chain—let’s call it Little Papa Dominos (LPD). LPD spends a \sphinxstyleemphasis{lot} on online advertising, but their resources aren’t being deployed as effectively as they could be. They spend more than most of their competitors, and yet their online sales are lagging.

\sphinxAtStartPar
After consulting industry groups and online advertising experts, they discovered that the rate at which people click their ads (their ads’ \sphinxstyleemphasis{click\sphinxhyphen{}through rate}, or CTR) is well below the industry average.

\sphinxAtStartPar
To address the problem, they’ve hired you—a newly minted Data Scientist—to improve the CTR of their ads. They give you a large budget, access to all the cloud computing resources you need, and even a small staff.

\sphinxAtStartPar
“Well,” you reason, “maybe the problem is that our ads aren’t being shown to the right people. After all, it seems unlikely that any ad for pizza—no matter how appealing—is likely to draw a click if it’s shown to a 75\sphinxhyphen{}year\sphinxhyphen{}old at 7 am.” So you set out to build a statistical model to answer the question, “given a user’s demographics and online behavior, how likely are they to click on one of LPDs ads?” If you can answer that, you figure, LPD can prioritize buying the ad spots for the types of users most likely to click on their ads.

\sphinxAtStartPar
To develop that model, you use your budget to run your ads on different sites and at different times. You then use that data (and those glorious cloud computing resources) to train a machine learning model that predicts whether someone will click on one of your ad based on the user’s demographics and ad placement. You try out a few different models, tune the model parameters, and eventually settle on a neural network model with extremely high precision \sphinxstyleemphasis{and} recall. Hooray!

\sphinxAtStartPar
LPD uses the model to target users likely to click their ads, and almost immediately the CTR of their ads increases 5\sphinxhyphen{}fold! Not only that, but the share of people who click on ads that go on to buy a pizza has also increased. Everyone congratulates you, and you move on to the next project feeling very smug.

\sphinxAtStartPar
A few months later, though, you are called into a meeting with the LPD advertising team and the company’s Chief Financial Officer. They’ve been looking over the numbers, and despite the huge rise in CTR, they seem to be getting fewer online orders than before you arrived. CTR rates are up, but somehow it isn’t generating greater profits.

\sphinxAtStartPar
Can you figure out what went wrong?

\sphinxAtStartPar
OK, this is the place in most books where the authors ask you that question, and you look up at the ceiling for a minute, shrug, and then read on.

\sphinxAtStartPar
But I’m really, \sphinxstyleemphasis{really} serious about this: close your laptop, stand up, set a 5\sphinxhyphen{}minute timer on your phone, and go for a walk. Ponder this example. See if you can figure out what’s going on. This is \sphinxstyleemphasis{precisely} the kind of problem you will soon face as a professional data scientist, so why not practice trying to think through the problem?


\subsection{Solving The Wrong Problem}
\label{\detokenize{10_introduction/30_solving_the_right_problem:solving-the-wrong-problem}}
\sphinxAtStartPar
So what happened?

\sphinxAtStartPar
The reason an increased click rate wasn’t making LPD richer is that LPD’s problem was never the fact they had a low CTR; LPD’s \sphinxstyleemphasis{real} problem was that they weren’t getting a lot of orders online. And because Little Papa Domino’s problem wasn’t a low CTR, being able to answer the question “How likely is a given user to click on an ad” \sphinxstyleemphasis{didn’t actually solve their real problem}.

\sphinxAtStartPar
What question, if answered, would have helped solve their problem? “Given a user’s demographics and online behavior, \sphinxstyleemphasis{how much more likely are they to buy a pizza} from LPD if we show them an ad?”

\sphinxAtStartPar
Or, expressed more succinctly, LPD \sphinxstyleemphasis{thought} their problem was that their ads weren’t \sphinxstyleemphasis{getting clicks,} but really their problem was that their ads weren’t \sphinxstyleemphasis{driving increased sales}.

\sphinxAtStartPar
The difference is subtle, but critically important: someone clicking an ad doesn’t make Little Papa Dominos any money. Someone clicking an ad \sphinxstyleemphasis{and ordering a pizza} doesn’t necessarily make LPD any money. Why? Because they may be someone who would have bought a pizza from LPD anyway, whether you showed them an ad or not. The person who was already thinking of ordering a pizza from LPD is \sphinxstyleemphasis{precisely} the type of person your algorithm may have targeted, and who may have clicked the ad to save themselves a Google search!

\sphinxAtStartPar
But the person LPD \sphinxstyleemphasis{wants} to show an ad to isn’t the person who was already thinking of ordering a pizza from LPD, it’s the person who was thinking of a pizza but wasn’t sure who to order it from, or the person who wanted dinner but didn’t know what to get. They may be less likely to click the ad than the person who was about to Google “Little Papa Dominos,” but their precisely the type of user who is more likely to buy a pizza from LPD as a result of seeing an ad than they would have been otherwise.


\subsubsection{Counter\sphinxhyphen{}Factual Advertising}
\label{\detokenize{10_introduction/30_solving_the_right_problem:counter-factual-advertising}}
\sphinxAtStartPar
Lest you think this example is contrived, it’s not. The realization that the goal of ads isn’t to maximize clicks but rather to induce the largest possible change in purchasing behavior is one of the most important ideas in online advertising. It has had a huge impact on how online advertising works, and how people evaluate the success of ad campaigns.

\sphinxAtStartPar
Indeed, this is why companies like Meta and Google are so eager to track user behavior across apps and websites. When Meta and Google can “follow” users after they’ve clicked an ad, they can evaluate ad performance based not on clicks but on customer behavior. When paired with their ability to show ads to some users and not to others and track both groups as they move around the web, Meta and Google can see whether users who see the ads are more likely to make purchases than those who don’t. This allows them to estimate the true effect of ads on sales, data they use to improve ad targeting \sphinxstyleemphasis{and} justify higher prices to advertisers.


\section{Next Up: Types of Questions}
\label{\detokenize{10_introduction/30_solving_the_right_problem:next-up-types-of-questions}}
\sphinxAtStartPar
Having established the importance of first articulating the problem one seeks to solve, we will shortly turn to developing our understanding of the three types of questions introduced in the first chapter of this book.

\sphinxAtStartPar
First, though, a quick digression into understanding the historical context of data science. This may feel like an odd topic to talk through in a technical data science text, but as we’ll see understanding how we got to where we are today is key to successfully navigating modern data science.


\section{Reading Reflection Questions}
\label{\detokenize{10_introduction/30_solving_the_right_problem:reading-reflection-questions}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Why should you care if your stakeholder misspecifies their problem?

\end{itemize}


\bigskip\hrule\bigskip


\sphinxstepscope


\chapter{What \sphinxstyleemphasis{is} Data Science: An Historical Perspective}
\label{\detokenize{10_introduction/40_data_science_in_historical_context:what-is-data-science-an-historical-perspective}}\label{\detokenize{10_introduction/40_data_science_in_historical_context::doc}}
\sphinxAtStartPar
Given how often the term “data science” gets thrown around, you would be excused for thinking that the meaning of the term was clearly understood. The reality, however, is that if you were to ask ten people working in the field you will almost certainly get ten different descriptions of what it is and what they do.

\sphinxAtStartPar
Part of that is deliberate obfuscation—data science is \sphinxstyleemphasis{so} trendy that everyone wants to claim that what they’re doing is data science in order to woo venture capitalists or to win research grants. Indeed, it has been said (half\sphinxhyphen{}joking, half\sphinxhyphen{}seriously): “Data science is \sphinxstyleemphasis{Artificial Intelligence} when you’re raising money, \sphinxstyleemphasis{Machine Learning} when you’re hiring, and it’s \sphinxstyleemphasis{Logistic Regression} when you actually have to get the job done.

\sphinxAtStartPar
But the ambiguity that surrounds the term “data science” is also the result of the fact that data science is not a mature discipline in the way that computer science, economics, or mechanical engineering are mature disciplines. And, as a young data scientist, that immaturity is important for you to understand, as it is both the source of some of the most exciting opportunities and also some of the biggest challenges you will face.


\section{The Organization of Academia, Data Science, and You}
\label{\detokenize{10_introduction/40_data_science_in_historical_context:the-organization-of-academia-data-science-and-you}}
\sphinxAtStartPar
To explain what the term data science means in practice, we have to start by discussing a bit of the inside\sphinxhyphen{}baseball%
\begin{footnote}[1]\sphinxAtStartFootnote
“\sphinxhref{https://en.wikipedia.org/wiki/Inside\_baseball\_(metaphor)}{Inside baseball}” refers to the discussion of the idiosyncracies and details of how an institution or system operates internally, something that is often not of interest to people who aren’t part of the system.
%
\end{footnote} of how academia operates. This may feel esoteric, but it’s important to understand because the way academia is organized has shaped the professional training — and thus the language and thought patterns — of most people you will encounter in the data science space. Understanding academia better, as a result, will not only help you understand the material you are exposed to in data science classes better, but also help you relate to your future peers and colleagues.

\sphinxAtStartPar
The idea that academia is deeply fragmented often surprises students, and understandably so. Universities \sphinxstyleemphasis{love} to pay lip service to the importance of interdisciplinarity and are quick to highlight successful interdisciplinary collaborations. But successful interdisciplinary collaborations are so notable precisely because they are the exception, not the rule. The reality is that academic research is starkly divided into disciplinary silos (e.g., computer science, statistics, political science, economics, and engineering). This isn’t because researchers aren’t \sphinxstyleemphasis{interested} in interdisciplinary collaborations, but rather that their professional imperatives push them to focus their attention on the priorities and language of their own departments and disciplines.%
\begin{footnote}[2]\sphinxAtStartFootnote
Nearly all university faculty are hired by established departments like statistics or economics, faculty submit their research to journals specific to their discipline, those journals in turn ask fellow members of the discipline to evaluate their work for publication, and promotions and tenure reviews are managed by the faculty in a faculty member’s own department.
%
\end{footnote}

\sphinxAtStartPar
Thus, while the past several decades have seen an unprecedented emergence of new methods across all of academia, the lack of intellectual cross\sphinxhyphen{}pollination across academic silos has resulted in disciplines failing to take full advantage of discoveries from other disciplines. Over time, each discipline has developed a perspective on computational methods that emphasizes its own intellectual priorities.

\sphinxAtStartPar
To illustrate, suppose we were interested in using patient data to reduce heart attacks. A computer scientist looking at this problem might use their discipline’s methods to \sphinxstyleemphasis{predict} which patients are most likely to experience a heart attack in the future using current patient data; a social scientist might focus on trying to understand the \sphinxstyleemphasis{effect} of giving patients a new drug on heart attack risk; and a statistician might focus on understanding \sphinxstyleemphasis{how confident} we should be in the conclusions reached by the computer scientist and social scientist.

\sphinxAtStartPar
This fragmentation has also resulted in a fragmentation of \sphinxstyleemphasis{language} around data science methodologies. Disciplines often come up with different terminology for the same phenomena, adding another layer of difficulty to efforts to work across departmental silos.

\sphinxAtStartPar
The result is a situation analogous to the Buddhist parable of the blind men and the elephant, wherein a group of blind people come upon an elephant, and upon laying hands on different parts of the elephant, they come to different conclusions about what lies before them. The person touching the tail declares “we have found a rope!”, while the person touching the leg declares “we have found a tree!”

\sphinxAtStartPar
\sphinxincludegraphics{{blindmenelephant}.jpg}

\sphinxAtStartPar
(\sphinxstyleemphasis{Note}: Not sure of original source of this image. \sphinxhref{https://pursuitofresearch.org/2011/01/19/the-blind-men-and-the-elephant/}{Found it here}, but need to figure out rights prior to anything about this becoming commercial! Lots of pics in public domain if needed, but not blindfolded scientists.)

\sphinxAtStartPar
And yet, as the poet John Godfrey Saxe wrote in his poem \sphinxhref{https://en.wikipedia.org/wiki/Blind\_men\_and\_an\_elephant\#John\_Godfrey\_Saxe}{\sphinxstyleemphasis{The Blind Men and the Elephant}} about this parable many centuries later:
\begin{quote}

\sphinxAtStartPar
And so these men of Indostan,
Disputed loud and long,
Each in his own opinion
Exceeding stiff and strong,
Though each was partly in the right,
And all were in the wrong!
\end{quote}

\sphinxAtStartPar
In recent years, however, there has been a growing appreciation of what can be gained from pulling together the insights that have been developed in different fields, despite the challenges of language and professional imperatives to such collaborations. And, at least amongst those who are serious about the development of data science as a discipline and not just a buzzword to use when raising money, is the promise of data science: to unify the different perspectives and methods for analyzing data. Or, to put it more succinctly: to finally see the whole elephant.

\sphinxAtStartPar
While the field is making progress towards “seeing the elephant as a whole,” however, as a result of this fragmented origin story, \sphinxstyleemphasis{most} people you will encounter in the world doing data science were trained in one of these academic silos. That means that depending on who you are working with and how they were trained, you may find your future colleagues using terms you’ve never heard before. And when that happens, it’s important to remember that while that \sphinxstyleemphasis{may} be because they’re talking about a concept you’ve yet to encounter, it may also simply be because they’re using different language for something you know. Similarly, you may also find senior colleagues unfamiliar with concepts that seem basic to you simply because you were exposed to perspectives that were alien to your colleague’s academic silo at the time they were trained. Indeed, given that data science education \sphinxstyleemphasis{is} finally becoming more unified, you should probably expect to learn a lot of ideas that even your more senior colleagues (or rather, especially your more senior colleagues!) were never exposed to.

\sphinxAtStartPar
And therein also lies some of the greatest opportunities. Precisely because of this intellectual fragmentation, there are \sphinxstyleemphasis{lots} of opportunities for taking insights from one intellectual silo and using them to solve problems in another — a kind of “intellectual arbitrage,” if you will.


\section{The Data Analyst / Software Engineering Distinction}
\label{\detokenize{10_introduction/40_data_science_in_historical_context:the-data-analyst-software-engineering-distinction}}
\sphinxAtStartPar
In addition to this broader intellectual fragmentation, the world of data science also often feels oddly fragmented around the way people use the tools of data science.

\sphinxAtStartPar
One model of data science is what we will call the “data analyst” approach. Data scientists doing this type of work often collect data to answer specific questions—what is the effect of expanded government health insurance subsidies on mortality? what type of customer should we target with our new advertising campaign?. As a result, when they write code, they write it to be run against a specific set of data to answer a specific question.

\sphinxAtStartPar
The other model is what we will call the “software engineering” approach. Data scientists doing this type of work write software they plan to \sphinxstyleemphasis{deploy} to thousands or millions of users. This is the type of work that gets embedded in the apps on your phone, or that generates your movie recommendations at Netflix. As a result, when these data scientists write code, they are writing more sophisticated and generalizable programs.

\sphinxAtStartPar
To be clear, most data scientists do at least a bit of both types of work—data analysts may often write small programs or packages to aid in types of analysis they do a lot, and software engineers have to prototype and test new programs before they write a version that can be deployed broadly. But most people will eventually choose to specialize in one direction or another, and when you see data science resources in the world—especially ones about programming for data science—bear in mind that depending on \sphinxstyleemphasis{your} proclivities towards on approach or another, not all resources will be well suited to your interests.

\sphinxAtStartPar
I also want to draw attention to this distinction because it’s remarkable how dismissive most data scientists will be of the “other” type of data science, and I want to encourage you to both (a)not be so tribal yourself (both flavors of data science have their place, and help solve real world problems!), and (b) not be too surprised when you encounter people with irrationally strong opinions about which approach is the “right” approach to doing data science.


\bigskip\hrule\bigskip


\sphinxstepscope


\part{Types of Questions}

\sphinxstepscope


\chapter{Descriptive v. Proscriptive Questions}
\label{\detokenize{30_questions/05_descriptive_v_proscriptive:descriptive-v-proscriptive-questions}}\label{\detokenize{30_questions/05_descriptive_v_proscriptive::doc}}
\sphinxAtStartPar
In the chapters that follow, we will discuss Exploratory, Passive\sphinxhyphen{}Prediction and Causal in detail. First, though, we must discuss another important concept: the distinction between descriptive and prescriptive questions.

\sphinxAtStartPar
\sphinxstyleemphasis{Descriptive Questions} are questions about the state of the world and include all the questions and examples we’ve covered so far in this book. “What kinds of users are clicking our ads?” and “Do high\sphinxhyphen{}income and low\sphinxhyphen{}income countries emit similar amounts of carbon dioxide?” are examples of Descriptive Questions. And because Descriptive Questions are questions about objective reality,%
\begin{footnote}[1]\sphinxAtStartFootnote
If you know enough epistemology to object to me asserting the existence of an “objective reality,” then I assume you can also understand the point I’m trying to get across in this chapter and will forgive me this philosophical slight.
%
\end{footnote} they have right and wrong answers (at least in principle. It may be hard to evaluate whether a given attempt to calculate the answer is actually right or wrong).

\sphinxAtStartPar
But Descriptive Questions are not the only type of question you will come across in your career.

\sphinxAtStartPar
\sphinxstyleemphasis{Proscriptive Questions} are questions about how the world \sphinxstyleemphasis{should be}, not how it actually is. “Should higher income and lower income countries be expected to meet the same carbon emission reduction standards?” or “Do high\sphinxhyphen{}income countries have a moral obligation to provide tuberculosis drugs to developing countries for free (or at cost)?” are both examples of Proscriptive Questions.

\sphinxAtStartPar
Unlike Descriptive Questions, Proscriptive Questions don’t have correct answers. That’s because answers to Proscriptive Questions require evaluating the \sphinxstyleemphasis{desirability} of possible outcomes, which can only be done in the context of a moral/ethical system of values. And as there is no “correct” system of values (in the sense that there is no single universally accepted system of morality), there can be no right or wrong answers to Proscriptive Questions, even in principle.

\sphinxAtStartPar
\sphinxincludegraphics{{question_tree}.png}

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
The terms “Proscriptive” and “Descriptive” are commonly used for these concepts in the natural sciences, but different academic silos sometimes use different terms. Social scientists, for example, tend to prefer the terms “Positive” in place of Descriptive and “Normative” instead of Proscriptive. These are only difference in nomenclature, however, not substantive meaning.
\end{sphinxadmonition}

\sphinxAtStartPar
The focus of this book is on Descriptive Questions. This is not because Proscriptive Questions are unimportant — indeed, one can easily make the argument that they are \sphinxstyleemphasis{more} important than Descriptive Questions. Moreover, as we will discuss in future chapters, they will arise frequently in your career as a data scientist. No, the reason that Descriptive Questions are the focus of this book is that those are the only questions data science tools can answer, and thus answering Descriptive Questions is the domain in which the data scientist has a clear comparative advantage.

\sphinxAtStartPar
Now, to be clear, none of this is to mean that the answers you generate as a data scientist will not have a \sphinxstyleemphasis{bearing} on how people answer Proscriptive Questions. Data science would be a very dull field indeed if it could not speak to the ethical issues of our day. Data science is powerful precisely because it can inform how we answer Proscriptive Questions by helping us understand the relevant stakes. Data science tools can help decision\sphinxhyphen{}makers understand the likely \sphinxstyleemphasis{consequences of different courses of action}, information that can help people make \sphinxstyleemphasis{informed} decisions about what outcomes they feel are most desirable. To illustrate, let’s consider a few vignettes.


\section{Opioid Reductions}
\label{\detokenize{30_questions/05_descriptive_v_proscriptive:opioid-reductions}}
\sphinxAtStartPar
Suppose you have been hired by a medical regulatory board concerned about the rise in opioid overdoses. They are debating whether they \sphinxstyleemphasis{should} (there’s that magic word!) make it harder for patients to get opioids. Fundamentally, however, they worry that while restrictions on opioids may reduce overdoses and addiction, they may also prevent some patients with very real pain conditions from getting the care they need.

\sphinxAtStartPar
Why are they stuck? Well, there may be two causes:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{)}%
\item {} 
\sphinxAtStartPar
They may be unsure of the relative moral weight to give preventing overdoses versus ensuring appropriate patient access to opioids, and/or

\item {} 
\sphinxAtStartPar
they may also be unsure about \sphinxstyleemphasis{how much} opioid regulations that reduce overdoses by a certain amount would limit access for patients in need.

\end{enumerate}

\sphinxAtStartPar
The first of these questions is a pure Proscriptive Question — if you could prevent one overdose death at the expense of preventing 10 patients in pain from getting the opioids they need, would you accept that trade\sphinxhyphen{}off?

\sphinxAtStartPar
But the second is actually a Descriptive Question that you — the data scientist — \sphinxstyleemphasis{can} answer! You could study policies that have been implemented in the past and come up with a rigorous estimate of how much opioid regulations that reduce overdoses also reduce access for patients in need. You could also evaluate different kinds of policies to figure out which is most efficient — maybe some policies (like not allowing any opioid prescriptions at all) are good at stopping overdose deaths but also \sphinxstyleemphasis{really} limit appropriate access, while other policies are similarly good at reducing overdoses but have a much smaller effect on limiting access.


\section{The Example of Carbon Emissions}
\label{\detokenize{30_questions/05_descriptive_v_proscriptive:the-example-of-carbon-emissions}}
\sphinxAtStartPar
A profoundly difficult Proscriptive Question in debates over carbon reduction is whether developing countries should be held to the same emission reduction targets as more developed countries. On the one hand, developing countries like China and India are the source of most current growth in carbon emissions, and so policies that do not apply to developing countries are unlikely to prevent many of the worst climate change outcomes. On the other hand, these countries produce radically less carbon \sphinxstyleemphasis{per capita} than Europe or the United States, and the industrial growth creating those emissions has been a major factor in lifting billions of people out of extreme poverty.

\sphinxAtStartPar
Hard choices indeed! How does one weigh the improvements in the quality of life of those in extreme poverty against the possible consequences of even greater climate catastrophes?

\sphinxAtStartPar
While that question, in part, is a Proscriptive Question that no regression can answer, data scientists \sphinxstyleemphasis{can} bring data to bear on this question indirectly by helping everyone understand the potential consequences of different carbon targets for developing countries, as well as the feasibility of different strategies for carbon reduction. A data scientist could, for example:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Evaluate the effectiveness of different messages politicians in the US and Europe could use to convince their constituents to support greater carbon reduction targets,

\item {} 
\sphinxAtStartPar
Quantify the magnitude of the effect on global warming caused by different emissions targets for developing countries to help politicians in developing countries weigh the poverty\sphinxhyphen{}reducing benefits of carbon\sphinxhyphen{}intensive industrialization against the likely direct effect of flooding, droughts, or more severe storms on their own citizens, or

\item {} 
\sphinxAtStartPar
Estimate the cost\sphinxhyphen{}effectiveness of developed countries sharing lower emissions industrial technologies with developing countries to ameliorate the tradeoff between poverty reduction and emissions.

\end{itemize}

\sphinxAtStartPar
In each of these cases, the data scientist is only answering Descriptive Questions, but in doing so they are helping everyone better understand the consequences of their decisions, and in doing so (hopefully) help the world to make more informed decisions about the trade\sphinxhyphen{}offs they are making.


\section{Recap}
\label{\detokenize{30_questions/05_descriptive_v_proscriptive:recap}}
\sphinxAtStartPar
Answering Descriptive Questions — questions about how the world is or would be in different scenarios — is the core competency of the data scientist. In the chapters that follow, we will explore in detail three different kinds of Descriptive Questions: Exploratory, Passive\sphinxhyphen{}Prediction, and Causal Questions.

\sphinxAtStartPar
While these are the only types of questions that data science tools can answer directly, it is important for you, the data scientist, to also recognize when you encounter Proscriptive Questions — that is, questions about how the world \sphinxstyleemphasis{should} be, or what we \sphinxstyleemphasis{ought} to do. These questions can only be answered with respect to a system of values, and as such, do not have right or wrong answers, and cannot be answered by statistical means. Nevertheless, as a data scientist, you are well\sphinxhyphen{}prepared to help others (and yourself!) make more informed choices when they decide how to answer Proscriptive Questions for themselves.


\bigskip\hrule\bigskip


\sphinxstepscope


\chapter{EDA: The Most Pernicious Term in Data Science}
\label{\detokenize{30_questions/07_eda:eda-the-most-pernicious-term-in-data-science}}\label{\detokenize{30_questions/07_eda::doc}}
\sphinxAtStartPar
In our next reading, we will turn our attention to \sphinxstyleemphasis{Exploratory Questions.} First, however, it is important to have a candid discussion about what I feel is one of the most problematic concepts in data science education: \sphinxstyleemphasis{Exploratory Data Analysis} or \sphinxstyleemphasis{EDA}.

\sphinxAtStartPar
The problem with the term Exploratory Data Analysis is that, if you asked most data scientists what it means, they probably couldn’t actually give you a straight answer. If you pressed them further, they would probably say something like “when you look at your data before you start fitting your models.”

\sphinxAtStartPar
While the idea that data scientists should “get to know their data” before fitting a model is well\sphinxhyphen{}meaning (you \sphinxstyleemphasis{absolutely} should!), the ubiquitous but uncritical use of the term has given young data scientists the sense that the undirected poking at data is worthy of a capitalized three world title, complete with a universally recognized acronym.

\sphinxAtStartPar
This is problematic because \sphinxstyleemphasis{any} activity that involves data but lacks a clear motivation is doomed to be unending and unproductive. Data science has emerged precisely because our datasets are far too complex for us to understand directly; indeed, I would argue that the job of a data scientist can be summed up, in part, as a person who identifies \sphinxstylestrong{meaningful} patterns in our data and makes them comprehensible.

\sphinxAtStartPar
But therein lies the problem — without a clear motivation for \sphinxstyleemphasis{why} the data scientist is poking at their data, what makes a pattern meaningful is undefined. And without a clear purpose from which a concept of meaningfulness can be derived, there is no end to the ways one can slice and dice the data with no way of knowing when to stop or what is useful.

\sphinxAtStartPar
I would argue that what most people call Exploratory Data Analysis (EDA) can actually be decomposed into three activities.

\sphinxAtStartPar
The first activity people call EDA is what I call “learning the structure of your \sphinxstyleemphasis{dataset}” (emphasis on learning about your \sphinxstyleemphasis{dataset}, not using your data to learn about the world). This consists of answering questions about your dataset like “what constitutes a single observation in this dataset?,” “what variables are included in this dataset?,” “how many observations are there?,” “how are variables coded?,” and “what population is represented in this data?” These are questions about \sphinxstyleemphasis{the specific dataset} you are working with, \sphinxstyleemphasis{not} the real world, and answers are likely to be found in the dataset documentation and through basic tools for data introspection.%
\begin{footnote}[1]\sphinxAtStartFootnote
In \sphinxcode{\sphinxupquote{pandas}}, this would be things like \sphinxcode{\sphinxupquote{df.columns}} to see what variables are in the data, \sphinxcode{\sphinxupquote{df.info()}} to get a sense of how data is being represented and the number of rows, and simple tools for tabulating unique values like \sphinxcode{\sphinxupquote{df{[}"first column"{]}.value\_counts()}}.
%
\end{footnote}

\sphinxAtStartPar
The second activity that often falls under the label EDA is what I call “validating your dataset.” It’s a poor data scientist who takes the validity of their data on blind faith, so when faced with a new dataset, one should begin with a few “sanity checks” just to make sure things look reasonable. Does the number of observations seem reasonable given what you know about how the data was collected and who is supposed to be represented in the data? If there are date variables in the data, does their range match what should be in this data? And given the specifics of the data, does the range of variables make sense? For example, if you have data on registered voters 18 and over, you should probably check that the age variable has a minimum value of 18 and a maximum value of something sensible (e.g., not 225).

\sphinxAtStartPar
The third and final activity people call EDA is… everything one does with the data before they fit a statistical or machine learning model. This is the second major reason that I feel the very concept of EDA has had a pernicious influence on data science — it implicitly devalues anything done with data that doesn’t entail a complicated model as “lesser” or “just a stop on the way towards the “real” analysis,” when nothing could be further from the truth.

\sphinxAtStartPar
This type of data analysis — looking at summary statistics, calculating distributions of variables, computing tabulations and cross\sphinxhyphen{}tabulations of different things to improve one’s understanding of the world — is categorically different from “learning the structure of your data,” because it is inquiry in the service of better understanding the world, not the structure of your dataset. But it is \sphinxstyleemphasis{not} categorically different analyzing data using statistical models, not just because in many cases generating cross\sphinxhyphen{}tabulations or calculating group averages are essentially equivalent to using a statistical method like linear regression, but also because they are both examples of the same enterprise: attempting to answer questions about the world using data in the service of solving problems.

\sphinxAtStartPar
And just as one cannot properly fit or tune a model without a clear sense of the question one is seeking to answer and how that answer is meant to be used, nor can one know what cross\sphinxhyphen{}tabulations to compute without having a sense of purpose to make clear what constitutes “meaningfulness.”

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
“But I do EDA all the time without a clear question!” I hear you cry. “Sometimes I just want to see what patterns there are in the data.” To you I say: you may not have realized you had questions in mind, but most of your data explorations have been \sphinxstyleemphasis{implicitly} motivated by a sense of questions you thought might relate to your stakeholder’s problem.

\sphinxAtStartPar
Perhaps you were looking at a store’s retail sales data and decided to see how sales volumes varied by customer age or gender. That may not seem obviously question\sphinxhyphen{}motivated, but I put it to you that you had in mind that those are customer demographics to which the store could target advertising or product stocking decisions. And had someone suggested “why don’t you look at how sales volumes vary by customer birth month or whether their name starts with a letter in the first half of the alphabet,” you would have looked at them funny and said “why on Earth would I do that?”

\sphinxAtStartPar
But the problem with approaching your data with \sphinxstyleemphasis{implicit} motivations is that (a) it’s hard to reflect on them or evaluate whether they rest on solid assumptions about the stakeholder problem, and (b) without an explicit goal, there’s no way to know when you’ve reached your destination, making it \sphinxstyleemphasis{really}  easy to get lost in the data.
\end{sphinxadmonition}


\section{Recap}
\label{\detokenize{30_questions/07_eda:recap}}
\sphinxAtStartPar
Despite its ubiquity, few data scientists could actually tell you what constitutes Exploratory Data Analysis (EDA). Moreover, some of what people might call EDA in practice — answering questions about the world without complex modeling — should not be called EDA, but rather… well, that’s just data science.

\sphinxAtStartPar
So in this book, we will acknowledge the important (but distinct!) goal of two purposeful activities often called EDA:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Learning the structure of your dataset (what constitutes a unit of observation, what variables are in the dataset),

\item {} 
\sphinxAtStartPar
Validating your dataset (does the data pass the sniff test? Does it exhibit the basic properties you would expect given what it claims to be?)

\end{itemize}

\sphinxAtStartPar
But I will \sphinxstyleemphasis{not} use the term EDA itself, and when I differentiate between data science enterprises, I will do so by emphasizing differences in the \sphinxstyleemphasis{end goals} of those activities (answering Exploratory Questions, Passive\sphinxhyphen{}Prediction Questions, or Causal Questions), not the methods used to achieve those ends.


\bigskip\hrule\bigskip


\sphinxstepscope


\chapter{Using Exploratory Questions}
\label{\detokenize{30_questions/10_using_exploratory_questions:using-exploratory-questions}}\label{\detokenize{30_questions/10_using_exploratory_questions::doc}}
\sphinxAtStartPar
The hardest part of a data science project is often properly articulating the problem we wish to solve. That’s because properly specifying a problem requires \sphinxstyleemphasis{understanding} the problem well enough to state it, and often we call issues “problems” precisely because we don’t really understand them!

\sphinxAtStartPar
Enter \sphinxstyleemphasis{Exploratory Questions}. Exploratory Questions are questions designed to elicit information about our problem space and aid us in prioritizing our efforts and refining our goals. Exploratory Questions are questions about broader patterns in the world. In their simplest form, they can be answered by simple summary statistics or plots. When more complicated or related to more subtle and contingent patterns, they are likely to be answered through unsupervised machine learning algorithms or the tools of \sphinxstyleemphasis{statistical inference}, such as regressions and generalized linear models. When used for answering Exploratory Questions, the emphasis of regression or generalized linear models is on what the model coefficients can tell us about how different factors may co\sphinxhyphen{}vary in the world. This is distinct from how these same tools may be used to answer Passive\sphinxhyphen{}Prediction Questions, however, where the emphasis is on the predicted values these models can generate.

\sphinxAtStartPar
Of the three classes of questions we detail in this book, answering Exploratory Questions often (though not always) requires the least technical sophistication, and as a result, Exploratory Questions often get the least respect. But because of their critical role in improving our understanding of our objectives, learning to ask and answer Exploratory Questions will have a huge influence on your effectiveness as a data scientist.

\sphinxAtStartPar
In this reading, we will discuss how to \sphinxstyleemphasis{use} Exploratory Questions to guide your work. Then, in the next reading, we will discuss the challenges inherent to \sphinxstyleemphasis{answering} Exploratory Questions.


\section{Using Exploratory Questions to Prioritize Efforts}
\label{\detokenize{30_questions/10_using_exploratory_questions:using-exploratory-questions-to-prioritize-efforts}}
\sphinxAtStartPar
Exploratory Questions are questions about the underlying patterns that characterize our world. Given that, answers to Exploratory Questions should make you feel like you understand the contours of the problem you seek to solve better. More than anything else, then, Exploratory Questions help data scientists prioritize their subsequent efforts and investigations.


\subsection{Code Optimization}
\label{\detokenize{30_questions/10_using_exploratory_questions:code-optimization}}
\sphinxAtStartPar
If this feels too abstract, let’s use a small example of a problem you’ve probably already come across (and if not, probably should have!) in the classroom to make it more concrete: learning to write performant (i.e., fast) code.

\sphinxAtStartPar
Data science is full of computationally intensive tasks that, if approached incorrectly, can leave a data scientist staring at their computer for hours, days, or even weeks (if they allow it). As a result, most data scientists will go through a phase in their development when they start constantly worrying about how to make every line of code they write as fast as possible. They bend over backward to write unnatural, unreadable code to ensure that they aren’t wasting a single CPU clock cycle.

\sphinxAtStartPar
The problem with this is that humans have \sphinxstyleemphasis{incredibly} bad intuition about what tasks take a computer a long time. It turns out that even in programs that take huge amounts of time to run, it is often the case that \sphinxstyleemphasis{most} of the program’s runtime is taken up by a single function or loop. As a result, programmers who fixate on ensuring every line of code they write is optimized for speed end up not only wasting their \sphinxstyleemphasis{own} time, but also writing code that is less natural, harder to maintain, and more likely to contain errors for effectively no benefit.

\sphinxAtStartPar
Indeed, no less a figure than \sphinxhref{https://en.wikipedia.org/wiki/Donald\_Knuth}{Donald Knuth}, one of the greatest programmers in history and author of the famous \sphinxhref{https://en.wikipedia.org/wiki/The\_Art\_of\_Computer\_Programming}{\sphinxstyleemphasis{The Art of Computer Programming}}, famously said of this trying to optimize each line of code at the time it is being written (“premature optimization”):
\begin{quote}

\sphinxAtStartPar
The real problem is that programmers have spent far too much time worrying about efficiency in the wrong places and at the wrong times; \sphinxstylestrong{premature optimization is the root of all evil (or at least most of it) in programming.} {[}emphasis added{]}
\end{quote}

\sphinxAtStartPar
So what is a programmer interested in performance to do? First, write code in as natural a way as possible. Then, \sphinxstyleemphasis{if} the result is code that is slower than they would like, ask the exploratory question: “What lines of code are contributing most to this program taking so long to run?” And only then, once the programmer has identified the problematic parts of their code, optimize it for performance.

\sphinxAtStartPar
How is this question answered accomplished? Programmers use tools called \sphinxstyleemphasis{profilers} that dip into a running program every few milliseconds to see what functions are currently running. Then after the program has finished running, it reports how often each part of the program code was found to be running, giving the user a sense of the overall distribution of time spent running different parts of the code.


\subsection{Picking the Right Target}
\label{\detokenize{30_questions/10_using_exploratory_questions:picking-the-right-target}}
\sphinxAtStartPar
If the preceding example feels too niche — you want to be a data scientist, after all, not a software engineer! — let’s consider a different example. Suppose you’ve been hired by a new non\sphinxhyphen{}profit interested in helping reduce energy use in buildings in the United States. They know that fixed structures (factors, stores, houses, etc.) are responsible for a huge share of US energy consumption, and are interested in figuring out how to drive down that energy use by helping building owners improve the energy efficiency of their buildings (by providing information on things like government subsidies for efficiency improvements and the potential value of energy efficient windows, better heating and cooling, etc.).

\sphinxAtStartPar
You \sphinxstyleemphasis{could} start out by trying to build a fancy supervised machine learning model that tried to predict the energy use of every building in the US based on infrared satellite data and weather information. Indeed, that may even be what you were asked to do! (See our discussion of how {\hyperref[\detokenize{10_introduction/30_solving_the_right_problem::doc}]{\sphinxcrossref{\DUrole{doc,std,std-doc}{stakeholders will often have somewhat wild ideas of what is feasible and what would help most.}}}}).

\sphinxAtStartPar
But given this is a new non\sphinxhyphen{}profit, it sounds like their real need is probably to figure out how to target their efforts to be most effective. So maybe we should step back and start by trying to answer a few Exploratory Questions that would help the organization decide where to focus its attention:
\begin{itemize}
\item {} 
\sphinxAtStartPar
What \sphinxstyleemphasis{type} of buildings (industrial, residential, commercial) consume the most power in the US?
\begin{itemize}
\item {} 
\sphinxAtStartPar
The answer to this question can help you prioritize the \sphinxstyleemphasis{types} of buildings on which to focus your efforts. For example, if industrial or commercial buildings only represent a few percent of all energy consumed by buildings, you don’t need to worry about addressing their needs!

\end{itemize}

\item {} 
\sphinxAtStartPar
In what \sphinxstyleemphasis{region} of the US are buildings consuming the most power?
\begin{itemize}
\item {} 
\sphinxAtStartPar
If most energy is being consumed in a specific area, perhaps the non\sphinxhyphen{}profit should start by focusing its efforts regionally.

\end{itemize}

\item {} 
\sphinxAtStartPar
Is there a \sphinxstyleemphasis{region} of the US where buildings are generating the most CO2?
\begin{itemize}
\item {} 
\sphinxAtStartPar
Not all power is created equal when it comes to climate change! Maybe buildings in California consume a lot of energy, but because they have cleaner power plants, those buildings are indirectly generating less CO2 than those in states in the US South?

\end{itemize}

\item {} 
\sphinxAtStartPar
Does the \sphinxstyleemphasis{average energy use per building} vary by region or building type?
\begin{itemize}
\item {} 
\sphinxAtStartPar
If the non\sphinxhyphen{}profit plans to approach building owners, it may be easier to have an impact working with a few owners of large buildings than lots of residential homeowners. But of course, that also depends on the answer to our previous question about what types of buildings are using the most power/generating the most CO2!

\end{itemize}

\item {} 
\sphinxAtStartPar
In what season is most building energy consumed? Is more energy consumed by heating or AC needs, or do the two use similar amounts of power?
\begin{itemize}
\item {} 
\sphinxAtStartPar
Again, this may impact both the regions the non\sphinxhyphen{}profit may wish to focus on, and also the types of efficiency retrofits they may wish to prioritize.

\end{itemize}

\item {} 
\sphinxAtStartPar
Where is power most expensive?
\begin{itemize}
\item {} 
\sphinxAtStartPar
Building owners are most likely to be interested in efficiency retrofits when power is expensive.

\end{itemize}

\end{itemize}

\sphinxAtStartPar
While answering these questions is likely to require some significant detective work, and may require some thoughtful data wrangling, none require deeply sophisticated statistical machinery. But that doesn’t mean answering these questions wouldn’t provide \sphinxstylestrong{huge} value to the stakeholder.


\subsection{Collecting, Merging, and Creating New Data}
\label{\detokenize{30_questions/10_using_exploratory_questions:collecting-merging-and-creating-new-data}}
\sphinxAtStartPar
Once you start articulating these questions, you can start to see that there is some important data science to do; that’s because the answers to these questions may not all point in the same direction, and so the non\sphinxhyphen{}profit likely needs someone to be able to evaluate how these different factors co\sphinxhyphen{}vary, and the relative magnitude of different trade\sphinxhyphen{}offs (e.g., if fewer buildings use a lot of power in the US South than California, but the US South is using coal power instead of renewable energy, where should the non\sphinxhyphen{}profit focus?).

\sphinxAtStartPar
And that, fundamentally, is what Exploratory Questions are about: understanding the patterns and distribution of features you care about in the world, and using that information to better understand the problem you want to solve.

\sphinxAtStartPar
This also demonstrates one of the key ways that one answers Exploratory Questions: by collecting and merging datasets that had not previously been pulled together. Sometimes this data collection requires no more than finding people who already have the data you need, getting it, and finding a way to merge different data sources (e.g., data on power plant CO2 emissions and data on building energy use), while in other situations this will entail building new datasets yourself by doing things like using Natural Language Processing to make collections of documents (contracts, patient files, public records) analyzable systematically.

\sphinxstepscope


\chapter{Answering Exploratory Questions}
\label{\detokenize{30_questions/15_answering_exploratory_questions:answering-exploratory-questions}}\label{\detokenize{30_questions/15_answering_exploratory_questions::doc}}
\sphinxAtStartPar
In the last reading, we discussed how Exploratory Questions are used by data scientists to help stakeholders better understand their problems and to prioritize subsequent investigations. In this reading, we turn to the questions of what \sphinxstyleemphasis{answering} Exploratory Questions effectively entails.


\section{The Three\sphinxhyphen{}Part Goal}
\label{\detokenize{30_questions/15_answering_exploratory_questions:the-three-part-goal}}
\sphinxAtStartPar
Whether one uses simple summary statistics (means and medians), plots, or more sophisticated algorithms from the domains of statistical inference and unsupervised machine learning, answering Exploratory Questions always boils down to the same challenge:

\sphinxAtStartPar
\sphinxstylestrong{Creating (1) understandable summarizations (2) of meaningful patterns in the data, (3) and ensuring they are faithful representations of the data.}

\sphinxAtStartPar
What is meant by these three components exactly? Let’s take each in turn.


\subsection{Understandable Summarizations}
\label{\detokenize{30_questions/15_answering_exploratory_questions:understandable-summarizations}}\begin{quote}

\sphinxAtStartPar
Creating \sphinxstylestrong{(1) understandable summarizations} (2) of meaningful patterns in the data, (3) and ensuring they are faithful representations of the data.
\end{quote}

\sphinxAtStartPar
Answering Exploratory Questions effectively is all about taking large datasets that, in their raw form, are effectively incomprehensible to humans and summarizing the patterns in that data in a way that can be understood. These summaries of patterns in the data may take many forms — summary statistics, regression coefficients, plots, etc. — but all, when done well, have a similar goal: to represent the salient aspects of data in a way that is accessible to the human mind.

\sphinxAtStartPar
Professionals from different disciplines often use different terminology to describe this process of summarization. Some like to refer to it as “separating the signal (the thing that’s important) from the noise (all the other variation that doesn’t matter),” others talk about “dimensionality reduction” (basically linear algebra speak for summarization), while still others may talk about “modeling the underlying data generating process that gave rise to the observed data.” Regardless of the terminology one uses, however, these all boil down to the same thing: filtering and discarding the variation the data scientist deems to be irrelevant to make it easier to see and understand the variation deemed important.

\sphinxAtStartPar
The importance of researcher discretion in deciding what variation to discard as noise and what variation to foreground as “important” is one of the defining challenges of answering Exploratory Questions. Other types of questions — like Passive Prediction Questions — often involve using more mathematically sophisticated modeling tools, and consequently are viewed as more challenging. In my experience, however, learning to understand the stakeholder’s problem context \sphinxstyleemphasis{and} the variation in a data set well enough to exercise this discretion effectively is actually one of the things young data scientists struggle with most. It requires both good domain knowledge to understand what is \sphinxstyleemphasis{meaningful} (as we will discuss below), and also for the data scientist to spend a lot of time exploring the data thoughtfully and from different perspectives. This is a hard skill to learn,%
\begin{footnote}[1]\sphinxAtStartFootnote
Although I am far from convinced that the discipline has tried particularly hard to teach it ({\hyperref[\detokenize{30_questions/07_eda::doc}]{\sphinxcrossref{\DUrole{doc,std,std-doc}{see my screed against “EDA”}}}}).
%
\end{footnote} but with intentionality, patience, and practice, it is a talent that once learned will helps set you apart from the average pytorch\sphinxhyphen{}jockey.

\sphinxAtStartPar
Summarizations created to answer Exploratory Questions can differ radically in their ambition. At one end of the spectrum are simple summary statistics, like means, median, and standard deviations. These seek to provide a simple characterization of a single feature of a single variable. Slightly more ambitious are various forms of plots — like histograms (which are substantially richer than the aforementioned summary statistics) or scatter plots and heatmaps (which provide substantial granularity and communicate information about the relationship between different variables). The most ambitious efforts make use of multivariate regressions and unsupervised machine learning algorithms to model what they call the \sphinxstyleemphasis{Data Generating Process} (DGP) — the actual physical or social processes that gave rise to the data you observe, and which (hopefully) can be represented in a relatively parsimonious manner, much as the relatively simple laws of physics give rise to the orbits of the planets and the complexity of life.

\sphinxAtStartPar
To illustrate what I mean by trying to deduce something about the data\sphinxhyphen{}generating process, suppose you are a medical researcher interested in a poorly understood disease like Chronic Fatigue Syndrome (CFS). It is generally agreed that CFS is more of a label for a constellation of symptoms than an understood physical ailment, and you have a hypothesis that the symptoms of CFS aren’t actually caused by a single biological dysfunction, but rather that multiple distinct biological dysfunctions give rise to similar symptoms that we have mistakenly grouped under this same umbrella term. In other words, you think that the data\sphinxhyphen{}generating process that gives rise to patients diagnosed with Chronic Fatigue Syndrome consists of two distinct diseases.

\sphinxAtStartPar
You’re fortunate enough to have detailed patient data on people diagnosed with the condition, but it’s impossible for you to just look at these gigabytes of thousands of patient records and “see” any meaningful patterns. You need a way to filter out irrelevant data to identify the “signal” of these two conditions. To aid you in this question, you decide to ask “If you were to group patients into two groups so that the patients in each cluster looked as similar as possible, but patients in different clusters looked as \sphinxstyleemphasis{dissimilar} as possible, how would you group these patients?”

\sphinxAtStartPar
This, you may recognize, is precisely the question clustering algorithms (a kind of unsupervised machine learning algorithm) are designed to answer! So you apply your clustering algorithm to the patient data and get back a partition of the patients into two distinct groups. This, in and of itself, doesn’t constitute a particularly \sphinxstyleemphasis{understandable} summarization of your data, but it provides a starting point for trying to investigate \sphinxstyleemphasis{diagnostically and biologically relevant} differences that exist between these populations. If one cluster included more patients reporting fatigue when doing any exercise, while another cluster reported they felt better when they exercised, but felt a high level of baseline fatigue that didn’t respond to sleep, that might suggest that the \sphinxstyleemphasis{data\sphinxhyphen{}generating process} for these patients was actually driven by two different biological processes. \sphinxstyleemphasis{And} it gives you a great starting point to prioritize your subsequent investigations into what might explain these differences!


\subsection{Meaningful Patterns}
\label{\detokenize{30_questions/15_answering_exploratory_questions:meaningful-patterns}}\begin{quote}

\sphinxAtStartPar
Creating (1) understandable summarizations \sphinxstylestrong{(2) of meaningful patterns in the data,} (3) and ensuring they are faithful representations of the data.
\end{quote}

\sphinxAtStartPar
Inherent in creating any summarization is exercising discretion over what variation is relevant (signal) and what variation is not (noise). But just as one person’s trash may be another person’s treasure, so too may one person’s signal be another person’s noise, depending on their goals! Crucially, then, the data scientists’ guiding star when deciding what is important is whether certain variation in the data is \sphinxstyleemphasis{meaningful to the stakeholder’s problem}.

\sphinxAtStartPar
As data scientists, we are blessed with an abundance of tools for characterizing different facets of our data. These range from the simple — means, standard deviations, and scatter plots — to the profoundly sophisticated, like clustering algorithms, principal component analyses, and semi\sphinxhyphen{}parametric generalized additive models.

\sphinxAtStartPar
Regardless of the specific methods being employed, however, none of these tools can really tell us whether the patterns they identify are meaningful, and that’s because what constitutes a meaningful pattern depends on the problem the stakeholder is seeking to address and the context in which they’re operating.

\sphinxAtStartPar
To illustrate the importance of context, suppose you are hired by a hospital to learn what can be done to reduce antibiotic\sphinxhyphen{}resistant infections. So you grab data on the various bacteria that had been infecting patients and write a web scraper and Natural Language Processing pipeline to systematically summarize all available research on the cause of these antibiotic\sphinxhyphen{}resistant bacteria. Your work is \sphinxstyleemphasis{amazing}, seriously top of the line, and after two months you conclude that in most cases, the cause of antibiotic resistance in the bacteria infecting patients is… the use of antibiotics in livestock.

\sphinxAtStartPar
Now, that analysis may not be \sphinxstyleemphasis{wrong} — you have properly characterized a pattern in the data — but it isn’t a pattern that’s meaningful to your stakeholder, who has no ability to regulate the livestock industry. That pattern might be meaningful to someone else — like a government regulator — but in this context, with this stakeholder, it just isn’t helpful. The features of the data that are important, in other words, depend on what we may be able to do in response to what we learn. And there’s no summary statistic, information criterion, or divergence metric that can evaluate whether a pattern of this type is \sphinxstyleemphasis{meaningful}.


\subsection{Faithful Representations}
\label{\detokenize{30_questions/15_answering_exploratory_questions:faithful-representations}}\begin{quote}

\sphinxAtStartPar
Creating (1) understandable summarizations (2) of meaningful patterns in the data, \sphinxstylestrong{(3) and ensuring they are faithful representations of the data.}
\end{quote}

\sphinxAtStartPar
What do you means, medians, standard deviations, linear regressions, logistic regressions, generalized additive models (GAMs), singular value decomposition (SVD), principal component analyses (PCAs), clustering algorithms, and anomaly detection algorithms all have in common?

\sphinxAtStartPar
Answer: unless your dataset is extremely degenerate, you can point \sphinxstyleemphasis{any} of these tools at your data and they will return a relatively easy\sphinxhyphen{}to\sphinxhyphen{}understand characterization of the structure of your data.

\sphinxAtStartPar
At first, that may seem extremely exciting. But if you think about it a little longer you will realize the problem: all of these are designed to give you a relatively understandable summary of radically different properties of your data, and even though they will all provide you with a result, these results can’t all possibly be faithful representations of the dominant patterns in your data.

\sphinxAtStartPar
To illustrate the point, suppose I told you that in one university math course, the average grade was a B\sphinxhyphen{}. You might infer that students were doing pretty well! But now suppose I told you that in a different university math course, 20\% of the students had gotten a 0 on the midterm and on the final—you would probably infer something was going seriously wrong in that class. And yet those two statistics could both be true of the same class—the only difference is what patterns in the data \sphinxstyleemphasis{I}, the data scientist, have decided are meaningful to communicate to you, the reader.

\sphinxAtStartPar
The example of the math class in which the average grade was a B\sphinxhyphen{} and 20\% of the students were failing also illustrates one of the great dangers of tools for data summarization: they are so eager to please, they will \sphinxstyleemphasis{always} provide you with an answer, whether that answer is meaningful or not. I think most readers would agree that learning that the average grade in the class was a B\sphinxhyphen{} actually misleads more than it informs (since for the class to have an average grade of 80\% and a 20\% fail rate, the grade distribution would need to be something like 20\% 0’s and 80\% 100’s). Indeed, it’s worth emphasizing that while hearing “the average grade is a B\sphinxhyphen{}” makes the reader think that most kids are doing ok\sphinxhyphen{}ish, the reality is that \sphinxstyleemphasis{no one} in the class is doing ok\sphinxhyphen{}ish! They’re either doing horribly or terrifically!

\sphinxAtStartPar
Less that feel like a contrived example, consider the case of Aimovig, a drug authorized by the FDA in 2018 for treating chronic migraines that was heralded as a “game changer.”

\sphinxAtStartPar
To get Aimovig authorized, the pharmaceutical companies developing (Amgen and Novartis) had to run a clinical trial in which a random sample of people with chronic migraines was given Aimovig (the treatment group) and a random sample was a placebo (the control group). Patients in the clinical trial self\sphinxhyphen{}reported how their migraine frequency changed when in the trial, and the effectiveness of Aimovig was then evaluated by comparing the decrease in self\sphinxhyphen{}reported migraines for those taking Aimovig (on average, a decrease of 6\sphinxhyphen{}7 migraines a month) to the decrease in self\sphinxhyphen{}reported migraines for those taking a placebo (on average, a decrease of 4 migraines a month).%
\begin{footnote}[2]\sphinxAtStartFootnote
A placebo is a “fake” treatment given to patients in clinical trials. Despite not being biologically active — placebos are often simple saline or sugar pills — most patients on placebos see their condition improve when dealing with subjective conditions, like pain.
%
\end{footnote} This difference of 2\sphinxhyphen{}3 migraines a month — called the “Average Treatment Effect” of the trial — was found to be positive and statistically significant, and so the drug was authorized. Indeed, if you see an ad for Aimovig, you’ll probably see the average effect of the drug reported in the same way:

\sphinxAtStartPar
\sphinxincludegraphics{{migraine_average_effect}.png}

\sphinxAtStartPar
That’s great! Chronic migraines can be a crippling disability, so any improvement in treatment is exciting. But you would be excused for asking why people were getting \sphinxstyleemphasis{so} excited about what seems like a relatively small reduction in migraines.

\sphinxAtStartPar
The answer, as it turns out, is that almost nobody experiences this “average effect.” Instead, \sphinxstyleemphasis{most} people who take Aimovig see little to no benefit, but \sphinxstyleemphasis{some} (depending on your criteria, something like 40\%) see their migraine frequency fall by 50\% or more. Amgen and Novartis don’t yet know how to identify who will benefit and who will not before they try the drug, and we don’t allow drug companies to “move the goalposts” after a clinical trial has already started by changing the way they plan to measure the effectiveness of a drug (for fear they will hunt through the data till they find a spurious correlation that makes it look like the drug works when it really doesn’t), so this average effect remains the only statistic that Amgen and Novartis are allowed to report in their advertising.

\sphinxAtStartPar
But if you’re a \sphinxstyleemphasis{doctor} or a \sphinxstyleemphasis{patient}, it seems clear that this simple average effect — a reduction of 2\sphinxhyphen{}3 migraines a month — really does not provide a \sphinxstyleemphasis{faithful} summary of the underlying variation.


\subsection{But… I Thought Unsupervised Machine Learning Always Found The “Best”}
\label{\detokenize{30_questions/15_answering_exploratory_questions:but-i-thought-unsupervised-machine-learning-always-found-the-best}}
\sphinxAtStartPar
“Fine,” I hear you say, “that makes sense for simple summary statistics. Those are computed by simple formulas. But what about unsupervised machine learning algorithms or generalized additive models? Those use numerical optimization to find the \sphinxstyleemphasis{best} answer!”

\sphinxAtStartPar
Well… yes and no. As you may recall, in the first chapter of the book I posited that all data science algorithms are just fancy tools for answering questions, and even the most sophisticated unsupervised machine learning algorithms are no exception. While it is true that the machinery that underlies these algorithms is much more sophisticated than the formula we use for calculating a variable’s average, it is important to not attribute too much intelligence to these tools.

\sphinxAtStartPar
Underlying any unsupervised machine learning algorithm is a simple formula that takes as input whatever parameters the algorithm gets to choose (be those factor loads in a PCA model, or the assignment of observations to clusters in a clustering algorithm) and returns as output a single number. Often this number is called “loss,” and the function is called a “loss function,” but occasionally different terminology will be used.

\sphinxAtStartPar
One way to think of the job of an unsupervised machine learning algorithm is to pick the parameter values that minimize this loss function. A clustering algorithm for example, may try and assign observations to clusters to maximize the similarity of observations within a cluster (say, by minimizing the sum of squared differences between the values of certain variables for all observations within a cluster) while also maximizing the differences between observations in different clusters (say, by maximizing the sum of squared differences between the values of certain variables for all observations \sphinxstyleemphasis{not} in the same cluster).

\sphinxAtStartPar
But another way to say that is that the job of an unsupervised machine learning algorithm (or any algorithm, really) is to find the parameter values (coefficients in a regression, observation assignments for a clustering algorithm) that answer the question “If my goal is to minimize {[}whatever the loss function your specific algorithm seeks to minimize{]}, how should I do it?” But while they are likely to find the best way to accomplish that goal given the parameters they control, they will do so \sphinxstyleemphasis{whether or not the “best” solution is actually a “good” solution!} Point a clustering algorithm at any data and ask it to split the data into 3 clusters, and it will pick the best way to split the data into three clusters, even if the three clusters are \sphinxstyleemphasis{almost} indistinguishable. In other words, clustering algorithms assign observations to clusters… even when there’s no real clustering of the data! Dimensionality reduction algorithms will always tell you a way to drop dimensions, and anomaly detection algorithms will always find (relative) outliers.

\sphinxAtStartPar
Moreover, just because your clustering algorithm finds what it thinks is the best solution doesn’t mean there isn’t a \sphinxstyleemphasis{substantively} very different solution that was \sphinxstyleemphasis{just} a little less good it hasn’t told you about.

\sphinxAtStartPar
It’s up to you, the data scientist, to evaluate whether the answers these algorithms provide to relatively myopic questions give a meaningful picture of the data.


\subsection{Myopic Tools}
\label{\detokenize{30_questions/15_answering_exploratory_questions:myopic-tools}}
\sphinxAtStartPar
This last point is illustrative of a more general point: data science tools are incredibly powerful at finding answers to questions of the form “If my goal is to minimize X, how should I do it?” type questions — answers you may have never figured out in millions of years! — but their power lies in figuring out the best way to accomplish an articulated goal, \sphinxstyleemphasis{not} in figuring out what goal to pursue.

\sphinxAtStartPar
This is true at both the macro level (doesn’t make sense to look for clusters in my data?) and also at the micro level (when assigning observations to clusters, how do I measure success?). Hidden inside nearly all algorithms you use are a handful of baked\sphinxhyphen{}in choices you may not even realize are being made for you. Take clustering, for example. In general, when clustering observations, one has two objectives: maximize the similarity of observations within each cluster and maximize the \sphinxstyleemphasis{dis}similarity of observations in different clusters. But what you might not have thought about very much is that there’s an inherent tension between these two objectives — after all, the best way to maximize the similarity of observations within each cluster is to only assign observations to the same cluster if they are identical (a choice that creates lots and lots of very small clusters). And the best way to maximize \sphinxstyleemphasis{dis}similarity between clusters is to only put \sphinxstyleemphasis{really really} different observations in different clusters (resulting in a few really big clusters). So how is your clustering algorithm balancing these two considerations? Is the algorithm’s choice of how to balance them in any way a reflection of the balance that makes the most sense in the context of your stakeholder’s problem? (I’ll give you a hint — the algorithm sure can’t answer that question, so you’d better be able to!)

\sphinxAtStartPar
Discretion: it’s everywhere, and you’re exercising it, whether you realize it or not.
















\bigskip\hrule\bigskip


\sphinxstepscope


\chapter{Internal versus External Validity}
\label{\detokenize{30_questions/17_exploratory_questions_internal_external:internal-versus-external-validity}}\label{\detokenize{30_questions/17_exploratory_questions_internal_external::doc}}
\sphinxAtStartPar
It is at this point I have to come clean about having employed a… small indirection. At the top of this reading, I introduced the idea that answering Exploratory Questions boiled down to creating (1) understandable summarizations (2) of meaningful patterns, and (3) ensuring those summaries faithful represent the data. But that three\sphinxhyphen{}part objective is actually only one\sphinxhyphen{}half of answering an Exploratory Question. More specifically, those are the three components of ensuring high \sphinxstyleemphasis{internal validity} when answering an Exploratory Question. But to generate a truly useful answer to an Exploratory Question, your analysis must also have high \sphinxstyleemphasis{external validity}.

\sphinxAtStartPar
Essentially, \sphinxstyleemphasis{internal validity} is a measure of how well you have analyzed \sphinxstyleemphasis{the data you have}, while \sphinxstyleemphasis{external validity} is how well you expect the answer you generated from that data to generalize to your stakeholder’s context. Internal and external validity arise when answering \sphinxstyleemphasis{any} data science question, and so these two concepts are ones that we will return to time and again in this book.


\section{Interval v. External Validity: An Example}
\label{\detokenize{30_questions/17_exploratory_questions_internal_external:interval-v-external-validity-an-example}}
\sphinxAtStartPar
To illustrate what is meant by these terms, suppose you’ve been hired by a specialty grocery chain interested in opening new stores. They have a good sense of their customer base ()

\sphinxAtStartPar
To illustrate the difference, suppose a new video streaming service sent out an e\sphinxhyphen{}mail offering new users a deal on subscriptions, and then measured the difference in sign\sphinxhyphen{}up rates between the users who got the deal and users who just got a generic e\sphinxhyphen{}mail with information about the service.

\sphinxAtStartPar
The \sphinxstylestrong{internal validity} of the study is the degree to which the study accurately measured the causal effect of the offer on signup rates. Internal validity hinges on things we’ve talked about a lot in class, like whether the people who received the deal had the same potential outcomes as the people who got the generic email.

\sphinxAtStartPar
The \sphinxstylestrong{external validity} of the study, by contrast, is about whether we think the estimated effect is the same effect we would see if we tried to send out a similar email to recruit customers to an \sphinxstyleemphasis{established} streaming service (instead of a new one), or if we tried to use a similar offer to recruit people to a new \sphinxstyleemphasis{music} streaming service.

\sphinxAtStartPar
All studies are subject to both types of concerns, and as we’ll discuss below, there are often trade\sphinxhyphen{}offs between internal and external validity, especially in causal research.


\section{External Validity}
\label{\detokenize{30_questions/17_exploratory_questions_internal_external:external-validity}}
\sphinxAtStartPar
External validity is fundamentally about the \sphinxstyleemphasis{generalizability} of a study: whether the causal estimate found in a study is likely to also be a good guess for the causal effect in a different context.

\sphinxAtStartPar
External validity is one of the most important things to think about as a \sphinxstyleemphasis{consumer} of other people’s research, because when you read other people’s research, you’re usually doing so because you’re looking for information you can use to address a specific problem you face. In these situations, it’s critical that you always ask yourself: are the results from this study likely to also be valid in the context of my problem?

\sphinxAtStartPar
Of course, when asking about the external validity of a study, we have to specify the setting to which we want to generalize its results. A study that looks at how Duke undergraduates’ consumer behavior changes when faced with different types of ads on google may have good external validity in terms of its generalizability to other elite Univerities like Emory, Vanderbilt, or UNC. But it might not generalize to the US population as a whole.

\sphinxAtStartPar
This means that external validity is different from internal validity in an important way: when faced with the same facts about a study, everyone should \sphinxstyleemphasis{generally} agree on the internal validity of a study, but the external validity of a study really depends on how you want to use the results.


\subsection{External Validity Considerations}
\label{\detokenize{30_questions/17_exploratory_questions_internal_external:external-validity-considerations}}
\sphinxAtStartPar
There are many reasons that the results of a study may not generalize to a new context. Here are a handful of the most common issues to bear in mind:

\sphinxAtStartPar
\sphinxstylestrong{The study population may be different from the population in the new context.}

\sphinxAtStartPar
Almost by definition, the entities in the new context will be different from the entities in the original study (even if we’re working with the same people, we’re looking at them at a different time). But the key question for external validity is whether the entities in the new context are different \sphinxstyleemphasis{in a way that would impact their response to a given treatment}.

\sphinxAtStartPar
It’s not hard to think of reasons that different populations may respond differently to a given treatment. For example, suppose a company finds ads for luxury cars increase sales among rich people in New York. It’s hard to imagine that the same ad run in a poor neighborhood in Detroit would have the same effect.

\sphinxAtStartPar
As you think about population differences, make sure you consider not only standard demographic attributes (age, gender, wealth, education), but also cultural or social differences. Many issues businesses deal with – especially advertising and brand image – may be culturally specific, and so may not generalize to all communities.

\sphinxAtStartPar
This may all seem obvious as you read it, but using unrepresentative samples in research and medicine, then making recommendations for the general public is a huge problem in the real world.

\sphinxAtStartPar
White men are massively over\sphinxhyphen{}represented in \sphinxhref{https://www.theatlantic.com/health/archive/2016/06/why-are-health-studies-so-white/487046/}{medical trials}, for example. Unsurprisingly, this means that when the results of those trials are generalized to the population as a whole, we suddenly discover (SURPRISE) that the predicted results didn’t always hold for women or people of color! (e.g. \sphinxhref{https://www.theguardian.com/lifeandstyle/2015/apr/30/fda-clinical-trials-gender-gap-epa-nih-institute-of-medicine-cardiovascular-disease}{drug doses set for men are often too high for women}; some heart drugs work great for White men, \sphinxhref{https://www.vice.com/en/article/mbjjnp/medical-studies-still-exclude-people-of-color}{but often interact poorly with a gene common in Asians and Pacific Islanders; and Multiple sclerosis turns out to be drive by a different mutation in Black patients than European descendants}).

\sphinxAtStartPar
And for the longest time, psychology research was based almost entirely on studies conducted using student volunteers. But of course, students at elite universities are not a representative population – they’re disproportionately Western, Educated, from Industrialized, Rich, and Democratic countries (they’re WEIRD). And as a result, our academic model of human behavior is really just a \sphinxhref{https://slate.com/technology/2013/05/weird-psychology-social-science-researchers-rely-too-much-on-western-college-students.html}{model of a bunch of WEIRD kids}.

\sphinxAtStartPar
Unrepresentative training data is also one of the reasons that so many machine learning algorithms are just plain racist (this isn’t causal inference, but it’s the same idea) – if you train a facial recognition algorithm using predominantly white faces, turns out that they will either \sphinxhref{http://www.cnn.com/2009/TECH/12/22/hp.webcams/index.html}{not see Black faces}, or worse, mis\sphinxhyphen{}identify people of color (which is a \sphinxhref{https://www.wired.com/story/best-algorithms-struggle-recognize-black-faces-equally/}{really bad thing when those algorithms are being used by the police}).

\sphinxAtStartPar
So while internal validity issues may seem more sophisticated and thus interesting, don’t overlook the importance of these kinds of external validity issues!

\sphinxAtStartPar
\sphinxstylestrong{The treatment might differ between study and new context}

\sphinxAtStartPar
A study may declare that it has measured the effect of billboard ads on sales, or an infinite scroll on engagement. But it’s always important to remember that while we may interprete studies in these general terms, the reality is that that billboard study probably measured the effect \sphinxstyleemphasis{of a specific set of billboard ads} on sales, and the infinite scroll study looked at the effect of infinite scroll \sphinxstyleemphasis{in a specific app}.

\sphinxAtStartPar
So always be careful to think about what \sphinxstyleemphasis{exactly} the treatment in a study was, and whether its likely to generalize to the case you study about.

\sphinxAtStartPar
\sphinxstylestrong{There may be scaling effects}

\sphinxAtStartPar
Often times when we’re thinking about external validity, we’re not just thinking re\sphinxhyphen{}using a treatment or intervention; we’re thinking about scaling them up.

\sphinxAtStartPar
But an intervention that works on a few people / is only in place for a short period may not be a perfect model for what happens when that same intervention is applied at scale or permanently. For example, the returns to showing people a TV ad about your company for the first time is probably not the same as the returns to airing that ad the 1,000,000th time. Or sales from selling a special product at one store for a limited time may not be a good indicator of the sales you would see if your “special product” were available everywhere all the time.

\sphinxAtStartPar
People may also respond differently to an intervention when it gets big or becomes permanent. To illustrate, I’d like to tell a story about a famous experiment in India (\sphinxhref{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2826809/}{paper}).

\sphinxAtStartPar
Rural health clinics in India have a huge problem: nurse absenteeism. To try and address the problem, in the late 2000s an NGO (along with some MIT economists) decided to see if they could fix the problem. The NGO started keeping track of when nurses clocked in and out, and then shared the information with the government, who then applied fines or punishments to nurses who weren’t showing up for work.

\sphinxAtStartPar
Initially, the intervention was successful, leading to very large increases in attendance (doubling it in fact!) after a few months. But as nurses came to realize this wasn’t just a little study but actually something that was going to be around for a while, they mobilized politically, and soon administrators were allowing nurses to claim an increasing number of “exempt days”, avoiding punishment. And so sure enough, nurses stopped coming to work, and absenteeism had returned to pre\sphinxhyphen{}intervention levels 16 months after the program began.

\sphinxAtStartPar
This is an example of what economists call a “general equilibrium” effect – when we introduce a treatment to the world, the world responds. But often these responses don’t happen in small trials the same way they do when policies go big, creating serious generalizability problems.

\sphinxAtStartPar
Relatedly: if you are a public policy person or an economic development person, I cannot recommend \sphinxhref{https://www.nber.org/papers/w22595}{this paper} by Angus Deaton and Nancy Cartwright enough for discussing the limitations of RCTs for learning about the effects of policy or nature of social processes. It’s a long, very thoughtful paper, but it’s really, \sphinxstyleemphasis{really} good.

\sphinxstepscope


\chapter{Passive\sphinxhyphen{}Prediction Questions}
\label{\detokenize{30_questions/20_passive_prediction_questions:passive-prediction-questions}}\label{\detokenize{30_questions/20_passive_prediction_questions::doc}}
\sphinxAtStartPar
When most people hear the term “machine learning,” what they think of is the ability of computers to answer Passive\sphinxhyphen{}Prediction Questions: “which patients are likely to experience complications from surgery if we don’t do anything?”, “which people applying for life insurance are healthy enough we should issue them a policy?”, or “which job applicants would make good employees (and thus, which job applicants should we interview)?” And indeed, the ability of data scientists to answer Passive\sphinxhyphen{}Prediction Questions is one of our most useful skills.

\sphinxAtStartPar
However, answering this type of question is also one of the easiest ways to get in trouble as a data scientist. Why? Just as you can always calculate a summary statistic or get a result from an unsupervised machine learning model when trying to answer an Exploratory Question, you can also always get predicted values from a statistical model. But with Passive\sphinxhyphen{}Prediction Questions—\sphinxstyleemphasis{unlike} with Exploratory Questions—you can’t fully check the validity of your answer to a Passive\sphinxhyphen{}Prediction Question with data you currently have. That’s because, \sphinxstyleemphasis{by definition}, the reason you are trying to answer a Passive\sphinxhyphen{}Prediction Question is that you want to predict something that you don’t currently know!


\section{Flavors of Passive\sphinxhyphen{}Prediction Questions}
\label{\detokenize{30_questions/20_passive_prediction_questions:flavors-of-passive-prediction-questions}}
\sphinxAtStartPar
There are two flavors of Passive\sphinxhyphen{}Prediction Questions:
\begin{itemize}
\item {} 
\sphinxAtStartPar
predicting something that has yet to occur (“which patients going in for surgery are likely, in the future, to experience complications?”), and

\item {} 
\sphinxAtStartPar
predicting something that \sphinxstyleemphasis{could} occur but actually won’t (“if a radiologist had looked at this mammogram, would they conclude the patient had cancer?”).

\end{itemize}

\sphinxAtStartPar
The first category of passive prediction—predicting something that has yet to occur—is the most intuitive, and is the type of passive prediction that accords best with the normal meaning of the term “predict.” But the second favor of passive prediction—in which we try and predict what someone \sphinxstyleemphasis{would} do—is also very important, as it underlies efforts at automation. Spam detection, image classification, autocomplete, and self\sphinxhyphen{}driving cars are all examples of situations where we train a model by showing it examples of how a person \sphinxstyleemphasis{would} do something, so the model can predict what a person would do when faced with new data and emulate that behavior itself.

\sphinxAtStartPar
And just as there are two flavors of passive\sphinxhyphen{}prediction, so too are there two corresponding use cases for answering Passive\sphinxhyphen{}Prediction Questions:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Identifying individual entities for follow\sphinxhyphen{}up, and

\item {} 
\sphinxAtStartPar
Automating data classification to make hard\sphinxhyphen{}to\sphinxhyphen{}work\sphinxhyphen{}with data (images, medical scans, text) simpler

\end{itemize}


\section{Differentiating Between Exploratory and Passive\sphinxhyphen{}Prediction Questions}
\label{\detokenize{30_questions/20_passive_prediction_questions:differentiating-between-exploratory-and-passive-prediction-questions}}
\sphinxAtStartPar
If you have not felt a little confused about the distinction between Exploratory and Passive\sphinxhyphen{}Prediction Questions previously, there’s a good chance you find yourself struggling with that issue here, and for understandable reasons.

\sphinxAtStartPar
In many cases, one can easily imagine how the same analysis might constitute an answer to \sphinxstyleemphasis{either} an Exploratory or Passive\sphinxhyphen{}Prediction Question. For example, predicting which patients are likely to experience complications from surgery using a logistic regression could constitute the answer a Passive\sphinxhyphen{}Prediction Question, but it could also answer Exploratory Questions like “what hospitals have the highest surgery complication rates?” or “what type of surgeries have the highest complication rates?”

\sphinxAtStartPar
The confusion lies in the fact that the distinction between these types of questions isn’t related to the statistical machinery you might use to answer the question, but rather what we are trying to accomplish, and thus how we might evaluate the success of a given statistical or machine learning model.

\sphinxAtStartPar
With Passive\sphinxhyphen{}Prediction Questions, our interest is in the values that get spit out of a model for each entity in the data. When answering a Passive\sphinxhyphen{}Prediction Question, the \sphinxstyleemphasis{only} thing we care about is the quality of those predictions, and so we evaluate the success of a model that aims to answer a Passive\sphinxhyphen{}Prediction Question by the quality of those predictions (using metrics like AIC, AUC, R\sphinxhyphen{}Squared, Accuracy, Precision, Recall, etc.). Thus, when using a logistic regression to answer a Passive\sphinxhyphen{}Prediction Question, we don’t actually care about what factors are being used to make our predictions, just that they improve the predictions. Our interest is only the quality of our predicted values, and a good model is one that explains a substantial portion of the variation in our outcome.

\sphinxAtStartPar
With Exploratory Questions, our interest is in improving our understanding of the problem space, not in making precise predictions for each entity in our data. Thus, in the example of logistic regression, our interest is in the factors on the “right\sphinxhyphen{}hand side” of our logistic regression and how they help us understand what shapes outcomes, not the exact accuracy of our predictions. A good model, in other words, doesn’t actually have to explain a large share of variation at the level of individual entities, but it does have to help us understand our problem space.

\sphinxAtStartPar
For example, a model that looked at the relationship between individuals’ salaries and their age, education, and where they live might tell us a \sphinxstyleemphasis{lot} about the importance of a college degree to earnings (which we could see by the large and statistically significant coefficient on having a college degree), even if it only explains a small amount of overall variation in salaries (e.g., the R\sphinxhyphen{}Squared might only be 0.2).

\sphinxAtStartPar
This distinction also has important implications when working with more opaque supervised machine learning techniques, like deep learning, random forests, or SVMs. These techniques are often referred to as “black boxes” because exactly how different impute factors relate to the predictions that the model makes is impossible to understand (in other words, it’s like the input data is going into a dark box we can’t see into, and then predictions are magically popping out the other side). These models can be very useful for answering Passive\sphinxhyphen{}Prediction Questions, as they can accommodate very unusual, non\sphinxhyphen{}linear relationships between input factors and predicted values, but because these relationships are opaque to us, the data scientist, they don’t really help us understand the problem space.


\section{When Are Our Predictions Valid?}
\label{\detokenize{30_questions/20_passive_prediction_questions:when-are-our-predictions-valid}}
\sphinxAtStartPar
Because passive\sphinxhyphen{}prediction is fundamentally about making predictions about things that are not\sphinxhyphen{}yet\sphinxhyphen{}seen, making predictions is one of the more precarious things a data scientist can do. But that doesn’t mean that we are helpless when it comes to determining how confident we should be in our predictions, and when and where we think our predictions will be reliable. In particular, as data scientists, we have a great many tools for evaluating how well our model fits the data we \sphinxstyleemphasis{already have} (a concept known as \sphinxstyleemphasis{internal validity}), and ways of thinking critically about the contexts in which using a given model to make predictions are appropriate (a concept known as \sphinxstyleemphasis{external validity}).


\subsection{Internal Validity}
\label{\detokenize{30_questions/20_passive_prediction_questions:internal-validity}}
\sphinxAtStartPar
Of all the places where data science is fragmented, none is more evident than in how data scientists evaluate how effectively we think a model is representing our data.

\sphinxAtStartPar
The first data science perspective on evaluating the internal validity of a model comes from the field of statistics. Statisticians have approached evaluating model fit with, unsurprisingly, methods based on the idea of random sampling and the properties of statistical distributions. They make assumptions about the distributions underlying data and use those to derive theoretically\sphinxhyphen{}motivated metrics. That’s the origin of statistics like Akaike Information Criterion (AIC), Bayesian Information Criterion (BIC), as well as the emphasis on the validity of the standard errors assigned to factors on the right\sphinxhyphen{}hand side of the regression.

\sphinxAtStartPar
When computer scientists were first developing their own machine learning techniques… I’m editorializing a little here, but I think it’s safe to say that initially they either didn’t \sphinxstyleemphasis{know about} a lot about these metrics, or they thought that they could do a better job investing their own. So they developed the “split\sphinxhyphen{}train\sphinxhyphen{}test” approach to model evaluation: they split their data into two parts, train their model on part of the data, then test how well the model is able to predict the (known) outcomes in the test dataset.

\sphinxAtStartPar
Of course, over time these two fields have largely converged in adopting one another’s methods, and some—like cross\sphinxhyphen{}validation—live comfortably in the middle. But if you’re ever wondering why, when you get to a machine learning class, it seems like everything you learned in stats has been abandoned (or end up in a stats class and have the opposite experience), it’s largely an artifact of parallel development of methods of model evaluation in computer science and statistics departments.


\subsection{External Validity}
\label{\detokenize{30_questions/20_passive_prediction_questions:external-validity}}
\sphinxAtStartPar
Where \sphinxstyleemphasis{internal validity} is a measure of how well a model captures the meaningful variation in the data we already have, \sphinxstyleemphasis{external validity} is a measure of how well we think that our model is likely to perform when faced with new data.

\sphinxAtStartPar
The external validity of a model, it is important to emphasize, is specific to the context in which a model is being used. A model will generally have very \sphinxstyleemphasis{high} external validity when used to answer Passive\sphinxhyphen{}Prediction Questions in a setting that is very similar to the setting from which the data used to train the model was collected, but \sphinxstyleemphasis{low} external validity when applied in a very different setting.

\sphinxAtStartPar
There are a range of factors that can determine external validity, such as whether a model is being used to answer Passive\sphinxhyphen{}Prediction Questions about:
\begin{itemize}
\item {} 
\sphinxAtStartPar
the \sphinxstyleemphasis{same population} from which the training data was drawn. The patterns in data from one country will often differ from patterns in data from another country, for example.

\item {} 
\sphinxAtStartPar
the \sphinxstyleemphasis{same time period} from which the training data was drawn. Consumer behavior may vary across seasons, and many patterns in data change over longer timespans.

\item {} 
\sphinxAtStartPar
the \sphinxstyleemphasis{same parameter ranges} as those in the training data. Statistical and machine learning models are designed to fit the data they can see as well as possible. However, while nearly all models will generate predictions about outcomes when given inputs that weren’t in the data used to fit a model because they weren’t trained with access to data of this type, their guesses are unlikely to be particularly meaningful.

\end{itemize}



\sphinxAtStartPar
To illustrate, consider the two models in the figure below (\sphinxhref{https://ece.uwaterloo.ca/~dwharder/NumericalAnalysis/06LeastSquares/extrapolation/complete.html}{source})—one a linear fit, and one a higher\sphinxhyphen{}order polynomial. Both model the data similarly \sphinxstyleemphasis{in the range for which data is available} but make very different predictions at values of \sphinxcode{\sphinxupquote{x}} below 0 or above 2.

\sphinxAtStartPar
FIX COMMENTED SECTIONS





\sphinxstepscope


\chapter{Causal Questions: The Theory}
\label{\detokenize{30_questions/30_causal_questions_theory:causal-questions-the-theory}}\label{\detokenize{30_questions/30_causal_questions_theory::doc}}
\sphinxAtStartPar
In our previous readings, we learned how answering different types of questions can help us better understand the world around us. By answering Exploratory Questions, we can better understand the contours of our problem — where our problem is most acute, whether there are groups who have figured out how to get around the problem on their own, etc. This, in turn, can help us prioritize our subsequent efforts. And by answering Passive Predictive Questions, we can help identify individual entities — patients, customers, products, etc. — to whom we may wish to pay extra attention or recommend certain products. And when answering Passive Predictive Questions, we can also automate tasks by predicting how a person or more complicated process \sphinxstyleemphasis{would} have classified an entity.

\sphinxAtStartPar
In both cases, however, answering these questions only helps us better understand the world \sphinxstyleemphasis{around} us. But to the extent to which, as data scientists, we want to intervene to directly address problems, we are rarely interested in just knowing about the world around us — we want to \sphinxstyleemphasis{act} on the world, and wouldn’t be great if data science could provide us with a set of tools designed to help us predict the \sphinxstyleemphasis{consequences} of our actions?

\sphinxAtStartPar
Enter \sphinxstyleemphasis{Causal Questions}. Causal Questions ask what \sphinxstyleemphasis{effect} we can expect from \sphinxstyleemphasis{acting} — that is, actively \sphinxstyleemphasis{manipulating} or \sphinxstyleemphasis{intervening} — in the world around us in some way. For example, if we pay to show an ad to a specific customer, what will the \sphinxstyleemphasis{effect} of that choice be the likelihood they buy something on our website? Or if we chose to give a new drug to a patient, what will the \sphinxstyleemphasis{effect} of that choice be on their disease?

\sphinxAtStartPar
Because of their potential to help us understand the future consequences of our actions, it should come as no surprise that the ability to answer Causal Questions is of \sphinxstyleemphasis{profound} interest to everyone from companies to doctors and policymakers. At the same time, however, it may also come as no surprise that answering Causal Questions is an inherently challenging undertaking.

\sphinxAtStartPar
In this reading, we will discuss what it means to measure the effect of an action X (administering a new drug to a patient, showing an ad to a user) on an outcome Y (patient survival, or customer spending). This section will, at times, feel a little abstract and woo\sphinxhyphen{}woo, but please hang in there. Answering Causal Questions is as much about critical thinking as it is statistics, and the concepts introduced here will prove crucial to your ability to be effective in this space.

\sphinxAtStartPar
Then in our next reading, we will term from the more abstract to the concrete and discuss where Causal Questions arise in practice, and the workflow one goes about answering them.


\section{What Does It Mean for X to Cause Y?}
\label{\detokenize{30_questions/30_causal_questions_theory:what-does-it-mean-for-x-to-cause-y}}
\sphinxAtStartPar
To understand what it means to answer a Causal Question, and why answering Causal Questions is intrinsically hard, we must start by taking a step back to answer the question: “what do we mean when we say some action X \sphinxstyleemphasis{causes} a change in some outcome Y?”

\sphinxAtStartPar
Seriously, what do we mean when we say “X causes Y?” Try and come up with a definition!

\sphinxAtStartPar
While this question may \sphinxstyleemphasis{seem} simple, it turns out that this question has been the subject of serious academic debate for hundreds of years by philosophers no less famous than David Hume. Indeed, even today there is still debate over how best to answer this question.

\sphinxAtStartPar
In this course, we will make use of the \sphinxstyleemphasis{Counterfactual Model of Causality} (sometimes called the Neyman\sphinxhyphen{}Rubin causal model). In plain English, it posits that for “doing X to cause Y”, it must be the case that if we do X, then Y will occur, and if we did not do X, then Y would not occur. This is by far the most used definition of causality today, and yet remarkably, it only emerged in the 20th Century and was only really fleshed out in the 1970s. Yeah… that recently.

\begin{sphinxShadowBox}
\sphinxstylesidebartitle{Counterfactual Model of Causality}

\sphinxAtStartPar
For it to be the case that doing X causes Y”, it must be the case that if we do X, then Y will occur, and if we did not do X, then Y would not occur.
\end{sphinxShadowBox}


\section{Measuring the Effect of X on Y}
\label{\detokenize{30_questions/30_causal_questions_theory:measuring-the-effect-of-x-on-y}}
\sphinxAtStartPar
At first blush, this definition may seem simple. But its simplicity belies a profoundly difficult practical problem. See, this definition relies on \sphinxstyleemphasis{comparing} the value of our outcome Y in two states of the world: the world where we do X, and the world where we don’t do X. But as we only get to live in one universe, we can never perfectly know what the value of our outcome Y would be in \sphinxstyleemphasis{both} a world where we do X and one where we don’t do X for a given entity at a given moment in time. As such, we can \sphinxstylestrong{never} directly measure the causal effect of X on Y for a given entity (say, a given patient or customer) at a given moment in time — a problem known as the \sphinxstylestrong{Fundamental Problem of Causal Inference} (causal inference being what people call the practice of answering Causal Questions).

\sphinxAtStartPar
To illustrate, suppose we were interested in the effect of taking a new drug (our X) on cancer survival (our Y)  for a given patient (a woman named Shikha who arrived at the hospital on June 18th 2022). We can give her the drug and evaluate whether she is still alive a year later, but that alone can’t tell us whether the new drug \sphinxstyleemphasis{caused} her survival according to our counterfactual model of causality — after all, if she survives maybe she would have survived even without the drug! To actually know the effect of the drug on Shikha \sphinxstyleemphasis{by direct measurement,} we would have to be able to measure her survival both in the world where we gave her the drug \sphinxstyleemphasis{and} the world where we did not and compare outcomes.

\sphinxAtStartPar
Since we can never see both states of the world — the world where we undertake the action whose effect we want to understand and the world where we don’t — almost everything we do when trying to answer Causal Questions amounts to trying to find something we \sphinxstyleemphasis{can} measure that we think is a \sphinxstyleemphasis{good approximation} of the state of the world we can’t actually see.

\sphinxAtStartPar
A quick note on vocabulary: by convention, we refer to the action whose effect we want to understand as a “treatment,” and the state of the world where an entity receives the treatment as the “treated condition.” Similarly, we refer to the state of the world where an entity does \sphinxstyleemphasis{not} receive the treatment as the “control condition.” We use this language even when we aren’t talking about medical experiments or even experiments at all. We also refer to the state of the world we cannot observe as the “counterfactual” of the world we can observe — so the world where Shikha does not get the cancer drug is the \sphinxstyleemphasis{counterfactual condition} to the world where Shikha does get the drug.

\sphinxAtStartPar
It’s at this point most people start throwing out “but what about…“‘s, and that’s good! You should be — that’s exactly the kind of thinking you have to do when trying to answer Causal Questions. For example, “what about if we measured the size of Shikha’s tumor before she took the drug and compared it to the size of her tumor after? If the tumor got smaller as soon as she started the drug, then surely the drug caused the tumor to shrink!”

\sphinxAtStartPar
Maybe! Implicitly, what you have done is asserted that you think that the size of Shikha’s tumor before we administered the drug is a good approximation for what you think the size of Shikha’s tumor \sphinxstyleemphasis{would have been} had we not given her the drug.

\sphinxAtStartPar
But this type of comparison will always fall short of the Platonic ideal given by our definition of causality. Yes, Shikha’s tumor \sphinxstyleemphasis{may} have stayed the same size if we had not given her the drug (in which case the size of the tumor before she took the drug would be a good approximation), but it is also possible that regardless of whether we’d given her the drug, her cancer would have shrunk on its own.%
\begin{footnote}[1]\sphinxAtStartFootnote
The fact that diseases naturally change over time on their own is known as a disease’s “natural history.”
%
\end{footnote}

\sphinxAtStartPar
According to the Counterfactual Model of Causality, we could only ever \sphinxstyleemphasis{know} if taking the drug caused a decrease in tumor size if we could both administer the drug and observe the tumor \sphinxstyleemphasis{and also observe a parallel world in which the same person at the same moment in time was not given the drug for comparison}. And since we can never see this parallel world — the \sphinxstyleemphasis{counterfactual} to the world we observe — the best we can do is come up with different, imperfect tricks for \sphinxstyleemphasis{approximating} what might have happened in this parallel world, like comparing the tumor size before and after we administer the drug, imperfect though that may be.

\sphinxAtStartPar
So does that mean we’re doomed? Yes and no. Yes, it \sphinxstyleemphasis{does} mean that we’re doomed to never be able to take the exact measurements that make it possible to directly answer a Causal Question. But no, that doesn’t mean we can’t do anything — in the coming weeks, we will learn about different strategies for approximating counterfactual conditions, and in each case we will learn about what \sphinxstyleemphasis{assumptions} must be true for our strategy to provide a valid answer to our Causal Question. By making the assumptions that underlie each empirical strategy explicit, we will then be able to evaluate the plausibility of these assumptions.

\sphinxAtStartPar
In the example of Shikha, for example, we know that our comparison of tumor size before taking the drug to tumor size after taking the drug is only valid if her tumor \sphinxstyleemphasis{would not have gotten smaller without the drug}. This is something we can’t measure directly, but we can look to other patients with similar tumors, or the history of her tumor size to evaluate how often we see tumors get smaller at the rate observed after she took the drug. If it’s very rare for these types of tumors to ever get smaller, than we can have more confidence that a decrease in tumor size was the result of the drug.

\sphinxAtStartPar
We are also sometimes in a position to be more proactive than our effort to answer Causal Questions. Rather than trying to make inferences from the world around us using what is termed “observational data” (data that was generated through a process we did not directly control, a process we only “observe”), we can sometimes generate our own data through randomized experiments.

\sphinxAtStartPar
Randomized experiments — perhaps the most familiar tool for answering Causal Questions — are also just another way of approximating the unobservable counterfactual condition. In a randomized experiment — also known as “Randomized Control Trials (RCTs)”, or “A/B Tests” whether you’re hanging out with statisticians, doctors, or web developers — participants are assigned to either receive the treatment (the treatment group) or not (the control group) based on the flip of a coin, a roll of a die, or more commonly a random number generator on a computer. Provided we have enough participants, the Law of Large Numbers then promises that, \sphinxstyleemphasis{on average}, the people assigned to the control group will (probably) be “just like” the people assigned to the treatment group in every possible way (save being treated). Subject to a few other assumptions we’ll discuss in great detail later, that means that the outcomes of the control group — being just like the treatment group \sphinxstyleemphasis{on average} — will be a good approximation of what \sphinxstyleemphasis{would} have happened to the treatment group in a world where they did not receive the treatment.

\sphinxAtStartPar
Randomized experiments are not a silver bullet, however. The validity of experimental comparisons still rests on a number of assumptions, many of which cannot be directly tested. For example, we can never be entirely sure that when we randomly assigned people to control and treatment groups, the process was truly random, or that we ended up with people who were similar in both groups (the law of large numbers only promises that getting similar groups becomes \sphinxstyleemphasis{more likely} as the size of the groups increases, not that it will happen with certainty!). Moreover, conducting a randomized experiment requires working in a context where the researcher can control everything, and that can sometimes generate results that may not generalize to the big messy world where you actually want to act.


\section{So where does that leave us?}
\label{\detokenize{30_questions/30_causal_questions_theory:so-where-does-that-leave-us}}
\sphinxAtStartPar
For many data scientists, this will feel \sphinxstyleemphasis{profoundly} dissatisfying. Many people come to data science because of the promise that it will provide direct answers to questions about the world using statistics. But because of the Fundamental Problem of Causal Inference, this will never be possible when answering Causal Questions. Rather, the job of a data scientist answering Causal Questions is a lot like the job of a detective trying to solve a crime — your task is to determine what \sphinxstyleemphasis{probably} happened at a crime scene. You can gather clues, collect forensic evidence, and interview suspects, all in an effort to come up with the \sphinxstyleemphasis{most likely} explanation for a crime. But no matter how hard you try, you can’t go back in time to witness the crime itself, so you will never be able to be entirely sure if you are right or not.

\sphinxAtStartPar
But just as we investigate and prosecute crimes despite our inability to ever be 100\% certain an arrested suspect is guilty, so too must businesses and governments make decisions using the best available evidence, even when that evidence is imperfect. But it is our job, as data scientists, to help provide our stakeholders with the best available evidence, and also to help them understand the strength of the evidence we are able to provide.


\section{Why Passive\sphinxhyphen{}Prediction Is Not Enough}
\label{\detokenize{30_questions/30_causal_questions_theory:why-passive-prediction-is-not-enough}}
\sphinxAtStartPar
At this point, it is worth pausing to reflect on a question it may not have occurred to you to ask above — if answering Causal Questions is usually about \sphinxstyleemphasis{predicting} what would happen if we were to act on the world in a certain way, then how/why is it different from answering the kind of Passive\sphinxhyphen{}Prediction Questions we discussed previously?

\sphinxAtStartPar
There are a number of different ways one can frame the answer to this question, but the one I like most for Data Scientists is that  when answering a Passive\sphinxhyphen{}Predictive Question, we can usually achieve our goals simply by identifying \sphinxstyleemphasis{correlations} that we think are likely to persist into the future. For example, suppose we run the maintenance department for a rental car company. The fact that a car whose \sphinxstyleemphasis{Check Engine} light is on is a car that is likely to break down if it isn’t taken to a mechanic is enough for us to identify cars in trouble! Obviously, the \sphinxstyleemphasis{Check Engine} light isn’t \sphinxstyleemphasis{causing} the cars to break down, but it doesn’t have to to be useful.

\sphinxAtStartPar
But when seeking to answer Causal Questions, we wish to go beyond just identifying cars in trouble, and instead predict what might happen to cars if we \sphinxstyleemphasis{chose to act} in different ways. This requires going beyond simple Passive\sphinxhyphen{}Prediction because, in choosing to act, we are asking about how things might turn out in a world where we are behaving differently than we are currently — in other words, we are no longer being passive.

\sphinxAtStartPar
Thus, in a sense, answering Causal Questions is therefore \sphinxstyleemphasis{always} an example of “out\sphinxhyphen{}of\sphinxhyphen{}sample extrapolation” or “out\sphinxhyphen{}of\sphinxhyphen{}sample prediction”, because by definition we are saying we want to know what happens in a world where at least one major agent — us! — changes their behavior. And indeed, there’s a very real sense in which that’s what we \sphinxstyleemphasis{mean} by a causal relationship: a relationship between our actions and an outcome that would persist even if we change our behavior!

\sphinxAtStartPar
What’s a situation where a correlation is sufficient for Passive Prediction but not answering a Causal Question? Well, let’s go back to our example of the rental car maintenance manager — suppose rather than using \sphinxstyleemphasis{Check Engine} lights to identify cars that needed more attention, the manager decided to just cut the cables that run to all the \sphinxstyleemphasis{Check Engine} lights! After all, the cars that are breaking down all have their \sphinxstyleemphasis{Check Engine} light on, and the cars that don’t have their \sphinxstyleemphasis{Check Engine} lights almost never break down! So why not just disable the \sphinxstyleemphasis{Check Engine} lights on all these cars so they stop breaking down?

\sphinxAtStartPar
Now that we’ve been clear about what we mean when we ask “does X cause Y?”, we can now understand why this is a perfect example of why correlation does not always imply causation.

\sphinxAtStartPar
Fundamentally, the manager is asking “would cutting the cables to the \sphinxstyleemphasis{Check Engine} lights prevent our cars from breaking down?” For that to be true, we know that in an ideal universe, we would want to compare a car on the verge of breaking down that has its \sphinxstyleemphasis{Check Engine} light intact to that same car in a world where we cut the \sphinxstyleemphasis{Check Engine} light — then we can see if there is a difference in whether these cars break down!

\sphinxAtStartPar
But this is \sphinxstyleemphasis{not} the data our manager has turned to draw their conclusion — rather, they are comparing cars with their \sphinxstyleemphasis{Check Engine} lights on and cars without their \sphinxstyleemphasis{Check Engine} lights on. And it turns out that cars \sphinxstyleemphasis{without} their \sphinxstyleemphasis{Check Engine} lights on are not a good approximation for the cars \sphinxstyleemphasis{with} their \sphinxstyleemphasis{Check Engine} lights on because the cars without the light on are different from the cars with the light on in ways that matter for the likelihood of breaking down (they have engine problems!) \sphinxstyleemphasis{other} than the \sphinxstyleemphasis{Check Engine} light!

\sphinxAtStartPar
Depending on what classes you may have taken in the past, you may have heard these differences referred to as “confounders” or “omitted variables” — those are just different words or ways of talking about the same idea! Confounders or omitted variables are just different words for features that are different between the “treated” and “untreated” observations being examined that the untreated observations are bad approximations of the counter\sphinxhyphen{}factual condition for the treated observations!


\section{Next Steps}
\label{\detokenize{30_questions/30_causal_questions_theory:next-steps}}
\sphinxAtStartPar
In this reading, we learned — in an intuitive sense — why answering Causal Questions is inherently hard. But this explanation, while accurate, is a little informal to be rigorous. In the readings that follow, we will be introduced to the \sphinxstyleemphasis{Potential Outcomes Framework} — the formal statistical framework that underlies the Neyman\sphinxhyphen{}Rubin Counterfactual Model of Causality. This framework will help us reason more systematically about how and when methods like randomized experiments, linear regression, matching, and differences\sphinxhyphen{}in\sphinxhyphen{}differences can help us answer Causal Questions.

\sphinxAtStartPar
But first, in the interest of not losing perspective on the forest for the trees, a discussion of \sphinxstyleemphasis{how} Causal Questions are used in practice.


\bigskip\hrule\bigskip


\sphinxstepscope


\chapter{Causal Questions in Practice}
\label{\detokenize{30_questions/40_causal_questions_application:causal-questions-in-practice}}\label{\detokenize{30_questions/40_causal_questions_application::doc}}
\sphinxAtStartPar
In our last reading, we learned a little about what it means to measure a causal effect, and why it is inherently difficult. That is a topic we will return to shortly, as understanding why measuring causal effects is hard is key to being able to measure them effectively. But first, take a moment to discuss how Causal Questions come up and are addressed in practice to help contextualize the more technical readings that will follow.




\section{When Do Causal Questions Come Up?}
\label{\detokenize{30_questions/40_causal_questions_application:when-do-causal-questions-come-up}}
\sphinxAtStartPar
Causal Questions arise when stakeholders want to \sphinxstyleemphasis{do} something — buy a Superbowl ad, change how the recommendation engine in their app works, authorize a new prescription drug — but they fear the action they are considering may be costly and not actually work. In these situations, stakeholders will often turn to a data scientist in the hope that the scientist can “de\sphinxhyphen{}risk” the stakeholder’s decision by providing guidance on the likely effect of the action \sphinxstyleemphasis{before} the action is undertaken at full scale.

\sphinxAtStartPar
\sphinxstyleemphasis{Usually}, the action the stakeholder is considering will not have been pulled out of a hat. Rather, a stakeholder will generally pose a Causal Question because they have some reason to suspect a given course of action may be beneficial. Indeed, Causal Questions often emanate from patterns discovered when answering Exploratory or Passive Predictive Questions.


\subsection{Where Causal Questions Come From: An Example}
\label{\detokenize{30_questions/40_causal_questions_application:where-causal-questions-come-from-an-example}}
\sphinxAtStartPar
For example, suppose the Chief of Surgery at a major hospital is interested in reducing surgical complications. They begin by asking “What factors predict surgical complications?” (a Passive Predictive Question) and develop a predictive model that allows the hospital to identify patients who are likely to have issues so that caretakers can provide additional support to these patients during recovery.

\sphinxAtStartPar
In the course of developing this model, the Chief discovers that one of the strongest predictors of surgical complications is patient blood pressure — patients with high blood pressure are substantially more likely to experience complications than those with normal blood pressure.

\sphinxAtStartPar
This leads the Chief to wonder about whether they could reduce surgical complications if they treated patients with high blood pressure with pressure\sphinxhyphen{}reducing medications prior to surgery. In other words, the Chief Surgeon wants to know “What effect treating patients with high blood pressure would have on surgical complication rates?”

\sphinxAtStartPar
But rather than just starting to give all patients with high blood pressure new drugs (and delay their surgeries while the drugs take effect), the Chief wants \sphinxstyleemphasis{you} to provide a more rigorous answer to their question. After all, high blood pressure may be \sphinxstyleemphasis{causing} the complications (and thus the medicine may help), but it could also be that high blood pressure isn’t the \sphinxstyleemphasis{cause} of the complications, but rather the \sphinxstyleemphasis{symptom} of a third factor that causes both high blood pressure \sphinxstyleemphasis{and} complications that makes people with high blood pressure different from those with low blood pressure — like leading an overly stressful life. The Chief doesn’t need to know whether high blood pressure is the \sphinxstyleemphasis{cause} of complications or just a “warning light” that identifies people at risk to use that information for directing additional support to those patients during recovery; but it \sphinxstyleemphasis{does} matter for determining whether it makes sense to delay surgeries to teach patient high blood pressure!

\sphinxAtStartPar
This is, of course, just one example, and it’s not hard to imagine others. Perhaps your online retailer stakeholder has noticed that one of your competitors has stopped showing customer reviews in the search results, for example, so they suspect it must be improving sales for your competitor and want to know if it would work for your site too! But the point is that Causal Questions generally don’t appear out of the blue, but rather because someone has noticed a pattern in the world and wants to act on it. Thus, many Causal Questions may actually take the form of hypotheses or hunches that your stakeholder wants investigated.


\section{The Two\sphinxhyphen{}Fold Challenge of Causal Questions}
\label{\detokenize{30_questions/40_causal_questions_application:the-two-fold-challenge-of-causal-questions}}
\sphinxAtStartPar
In our last reading, we discussed how answering Causal Questions is difficult in part because measuring the effect of any action on any outcome is a definitionally difficult endeavor. But answering Causal Questions is also difficult for a more practical — less epistemological — reason: risk aversion!

\sphinxAtStartPar
As we noted above, stakeholders generally turn to data scientists because they want to know the likely consequences of an action \sphinxstyleemphasis{before they actually undertake the action at full scale.} This may seem obvious, but it bears repeating — not only is answering Causal Questions hard because we never get to measure outcomes in both a universe where our treatment occurs and also a universe where it does not (the Fundamental Problem of Causal Inference), but \sphinxstyleemphasis{also} because stakeholders want to know about the likely consequences of an action they aren’t ready to actually undertake!

\sphinxAtStartPar
As a result, the job of a data scientist who wants to answer a Causal Question is to design a study that not only measures the effect of a treatment, but also does so in a setting that is enough like the context in which the stakeholder wants to act that any measured effect will generalize to the stakeholder’s context.

\sphinxAtStartPar
We call these two objectives of a study \sphinxstyleemphasis{internal validity} (how well the study answers the Causal Question \sphinxstyleemphasis{in the setting the study is conducted}) and \sphinxstyleemphasis{external validity} (how well the results of the study generalize to the context the stakeholder cares about). And to provide value to a stakeholder, a data scientist’s analysis must have both.


\subsection{Internal and External Validity: An Example}
\label{\detokenize{30_questions/40_causal_questions_application:internal-and-external-validity-an-example}}
\sphinxAtStartPar
To illustrate, suppose you work for a medical device company in Boston that wants the US Food and Drug Administration (FDA) to authorize a new cochlear implant your company has developed (a partially surgically implanted device for helping those with certain types of hearing loss regain hearing). Before authorizing the device, the FDA wants to be sure that it’s safe and effective — in other words, it wants to know what the \sphinxstyleemphasis{effect} of authorizing the device for patients throughout the United States would be on patient health.

\sphinxAtStartPar
Your job, therefore, is to conduct a study that (a) convincingly measures the effect of the device on patients (has high internal validity), \sphinxstyleemphasis{and} (b) does so in a way that convinces the FDA that the findings from \sphinxstyleemphasis{your study} are likely to be the same as what would be seen if the device were being used across the United States (has external validity to the context the FDAs cares about).

\sphinxAtStartPar
In medical trials, internal validity is usually ensured by conducted a randomized experiment — referred to as a Randomized Control Trial (RCT) in medical circles — according to a set of FDA requirements. We’ll discuss what features must be present for us to have confidence in the results of a randomized experiment soon, but they are things like making sure that the people in the control group look like the people in the treatment group in terms of things we can measure (age, gender, etc.) to help us feel confident that when people were randomly assigned to control and treatment groups, we didn’t end up in a really unlikely situation where, purely by chance, only men ended up in control group and only women ended up in treatment group.

\sphinxAtStartPar
External validity, by contrast, comes from things like \sphinxstyleemphasis{who} is enrolled in the trial. The average age of children getting cochlear implants is between 2 and 3, so if your study only included children between 12 and 18 months of age, the FDA may worry that the results of the study would not \sphinxstyleemphasis{generalize} to the US population as a whole.

\sphinxAtStartPar
In the context of a clinical trial, this issue of external validity may seem easy to address — just get a sample of people who “look like” the US population (when applying for US FDA approval)! Historically, however, \sphinxhref{https://www.theguardian.com/lifeandstyle/2015/apr/30/fda-clinical-trials-gender-gap-epa-nih-institute-of-medicine-cardiovascular-disease}{women}%
\begin{footnote}[1]\sphinxAtStartFootnote
In 1977, the FDA actually banned enrollment of women of “childbearing potential” from Phase 1 and Phase 2 clinical trials in the \sphinxhref{https://www.womenshealth.gov/30-achievements/04\#:~:text=In\%201977\%2C\%20the\%20FDA\%20issued,thalidomide)\%20causing\%20serious\%20birth\%20defects.}{interest of avoiding birth defects}.
%
\end{footnote} and \sphinxhref{https://www.thelancet.com/journals/lanam/article/PIIS2667-193X(22)00069-2/fulltext}{minorities} have been underrepresented in clinical trial participants.%
\begin{footnote}[2]\sphinxAtStartFootnote
This seems likely to be due, in part, to hesitancy to enroll in clinical trials by individuals aware of past abuses of minority patients, as in the \sphinxhref{https://www.cdc.gov/tuskegee/index.html}{Tuskegee Syphilis Study}.
%
\end{footnote} Moreover, the people designing clinical trials often limit enrollment to participants who, aside from the specific condition being treated, are healthy to avoid complications. This reduction in complications may increase the \sphinxstyleemphasis{internal} validity, but as many patients face more than one health challenge, it may reduce external validity.

\sphinxAtStartPar
Outside of drug or medical device trials, however, external validity can much harder to establish. For example, the functionality of many internet services and apps depends on network effects — testing out a new social feature on Instagram by making it available to only a handful of users in a randomized trial (an A/B test, in the language of tech companies) may not give you a meaningful sense of how the feature would be used if it was visible to all users. And the way that bank customers use a new budgeting app in the context of a two\sphinxhyphen{}week study may not be indicative of how they would use it over the long run when the feature is no longer new.


\subsection{External Validity To \sphinxstyleemphasis{What}}
\label{\detokenize{30_questions/40_causal_questions_application:external-validity-to-what}}
\sphinxAtStartPar
Throughout this text, we will refer to whatever course of action the stakeholder is actually considering pursuing as the “stakeholder’s context.” As a result, when discussing the external validity of a study, we will implicitly be referring to its external validity \sphinxstyleemphasis{to the stakeholder’s context.} But it is worth emphasizing that while the internal validity of a study is a single things — you have some level of confidence that the study measured the effect they set out to measure — external validity is \sphinxstyleemphasis{relative}. A study conducted in a hospital in Denver, Colorado may have good external validity from the perspective of a doctor in a Pheonix, Arizona hospital, but that same study may not have very good external validity from the perspective of a doctor at a hospital in Pune, India. So always remember that external validity is not an absolute property of an analysis, but a property that is \sphinxstyleemphasis{relative} to the context to which one wishes to generalize the results.


\section{The Causal Question Work Flow}
\label{\detokenize{30_questions/40_causal_questions_application:the-causal-question-work-flow}}
\sphinxAtStartPar
Before we dive into the technical details of answering Causal Questions, it’s worth starting with a high\sphinxhyphen{}level overview of how data scientists approach answering Causal Questions.


\subsection{Identify Relevant Previous Studies}
\label{\detokenize{30_questions/40_causal_questions_application:identify-relevant-previous-studies}}
\sphinxAtStartPar
Once a Causal Question has been posed, the next step is \sphinxstylestrong{to identify any research that has already been done} that may help answer your causal question. It’s hard to overstate how often this step is overlooked by data scientists, but it’s \sphinxstyleemphasis{such} a no\sphinxhyphen{}brainer once you think of it! There’s no reason to spend days or weeks trying to design a study to answer a question if someone else has already put the time and money into doing it for you!

\sphinxAtStartPar
If your stakeholder is somebody who works in public policy or medicine, then the first place to look for previous studies is in academic medical or policy journals. But don’t assume that if you aren’t working on a medical or public policy question that you won’t be able to find an answer to your question in academic or pseudo\sphinxhyphen{}academic publications — lots of data scientists present research done at private companies at ``industry’’ conferences like the \sphinxhref{https://ide.mit.edu/events/2022-conference-on-digital-experimentation-mit-codemit/}{MIT Conference on Digital Experimentation (CODE@MIT)} or the \sphinxhref{https://netmob.org/}{NetMob Cellphone MetaData Analysis Conference}!

\sphinxAtStartPar
And if you are at a company, ask around! Someone at your own company may have looked into a similar question before, and talking to them could save you a lot of effort.


\subsection{Evaluate Previous Studies}
\label{\detokenize{30_questions/40_causal_questions_application:evaluate-previous-studies}}
\sphinxAtStartPar
If you do find studies, then for each study you will have to ask yourself two questions:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Did the study authors do a good job of answering the Causal Question? \sphinxstyleemphasis{in the context they were studying}}?

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Do I believe that the \sphinxstyleemphasis{context} in which the study was conducted is similar enough to my own context that their conclusions are relevant to me?}

\end{itemize}

\sphinxAtStartPar
This first question is about the \sphinxstyleemphasis{internal validity} of the study, and we’ll talk at length about how to evaluate that in the context of causal inference in the coming weeks. The second question is about the \sphinxstyleemphasis{external validity} (i.e., the generalizability) of the study to your context. There are lots of extremely well\sphinxhyphen{}conducted studies in the world that may be seeking to answer the same question as you, but if, for example, they investigated the effect of a new drug in \sphinxstyleemphasis{young} patients, and your hospital only treats very old patients, you may not be comfortable assuming their results are good predictors for what might happen in your hospital.


\subsection{Plan A New Study}
\label{\detokenize{30_questions/40_causal_questions_application:plan-a-new-study}}
\sphinxAtStartPar
If you were unable to find any studies that answer your Causal Question satisfactorily (either on their own or in combination), then it may be time to do a study of your own!

\sphinxAtStartPar
When most people think about answering Causal Questions, their minds immediately jump to randomized experiments. Randomized experiments are \sphinxstyleemphasis{often} the best strategy for trying to answer Causal Questions, but they are not always the best choice.

\sphinxAtStartPar
Studies designed to answer Causal Questions can be divided into roughly two types: experimental studies and observational studies.

\sphinxAtStartPar
In an experimental study, a researcher has control over everything that happens in the study, including who enrolls in the study and also who in the study gets assigned to the treatment group and who gets assigned to the control group. Nearly all clinical trials, A/B tests where the version of a website or app users see is randomly determined, and field experiments where, say, voters are randomly assigned to receive different types of mailers from political campaigns to measure their effect on voter turnout are all examples of “experimental studies.”

\sphinxAtStartPar
In an observational study, by contrast, researchers use data from a context where the researchers did not control who was treated and who was not. This includes data from public opinion surveys, data on user behavior and demographics, or census data.

\sphinxAtStartPar
(We say studies can be divided into roughly two types because some studies fall into a category sometimes called “quasi\sphinxhyphen{}experimental.” In these studies, researchers were not in control over who was treated and who was not, but they have some reason for thinking that \sphinxstyleemphasis{something in the world} — like a chance storm, or a draft lottery — caused who was treated and who was not to be determined randomly. But these types of studies tend to be more relevant for academics than applied data scientists, and evaluating them is incredibly difficult, so we will largely ignore them in this text.)

\sphinxAtStartPar
While it is sometimes believed that only experimental studies can generate valid answers to Causal Questions, this is \sphinxstyleemphasis{unequivocally untrue}, as is the slightly more generous version of this claim, that experimental studies always constitute the best form of evidence for answering Causal Questions. As we will explore in \sphinxstyleemphasis{great} detail in the coming days, the validity of conclusions drawn from \sphinxstyleemphasis{both} experimental and observational studies rests on whether a number of fundamentally untestable assumptions hold. As a result, both types of studies are capable of providing meaningful answers to causal questions \sphinxstyleemphasis{and} of being deeply misleading.

\sphinxAtStartPar
Moreover, while experimental studies often (but not always) have greater \sphinxstyleemphasis{internal validity} (they are often better able to ensure that they have measured the true causal effect in the lab), this often comes at the expense of lower \sphinxstyleemphasis{external validity}, because ensuring the researchers can control who is treated and who is not requires operating the study take place in a highly monitored, often artificial and unrealistic setting. Observational studies, by contrast, are often based on data collected in the real world, and as a result may yield answers that tell us more about what is likely to happen in our own real\sphinxhyphen{}world application, even if they have somewhat lower internal validity.


\section{Wrapping Up and Next Steps}
\label{\detokenize{30_questions/40_causal_questions_application:wrapping-up-and-next-steps}}
\sphinxAtStartPar
Hopefully, this reading has given you a better sense of \sphinxstyleemphasis{how} Causal Questions are used to solve stakeholder problems, and when and where they come up in the life of a practicing data scientist. In the readings that follow, we will turn first to the details of the \sphinxstyleemphasis{Potential Outcomes Model}, a rigorous, formal statistical framework for understanding the Counterfactual Model of Causality. This framework will not only provide a presentation of the Counterfactual Model of Causality that may be appealing to those who draw intuition from mathematical formalism, but also machinery that we can use to evaluate how much confidence we can have in answers generated using different methods of answering Causal Questions — including both experimental and observational studies.


\bigskip\hrule\bigskip


\sphinxstepscope


\part{Data Science in Practice}

\sphinxstepscope


\chapter{Backwards Design}
\label{\detokenize{40_in_practice/00_backwards_design:backwards-design}}\label{\detokenize{40_in_practice/00_backwards_design::doc}}
\sphinxAtStartPar
Backwards Design is a way of developing an efficient strategy for completing a new data science project, and in my view it is one of the most important skills of a professional data scientist.

\sphinxAtStartPar
If you don’t have a lot of professional data science experience, it may not be obvious why this is an important skill, or even why I call it a “skill.” That’s because most data science students’ experience with project development comes from classroom exercises or sites like kaggle. These types of projects are excellent opportunities for learning, but it is usually the case that – unbeknownst to the student – these projects have been carefully tailored to have clearly defined goals, and they come with data sets that have been cleaned and filter to provide only relevant variables. This is usually done for good reasons – the instructors design these exercises in a way that focuses student attention on the skills that they are trying to develop (like model selection or model interpretation). But as a result, students often come away with the impression that most of what data scientists do is work with statistical models.

\sphinxAtStartPar
In reality, however, often the most important thing that a data scientist does is (a) develop and articulate a concrete, feasible objective of a data science project, and (b) develop a strategy for achieving that objective efficiently. And Backwards Design is one of the best ways to go about accomplishing both of these goals.


\section{Overview}
\label{\detokenize{40_in_practice/00_backwards_design:overview}}
\sphinxAtStartPar
As the name implies, the idea Backwards Design is to \sphinxstyleemphasis{start} by clearly defining where you want to end up at the end of the project, and then working backwards to figure out exactly what you need to do to get there. Backwards Design is actually a common project management strategy and a range of different domains, and so you may already be familiar with the strategy and broad terms. In this class, however, we will focus on a five\sphinxhyphen{}step strategy for doing Backwards Design in data science:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Define the problem you want to solve.

\item {} 
\sphinxAtStartPar
Define a \sphinxstyleemphasis{question} that you wish to answer to help you solve this problem.

\item {} 
\sphinxAtStartPar
Articulate exactly what an answer to your question would look like.

\item {} 
\sphinxAtStartPar
Determine the variables you would need in order to generate that answer.

\item {} 
\sphinxAtStartPar
Identify data sets with those variables, and develop a strategy for bringing them together.

\end{enumerate}


\section{1) Define Your Problem}
\label{\detokenize{40_in_practice/00_backwards_design:define-your-problem}}
\sphinxAtStartPar
This first step should be the most straightforward, and yet you will be surprised at how often it is never actually explicitly addressed. People get so excited about the idea of data science that they will often come to you (the data scientist) with the data set and say “do some data science with this!” So the first thing you should always do when starting a data science project is make sure that you can clearly articulate the objective of the project. In addition, you should always make sure that \sphinxstyleemphasis{your stakeholder} agrees with that articulation of the problem you are trying to address! There’s nothing worse than spending weeks on a project and then discovering that it’s not actually a value to your stakeholder.

\sphinxAtStartPar
Here are a few examples of defined problems:
\begin{itemize}
\item {} 
\sphinxAtStartPar
We don’t know how to reduce mass incarceration.

\item {} 
\sphinxAtStartPar
My business can’t identify potential new customers.

\item {} 
\sphinxAtStartPar
We don’t know who is going to develop Alzheimers, so we can’t test early interventions.

\end{itemize}


\section{2) Define the Question You Wish to Answer}
\label{\detokenize{40_in_practice/00_backwards_design:define-the-question-you-wish-to-answer}}
\sphinxAtStartPar
Although not everyone will agree with us, it is my view the data science is fundamentally the practice of using data to quantifiably answer questions about the world.

\sphinxAtStartPar
For example, when we ran our regressions of birth weight on various demographic variables and whether the mother smoked during pregnancy, those models were answering the question “is maternal smoking associated with lower birth weight (at a statistically significant level after controlling for other confounds)?”

\sphinxAtStartPar
If someone who runs a commerce website runs an A/B test where users visiting the site are randomly assigned to see two versions of a new landing page, and we then track their purchasing behavior, then when we analyze that data statistically what we’re doing is answering the question “Which of these designs is more effective at getting customers to buy things?”

\sphinxAtStartPar
And finally we can think of supervised machine learning algorithms as answering two types of question: there’s the broad question that you answer by building a model and evaluating it (“can we identify cancer from patient x\sphinxhyphen{}rays, and if so, how well?”), and then the narrow question the is answered each time the model is run (“given this x\sphinxhyphen{}ray, how likely is this patient to have cancer?”). (There’s a small digression on supervised machine learning and this “data science is about answering questions” conceptual framework at the end of this if you’re interested).

\sphinxAtStartPar
So the next step in backwards design is to ask yourself: what question, if answered, would help you solve the problem that motivates you?


\subsection{Defining a Good Question}
\label{\detokenize{40_in_practice/00_backwards_design:defining-a-good-question}}
\sphinxAtStartPar
A key feature of a good question is one that it is \sphinxstyleemphasis{concrete}, \sphinxstyleemphasis{tractable} and \sphinxstyleemphasis{answerable} by a data science project. Your question meets these criteria if it \sphinxstylestrong{directly implies how you should approach the data science project, and that approach seems feasible.} If your question is so vague that you don’t immediately start thinking about the data you want to collect, it’s not a good motivating question.

\sphinxAtStartPar
To illustrate, here are a set of \sphinxstyleemphasis{bad} questions to the three problems described above:
\begin{itemize}
\item {} 
\sphinxAtStartPar
What policies reduce mass incarceration?

\item {} 
\sphinxAtStartPar
Can machine learning help me identify potential customers.

\item {} 
\sphinxAtStartPar
What indicates Alzheimers?

\end{itemize}

\sphinxAtStartPar
By contrast, here’s a set of concrete, tractable, and answerable questions:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Does the availability of grand juries result in longer sentences? (Grand juries are a pool of citizens prosecutors can ask for guidance on sentencing. In theory they’re supposed to hold prosecutors accountable, but in reality its often said that prosectors can shape the information grand juries get so they reach the recommendations that prosecutors wanted to begin with).

\item {} 
\sphinxAtStartPar
What attributes are common to the customers who buy the most from my business?

\item {} 
\sphinxAtStartPar
Are there lab results common in patients who later develop Alzheimers (diagnosed post\sphinxhyphen{}mortem) that we don’t see in patients who don’t go on to develop Alzheimers?

\end{itemize}

\sphinxAtStartPar
For the first set, we’ve asked questions, but they’re so vague that it’s not clear how you should approach answering the question. In the second set, by contrast, likely first steps are very clear. For example, the first good question clearly implies we need to find data on sentencing from places with and without grand juries. For the second question, its clear we need data on our current customers, and data from the general population for comparison. And for the last question we clearly want lab data from patients with and without diagnosed Alzheimers!

\sphinxAtStartPar
Moreover, for these answerable questions, you can imagine what the answer to the question will look like: for the first, you could have a regression that regresses sentences on grand jury availability controlling for crime committed; and for the second, you could imagine a table that compares various demographic characteristics of customers to non\sphinxhyphen{}customers.


\subsection{Why is Having a Good Question Important?}
\label{\detokenize{40_in_practice/00_backwards_design:why-is-having-a-good-question-important}}\begin{itemize}
\item {} 
\sphinxAtStartPar
It will save you from getting lost in your data, since it helps you focus you energy.

\item {} 
\sphinxAtStartPar
Being able to articulate the question you wish to answer allows you to make sure that answering that question will actually help address your motivating problem (/make sure that your stateholder agrees that answering your question will help them). There’s \sphinxstyleemphasis{nothing} worse than getting excited, diving into your data, doing lots of work, and then getting a result that doesn’t actually help address the problem that motivated you (but it happens \sphinxstyleemphasis{all the time}).

\end{itemize}


\section{3) Write Down What An Answer Would Look Like}
\label{\detokenize{40_in_practice/00_backwards_design:write-down-what-an-answer-would-look-like}}
\sphinxAtStartPar
Seriously. Do it. Not abstractly: I mean draw the graph, figure, table, dataset with columns of predicted values and predictors, or set of model diagnostics you want to generate as a way of answering your question. Literally draw the graph, label the axes, etc.

\sphinxAtStartPar
Why?
\begin{itemize}
\item {} 
\sphinxAtStartPar
If you can’t, then it turns out your question wasn’t sufficiently concrete.

\item {} 
\sphinxAtStartPar
You can then show this to your stakeholder to ensure they think this constitutes an answer that would help them solve their problem (and avoid later being told your work doesn’t actually help them)

\item {} 
\sphinxAtStartPar
It makes it even clearer what steps you need to do next to generate this result.

\end{itemize}


\subsection{Falsifiability}
\label{\detokenize{40_in_practice/00_backwards_design:falsifiability}}
\sphinxAtStartPar
OK. So now you’re written down what an answer to your question looks like. But there’s one other key feature of a good question that we didn’t get into above: it should be \sphinxstyleemphasis{falsifiable}, which means that (a) you should be able to articulate a hypothesis about the answer to your question \sphinxstyleemphasis{and} (b) know what a result to your question would look like.

\sphinxAtStartPar
So when writing down what your answer should look like, do the following:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
State a hypothesis about what you think the answer to your question is likely to be.

\item {} 
\sphinxAtStartPar
Draw what an answer to your question would look like \sphinxstyleemphasis{if your hypothesis is true}.

\item {} 
\sphinxAtStartPar
Draw what an answer to your question would look like \sphinxstyleemphasis{if your hypothesis is false}.

\end{enumerate}

\sphinxAtStartPar
For example, consider our question about grand juries and sentecing. My hypothesis might be that grand juries result in longer sentences because they insulate prosectors from accountability.

\sphinxAtStartPar
My result, as described above, could be a regression table where I regress sentences on whether a county has a grand jury along with controls for crime committed.

\sphinxAtStartPar
The answer if my hypothesis is true is that we’d have a positive coefficient on the presence of grand juries.

\sphinxAtStartPar
The answer if my hypothesis is false is that we’d have a zero or negative coefficient on the presence of grand juries.

\sphinxAtStartPar
Why do all this? Because it helps ensure that the way we’re planning to answer our question will actually answer it by generating different results in different states of the world.


\section{4) What Data Do You Need?}
\label{\detokenize{40_in_practice/00_backwards_design:what-data-do-you-need}}
\sphinxAtStartPar
Congratulations! You’ve now completed the really hard part of a data science project: defining your goals. Now we turn to the easy stuff.

\sphinxAtStartPar
First, now you know your goal – the result described above – we turn to how we will actually answer our question. So ask yourself:
\begin{itemize}
\item {} 
\sphinxAtStartPar
What variables do I need to make the result I described above,

\item {} 
\sphinxAtStartPar
What population do I need represented in that data

\end{itemize}

\sphinxAtStartPar
So let’s think about our business trying to find new customers. Clearly, we need data on (a) customer spending, and (b) the demographics of those same customers.

\sphinxAtStartPar
We also need data on \sphinxstyleemphasis{both} people who spend a lot, and people who don’t spend a lot so we can compare these two populations. We could do this either by getting data on all our customers and comparing big spenders from people who don’t buy much (if there’s a lot of variation in the data on level of spending), or we could compare current customers to the general public (most of whom aren’t customers).


\section{5) Where Can You Get That Data?}
\label{\detokenize{40_in_practice/00_backwards_design:where-can-you-get-that-data}}
\sphinxAtStartPar
OK, now you know the variables you need measured and the populations for whom you need those variables. Now let’s figure out:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Where can I get that data, and

\item {} 
\sphinxAtStartPar
If the data will come from different datasets, how will I combine them?

\end{itemize}

\sphinxAtStartPar
In the customer example above, for example, we can start by looking for the data the company already has on its current customers. What’s in that data?

\sphinxAtStartPar
We can also look for similar demographic data for non\sphinxhyphen{}customers using a resource like the American Community Survey (the annual survey run by the US Census bureau).

\sphinxAtStartPar
If we use government data for our comparison group, we’ll then have to make sure we get comparable samples, so we’ll want to make sure we can match our observations on things like age, gender, and where people live, so we’ll need to make sure we have those variables in both datasets.


\section{Wrapping Up}
\label{\detokenize{40_in_practice/00_backwards_design:wrapping-up}}
\sphinxAtStartPar
Congratulations!

\sphinxAtStartPar
By the time you’ve done these 5 steps, you’ve managed to develop a concrete plan for exactly where you’ll focus your time, and you’ve nearly guaranteed that the result you’re working to generate will actually be useful in solving the problem that motivates you or your stakeholder. There’s still a lot of data wrangling, model selection, etc. ahead, but at least you won’t get lost in your data, or do lots of work that ends up no helping anyone!

\sphinxAtStartPar
\sphinxstylestrong{Want a template for this?} Great news! \sphinxhref{https://github.com/nickeubank/practicaldatascience/raw/master/handouts/PracticalDataScience\_BackwardsDesignTemplate.pdf}{You can download one here!}


\section{A Digression on Supervised Machine Learning}
\label{\detokenize{40_in_practice/00_backwards_design:a-digression-on-supervised-machine-learning}}
\sphinxAtStartPar
As noted above, we can think of superived machine learning as a tool that answers two types of questions: the first is the broad question of “can we predict {[}outcome of interest{]} using {[}variables we have{]} and the training set we have access to?”, and the second is the more narrow prediction question “for a given set of predictors, what value of {[}outcome of interest{]} would the model predict for a given observation”?

\sphinxAtStartPar
The first, I think, is pretty straightforward. But there’s a nuance to the second question that’s super important to understand: when we ask a supervised machine learning it’s prediction for a given observation, what we’re fundamentally asking your model is: \sphinxstylestrong{“how do you think the entity who labeled the data in your training data set would label this new observation?”}

\sphinxAtStartPar
Because that’s all that supervised machine learning does: it develops models that are designed to replicate the behavior that gave rise to the data set due used for training your model. For example, if you train a supervised machine learning algorithm to label pictures with the name of the animal in the picture by feeding it a bunch of pictures that have been labeled by undergraduates at an American university, than what you are training that machine learning algorithm to do is answer the question “how would an American undergraduate label this photo” every time it sees an unlabeled photograph.

\sphinxAtStartPar
Obviously different supervised machine learning algorithms go about trying to answer this question in different ways, and some will be more successful than others depending on the context (which is why we spend so much time studying model selection in machine learning courses), but answering this question is \sphinxstyleemphasis{always} the goal to which they aspire.

\sphinxAtStartPar
This is a bit of a digression, but I think it’s an important one: recognizing that this is all supervised machine learning algorithms do is important because it helps you, the data scientist, understand the limitations of supervised machine learning algorithms. For a surprisingly long time, people thought that machine learning algorithms were incapable of harboring racial or sexist prejudices. They are, after all, just built of math, and math can’t be racist, can it? And so companies like amazon tried to build supervised machine learning algorithms to help them decide who to hire. The problem, though, is that they trained them using data on which people human employees had decided to hire in the past, and data from subjective employee evaluations that had been made by human supervisors. And because this gave rise to an algorithm that looked at people’s resumes and asked itself “what would Amazon’s (very human) hiring staff and supervisors have thought of this person?,” the algorithm of course inherited all the biases of those humans. And so, OOPS!, when Amazon suddenly realized that “their new recruiting engine didn’t like women,” \sphinxhref{https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G}{they had to abandon the project}.

\sphinxAtStartPar
OK, digression on bias in data science complete. For now. :)

\sphinxstepscope


\chapter{Making Decisions Using Data}
\label{\detokenize{40_in_practice/20_from_data_to_decisions:making-decisions-using-data}}\label{\detokenize{40_in_practice/20_from_data_to_decisions::doc}}
\sphinxAtStartPar
(This is something that I know I need to add to my classes but I haven’t really managed integrated yet. I talk to my students about that fact that they should just pray at the altar of p<0.05, but instead weigh the relative costs and benefits of Type 1 and Type 2 errors in the context in which they are trying to make a decision. But where I really struggled is the fact that you can’t directly map P values onto decision theory very easily because of all of the weirdnesses of frequentist P values—e.g. A p\sphinxhyphen{}value of 0.05 means that under the null, the odds of a Type 2 is 5\%… but that means the ACTUAL odds of a Type 2 error if you have a p\sphinxhyphen{}value of 0.05\% is pr(null is true) * 0.05. 🤦‍♂️. )

\sphinxstepscope


\chapter{Writing Data Science Report for Non\sphinxhyphen{}Technical Audiences}
\label{\detokenize{40_in_practice/25_writing_to_stakeholders:writing-data-science-report-for-non-technical-audiences}}\label{\detokenize{40_in_practice/25_writing_to_stakeholders::doc}}
\sphinxAtStartPar
As a data scientist, you’ll often be required to summarize your analyses and present them to non\sphinxhyphen{}data scientists. This type of translation of technical analyses to something of use to less\sphinxhyphen{}technical audiences is an absolutely critical part of being an effective data scientist – if you don’t communicate what you’ve done to decision makers, it often doesn’t matter how rigorous or careful your work has been up to that point.

\sphinxAtStartPar
With that in mind, here is an outline of one strategy for writing for non\sphinxhyphen{}technical audiences. Obviously different people may prefer slightly different approaches, but I think this is a good model to start with.

\sphinxAtStartPar
Also, note that this \sphinxstyleemphasis{is} the model I’d like you to use when writing your final report for this class, so there are a few notes that are specific to class expectations!


\section{Identify your audience}
\label{\detokenize{40_in_practice/25_writing_to_stakeholders:identify-your-audience}}
\sphinxAtStartPar
Before you write a single word, you should pause to reflect on exactly who you wish to address with your report, and their background. What follows are general guidelines, but the better you know your audience, the more precisely you can tailor the level of detail in your report.

\sphinxAtStartPar
\sphinxstylestrong{For this class:} At the top of your report, please specify the stakeholder to whom you are addressing your report – a product manager, a legislative aid, a policymaker, etc. This stakeholder should be relevant to your study, but should not be someone with data science training. You may assume they know about basic statistical concepts (means and standard deviations), but no more (no assumed understanding of potential outcomes, the theoretical underpinnings of experiments, specific designs like differences\sphinxhyphen{}in\sphinxhyphen{}differences, etc.). Obviously this is not something you’d put in a real write\sphinxhyphen{}up, but will be helpful for evaluation of your project.


\section{Introduction / Executive Summary}
\label{\detokenize{40_in_practice/25_writing_to_stakeholders:introduction-executive-summary}}
\sphinxAtStartPar
One of the most important things to remember when writing up an analysis is that the person your writing to has too many things to do, and is \sphinxstylestrong{definitely} less interested in your project than you are. With that in mind, it’s important that you write and organize your report in a way that catches their attention early and gets them invested so they keep reading. As a result, one generally wants to start with the most important parts of the analysis, then slowly draw back and lay out additional details.

\sphinxAtStartPar
You may have never noticed this before, but this is how most news articles are written: one of the first two or three paragraphs is what’s referred to as the “nut graf” (or nutshell paragraph) in which the journalist basically summarizes the entire news article in a single paragraph. In the words of \sphinxhref{https://www.poynter.org/archive/2003/the-nut-graf-part-i/}{Ken Wells from the Wall Street Journal}, the nut graf is “a paragraph that says what this whole story is about and why you should read it. It’s a flag to the reader, high up in the story: You can decide to proceed or not, but if you read no farther, you know what that story’s about.

\sphinxAtStartPar
Thankfully you probably aren’t \sphinxstyleemphasis{so} pressed for time that you have to summarize everything in a single paragraph, but we will follow a similar structure in which we try and give the reader a full summary of why your project is important, how you do your analysis, and broadly what you conclude up front. In particular, I would argue that your introduction / executive summary should be organized as follows:

\sphinxAtStartPar
\sphinxstylestrong{Identify the problem you wish to address}

\sphinxAtStartPar
The first thing to do in any report is \sphinxstyleemphasis{motivate} your analysis – tell us about \sphinxstyleemphasis{why} you need to undertake this project. At this point in the report, keep this relatively brief – the motivation for the project is important, but you don’t want to drown the reader in background. This should probably be one\sphinxhyphen{}to\sphinxhyphen{}two solid paragraphs. But don’t draw it out – we can get more into background on the problem later, and you don’t want to get bogged down talking about the problem, you want to get to how you’re gonna help the reader.

\sphinxAtStartPar
\sphinxstylestrong{What question will you try to answer, and how will it help you address}

\sphinxAtStartPar
Here’s the linchpin of the report: announce the question you’re seeking to answer in your project \sphinxstyleemphasis{and} make it clear how this will help address the problem you’ve identified. This transition is where you will either get the reader to buy into the report and read it carefully, or lose their interest.

\sphinxAtStartPar
\sphinxstylestrong{Summarize your strategy}

\sphinxAtStartPar
Now in one to two paragraphs provide an overview of your project, your approach, and a preliminary summary of your results.

\sphinxAtStartPar
In all, you should have covered all this is about one page, maybe a page and a half, and \sphinxstyleemphasis{hopefully} now you’ve got your reader hooked!


\section{Background}
\label{\detokenize{40_in_practice/25_writing_to_stakeholders:background}}
\sphinxAtStartPar
OK, so at this point you’ve hopefully caught your readers interest, so now you can circle back and provide any additional background needed to help the reader better understand your motivation or the specific context you are analyzing (if you’re looking at a policy change, the details of the policy, the context in which it occurred, the players involved, etc.) The amount of background needed will vary across projects, but whatever you need goes here.


\section{Your Design}
\label{\detokenize{40_in_practice/25_writing_to_stakeholders:your-design}}
\sphinxAtStartPar
Here’s where you lay out how you plan to answer the question you laid out in your summary.

\sphinxAtStartPar
As you do so, bear in mind the difference between your goals in writing to a non\sphinxhyphen{}technical stakeholder and your goals when writing to a fellow data scientist (most of your professors).

\sphinxAtStartPar
When writing to a fellow data scientist, you’re generally writing to a skeptical audience. Your goal is to try and convince them that you did everything correctly – crossed every t and dotted every i. This is especially true when writing to professors in technical classes, since you’re usually trying to demonstrate your mastery of a technical skill, which means communicating very detail.

\sphinxAtStartPar
But a stakeholder reading your analysis is generally someone who mostly decided to put their trust in you when they hired you, and at this point your job is not to convince them every technical nuance of the project is right – by definition, most non\sphinxhyphen{}technical audiences wouldn’t be able to read a balance table showing that your randomization created balanced samples – but rather to communicate to them \sphinxstylestrong{the key take\sphinxhyphen{}aways} of the analysis.

\sphinxAtStartPar
That’s not to say you don’t need to engage with some technical aspects of your project. For example, if you’re using a good causal design, it’s critical the reader know why your causal research design is better than just looking at observational data in a regular regression (especially since someone else may try and argue with your results using that type of data). And of course they need to know about any limitations of what you’ve learned. But you don’t have to put every bit of due deligience you’ve done in the main report.

\sphinxAtStartPar
With that in mind, one thing that’s crucial to this section if you’re doing causal inference is to help the reader \sphinxstylestrong{understand why you’re using a specific causal design without using technical language.} To do so, you want to lay out \sphinxstyleemphasis{specific, concrete reasons} that just using observational data might lead to erroneous conclusions (e.g. do the same thing you did on the homework assignments / midterm when asked about how people were interpreting observational studies.)

\sphinxAtStartPar
For example, if you are doing an experiment to see how sending people coupons would impact consumer behavior, you want to explain that “we can’t just use data on sales from stores that chose to send out coupons to evaluate whether we should be sending out coupons to all our customers because it’s possible that the stores that sent out coupons did so precisely because they knew that their customers were struggling financially, and thus needed coupons to be able to afford products. As a result, if we compared sales to customers who got coupons to those who did not, we might inadvertently assume the lower sales to customers who got coupons was the result of the coupons, when in fact it actually reflected the fact that the coupons went to customers who were less well\sphinxhyphen{}off financially to begin with.”

\sphinxAtStartPar
“But if we run an experiment in which we randomly assign customers to either receive a coupon or not, then we know that on average the people getting coupons will be the same as the people not getting coupons (since who gets coupons is random, and not related to anything like customer income). As a result, we can compare sales to customers who got coupons and those that did not, and infer with confidence that any difference we see is the result of getting coupons, not other differences in the customers with or without coupons.”

\sphinxAtStartPar
(See? No discussion of potential outcomes or use of terms like “baseline differences!”


\section{Your Results}
\label{\detokenize{40_in_practice/25_writing_to_stakeholders:your-results}}
\sphinxAtStartPar
Now it’s time for results! As with your design, remember your goal is to emphasize the key take\sphinxhyphen{}aways of your analysis, which means both what the data can tell you \sphinxstyleemphasis{and what it can’t}. Remember that honest humility is a key part of being a good data scientist – don’t over\sphinxhyphen{}sell your results!


\section{Conclusions}
\label{\detokenize{40_in_practice/25_writing_to_stakeholders:conclusions}}
\sphinxAtStartPar
Now the final part of the project – quickly recapitulate the problem you wanted to address, the question you sought to answer, the answer you reached, and the implications of this result. In this discussion, make sure you talk a lot about \sphinxstyleemphasis{external validity}: where are these results likely applicable? Where are they not? What other research could be done to learn more? Do you have concrete recommendations?


\section{Appendix}
\label{\detokenize{40_in_practice/25_writing_to_stakeholders:appendix}}
\sphinxAtStartPar
Remember when I said that in writing to a non\sphinxhyphen{}technical stakeholder, you don’t have to detail all the nuances of your analysis? Well… that’s true. BUT: it’s often good to put the details of all the careful analyses of robustness and diagnostic tests you completed in appendices. That way you can reference them in the body of your report (communicating in broad terms that you were careful without boring your reader), but then also include them in case your stakeholder wants to share your report with another data scientist for a second opinion.

\sphinxAtStartPar
So you probably want (\sphinxstylestrong{and for this class, should have}) an appendix with things like balance tests, A/A tests, evidence of parallel trends, discussion of why you chose certain sample restrictions, alternate specifications, etc., depending on what’s appropriate for your particular research design.

\sphinxstepscope


\part{Advanced Topics}

\sphinxstepscope


\chapter{Interpretable Models}
\label{\detokenize{40_advanced_topics/30_interpretability:interpretable-models}}\label{\detokenize{40_advanced_topics/30_interpretability::doc}}
\sphinxAtStartPar
For most applications, perform just as well as fancy pants models. \sphinxurl{https://arxiv.org/abs/1811.10154}
Allow for non\sphinxhyphen{}specialists to see what goes into a model to debate ethics (after all, we data scientists have specialized knowledge when it comes to statistical methods, but not ethics)







\renewcommand{\indexname}{Index}
\printindex
\end{document}